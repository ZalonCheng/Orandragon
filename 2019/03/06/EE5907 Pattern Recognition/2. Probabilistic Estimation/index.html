<!DOCTYPE html>





<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.3.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2">
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.3.0',
    exturl: false,
    sidebar: {"position":"right","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    }
  };
</script>

  <meta name="description" content="1. MAP Estimation The key goal in machine learning is to do estimation. That means we give the estimated result when we are given observation. If we have no model of the estimation in the prior, we c">
<meta name="keywords" content="Optimization, Machine Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Chapter 2. Probabilistic Estimation">
<meta property="og:url" content="http://yoursite.com/2019/03/06/EE5907 Pattern Recognition/2. Probabilistic Estimation/index.html">
<meta property="og:site_name" content="Cheng-Zilong">
<meta property="og:description" content="1. MAP Estimation The key goal in machine learning is to do estimation. That means we give the estimated result when we are given observation. If we have no model of the estimation in the prior, we c">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2019-03-06T06:49:50.053Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 2. Probabilistic Estimation">
<meta name="twitter:description" content="1. MAP Estimation The key goal in machine learning is to do estimation. That means we give the estimated result when we are given observation. If we have no model of the estimation in the prior, we c">
  <link rel="canonical" href="http://yoursite.com/2019/03/06/EE5907 Pattern Recognition/2. Probabilistic Estimation/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Chapter 2. Probabilistic Estimation | Cheng-Zilong</title>
  <meta name="generator" content="Hexo 3.9.0">
  








  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Cheng-Zilong</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">Learning Notes</p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
      <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block post">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/03/06/EE5907 Pattern Recognition/2. Probabilistic Estimation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Cheng-Zilong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cheng-Zilong">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">Chapter 2. Probabilistic Estimation

          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2019-03-06 13:46:13 / Modified: 14:49:50" itemprop="dateCreated datePublished" datetime="2019-03-06T13:46:13+08:00">2019-03-06</time>
            </span>
          
            

            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/EE5907-Pattern-Recognition/" itemprop="url" rel="index"><span itemprop="name">EE5907 Pattern Recognition</span></a></span>

                
                
              
            </span>
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="map-estimation">1. MAP Estimation</h2>
<p>The key goal in machine learning is to do estimation. That means we give the estimated result when we are given observation. If we have no model of the estimation in the prior, we can give the estimated result only based on the result. So we choose maximum likelihood estimation. But if we have the prior knowledge, we can give the estimated result based on both the data and the prior knowledge, that is the maximum a posterior estimation.</p>
<p>Maximum a posterior estimation <span class="math display">\[
\begin{array}{rcl}
y_{MAP}&amp;=&amp;\underset{y}{\operatorname{argmax}}p(y|x)\\
&amp;=&amp;\underset{y}{\operatorname{argmax}}\frac{p(y)p(x|y)}{p(x)}\\
&amp;=&amp;\underset{y}{\operatorname{argmax}}p(y)p(x|y)\\
\end{array}
\]</span> In this case, we hope to find a maximum value of the probability when the data is given and we have the prior knowledge of the estimated data <span class="math inline">\(p(y)\)</span>.</p>
<h2 id="ml-estimation">2. ML Estimation</h2>
<p>Maximum likelihood estimation</p>
<p>When <span class="math display">\[
p(y)=1
\]</span> we have <span class="math display">\[
y_{MAP}=\underset{y}{\operatorname{argmax}}p(x|y)=y_{ML}
\]</span> In this case, we hope to get the max likelihood of the observation x given y. In general, ML estimation is computationally easier than MAP estimation, because we do not need to deal with the extra prior term. We often use ML estimation if the prior is unknown or if we do not feel comfortable assuming priors.</p>
<p>If sample goes to infinity, then <span class="math display">\[
\lim_{N\rightarrow\infty}y_{MAP}=y_{ML}
\]</span></p>
<h2 id="modeling-pyx">3. Modeling p(y|x)</h2>
<p><span class="math display">\[
p(y|x)=\frac{p(x|y)p(y)}{p(x)}
\]</span></p>
<p>Generative supervised learning: Modeling likelihood p(x|y) and prior p(y) directly, "Generative" because we can generate new data from p(x,y)=p(x|y)p(y)</p>
<p>Discriminative supervised learning: model p(y|x) directly</p>
<h2 id="probabilistic-estimation-of-model-parameters">4. Probabilistic Estimation of Model Parameters</h2>
<p>In general, parameter <span class="math inline">\(\theta\)</span> needs to be learnt from the training set for both generative models <span class="math inline">\(p(x,y|\theta)\)</span> and discriminative models <span class="math inline">\(p(y|x,\theta)\)</span>. Here we can use different strategies to learn the parameters from the data set.</p>
<p>Strategy 1: ML</p>
<p>First estimate <span class="math inline">\(\theta_{ML}=\underset{\theta}{\operatorname{argmax}}p(D|\theta)\\\)</span></p>
<p>Then plug in <span class="math inline">\(\theta_{ML}\)</span> into <span class="math inline">\(p(x,y|\theta_{ML})\)</span> and find ==MAP== estimate of y</p>
<p>Strategy 2: MAP</p>
<p>First estimate <span class="math inline">\(\theta_{MAP}=\underset{\theta}{\operatorname{argmax}}p(\theta|D)\\\)</span></p>
<p>Then plug in <span class="math inline">\(\theta_{MAP}\)</span> into <span class="math inline">\(p(x,y|\theta_{MAP})\)</span> and find ==MAP== estimate of y</p>
<p>Strategy 3: Posterior Predictive</p>
<p>Discuss in the future</p>
<h2 id="beta-binomial-generative-model">5. Beta-Binomial Generative Model</h2>
<p>Beta Distribution (Discussed in the last passage) <span class="math display">\[
p(\theta|a,b)=\frac{1}{B(a,b)}\theta^{a-1}(1-\theta)^{b-1}
\]</span> Consider N coin tosses: data <span class="math inline">\(D=(N_0,N_1)\)</span>, where <span class="math inline">\(N_0=\#tails\)</span> and <span class="math inline">\(N_1=\#heads\)</span> , <span class="math inline">\(N=N_0+N_1\)</span> . <span class="math inline">\(\theta\)</span> is the probability of head</p>
<p>Assume beta distribution prior on <span class="math inline">\(\theta\)</span>: <span class="math inline">\(p(\theta|a,b)=Beta(\theta|a,b)\)</span></p>
<p>Coin tosses problem <span class="math display">\[
P(D|\theta)=\left(
\begin{array}{c}
N\\
N_0
\end{array}
\right)\theta^{N_1}(1-\theta)^{N_0}
\]</span></p>
<p>Posterior <span class="math display">\[
\begin{array}{lll}
p(\theta|D)&amp;=&amp;\frac{p(D|\theta)p(\theta)}{p(D)}\\
&amp;=&amp; \frac{\left(
\begin{array}{c}
N\\
N_0
\end{array}
\right)\theta^{N_1}(1-\theta)^{N_0} \quad \frac{1}{B(a,b)}\theta^{a-1}(1-\theta)^{b-1}}{p(D)}\\
&amp;=&amp; \frac{\frac{B(N_1+a,N_0+b)}{B(a,b)}\left(
\begin{array}{c}
N\\
N_0
\end{array}
\right)
\frac{1}{B(N_1+a,N_0+b)}
\theta^{N_1+\alpha-1}(1-\theta)^{N_0+b-1} \quad }{p(D)}\\
&amp;=&amp; \frac{k(N_0,N_1,a,b)Beta(\theta|N_1+a, N_0+b)}{p(D)}\\
&amp;=&amp; Beta(\theta|N_1+a, N_0+b)
\end{array}
\]</span> Here we can see that the posterior is the same form as the prior, so we say that the beta is a conjugate prior of the binomial distribution.</p>
<p>Since ML is a special case of MAP, first we consider MAP here, and we know that the mode of Beta distribution is <span class="math inline">\(mode=\frac{c-1}{c+d-2}\)</span>, we have <span class="math display">\[
\begin{array}{rcl}
\theta_{MAP}&amp;=&amp;\underset{\theta}{\operatorname{argmax}}p(\theta|D)\\
&amp;=&amp;\frac{N_1+a-1}{N+a+b-2}
\end{array}
\]</span> when a=b=1 <span class="math display">\[
\theta_{ML}=\frac{N_1}{N}
\]</span> Predicting Future Coin Tosses</p>
<p>Strategy 1 ML <span class="math inline">\(p(\tilde x=1)=\theta_{ML}\)</span></p>
<p>Strategy 2 MAP <span class="math inline">\(p(\tilde x=1)=\theta_{MAP}\)</span></p>
<p>Strategy 3 Posterior Predictive Distribution</p>
<p>Actually our problem is <span class="math display">\[
p(\tilde x=1|D)
=\int_0^1 p(\tilde x=1,\theta|D)d\theta
=\int_0^1 p(\tilde x=1|\theta,D)p(\theta|D)d\theta 
= \int_0^1 \theta p(\theta|D)d\theta\\
= \int_0^1 \theta Beta(\theta|N_1+a, N_0+b)d\theta
\]</span> This is the mean of posterior distribution <span class="math display">\[
p(\tilde x=1|D)=\frac{N_0+b}{N+a+b}
\]</span></p>
<h2 id="dirichlet-multinomial-generative-model">6. Dirichlet-Multinomial Generative Model</h2>
<p>Multinomial Distribution <span class="math display">\[
\begin{array}{ccc}
P(X_1=x_1,X_2=x_2,X_3=x_3\dotsm)=\frac{n!}{x_1!x_2!\dotsm x_k!}p_1^{x_1}p_2^{x_2}\dotsm p_k^{x_k}\quad when \sum_{i=1}^kx_i=n\\
otherwise\quad P(X_1=x_1,X_2=x_2,X_3=x_3\dotsm)=0
\end{array}
\]</span> Dirichlet Distribution <span class="math display">\[
P(x|\alpha)=\frac{1}{B(\alpha)}\prod_{i=1}^Kx_i^{\alpha_i-1}
\]</span> Consider N rolls of K-sided dice <span class="math display">\[
p(D|\theta)=\frac{N!}{N_1!N_2!\dotsm N_k!}\theta_1^{N_1}\theta_2^{N_2}\dotsm \theta_K^{N_K}\quad
\propto\prod_{i=1}^K\theta_i^{N_i}\\
p(\theta|\alpha)=\frac{1}{B(\alpha)}\prod_{i=1}^Kx_i^{\alpha_i-1}
\]</span> Then <span class="math display">\[
p(\theta|D)\propto p(D|\theta)p(\theta)=Dir(\theta|N_1+\alpha_1,\dotsm,N_K+\alpha_K)
\]</span> Then MAP estimation of parameters <span class="math display">\[
\hat \theta_k^{MAP}=\frac{N_k+\alpha_k-1}{N+\sum_k\alpha_k-K}
\]</span> ML <span class="math display">\[
\hat \theta_k^{ML}=\frac{N_k}{N}
\]</span></p>
<p>Predicting Future Dice Rolls</p>
<p>Strategy 1 ML <span class="math inline">\(p(\tilde x=i)=\theta_{ML}^i\)</span></p>
<p>Strategy 2 MAP <span class="math inline">\(p(\tilde x=i)=\theta_{MAP}^i\)</span></p>
<p>Strategy 3 Posterior Predictive Distribution <span class="math inline">\(p(\tilde x=i|D)=\frac{N_i+\alpha_i}{N+\sum_k\alpha_k}\)</span></p>
<h2 id="univariate-gaussian">7. Univariate Gaussian</h2>
<p>Binomial and Multinomial are discrete random variables, here we look at continuous variables</p>
<p>Gaussian Distribution <span class="math display">\[
P(x|\mu,\sigma^2)=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}
\]</span> Given training data D, we hope to estimate parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span></p>
<p>ML: <span class="math display">\[
(\hat \mu,\hat\sigma^2)=\underset{\hat \mu,\hat\sigma^2}{\operatorname{argmax}}p(D|\hat \mu,\hat\sigma^2)
\]</span> We have <span class="math display">\[
\hat \mu=\frac{1}{N}\sum_{n=1}^Nx_n\\
\hat \sigma^2=\frac{1}{N}\sum_{n=1}^N(x_n-\hat\mu)^2
\]</span> MAP:</p>
<p>Using Normal Inverse Gamma Distribution as prior <span class="math display">\[
p(\mu,\sigma^2)=NormInvGam(\mu,\sigma^2|\alpha,\beta,\gamma,\delta)
\]</span></p>
<p><span class="math display">\[
\hat \mu=\frac{\sum_{n=1}^Nx_n+\gamma\delta}{N+\gamma}\\
\hat \sigma^2=\frac{\sum_{n=1}^N(x_n-\hat \mu)^2+2\beta+\gamma(\delta-\hat \mu)^2}{N+3+2\alpha}
\]</span></p>
<p>Predicting Future Gaussian Samples</p>
<p>Strategy 1 ML <span class="math inline">\(p(x^*)=\mathcal N(\mu_{ML},\sigma^2_{ML})\)</span></p>
<p>Strategy 2 MAP <span class="math inline">\(p(x^*)=\mathcal N(\mu_{MAP},\sigma^2_{MAP})\)</span></p>
<p>Strategy 3 Posterior Predictive Distribution (skipped)</p>

    </div>

    
    
    
        
      

      <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2019/03/03/EE5907 Pattern Recognition/1. Probability/" rel="next" title="Chapter 1. Probability">
                  <i class="fa fa-chevron-left"></i> Chapter 1. Probability
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2019/03/11/EE5907 Pattern Recognition/3. Naive Bayes Classifier/" rel="prev" title="Chapter 3. Navie Bayes Classifier">
                  Chapter 3. Navie Bayes Classifier <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </div>
  
  
  
  </article>

  </div>


          </div>
          

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc" data-target="post-toc-wrap">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview" data-target="site-overview-wrap">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#map-estimation"><span class="nav-text">1. MAP Estimation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ml-estimation"><span class="nav-text">2. ML Estimation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#modeling-pyx"><span class="nav-text">3. Modeling p(y|x)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#probabilistic-estimation-of-model-parameters"><span class="nav-text">4. Probabilistic Estimation of Model Parameters</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#beta-binomial-generative-model"><span class="nav-text">5. Beta-Binomial Generative Model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#dirichlet-multinomial-generative-model"><span class="nav-text">6. Dirichlet-Multinomial Generative Model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#univariate-gaussian"><span class="nav-text">7. Univariate Gaussian</span></a></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Cheng-Zilong</p>
  <div class="site-description" itemprop="description"></div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">74</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">categories</span>
        </a>
      </div>
    
  </nav>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:zilongcheng@u.nus.edu" title="E-Mail &rarr; mailto:zilongcheng@u.nus.edu" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
    
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Cheng-Zilong</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.3.0</div>

        












        
      </div>
    </footer>
  </div>

  
    
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/jquery/index.js?v=3.4.1"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.3.0"></script><script src="/js/motion.js?v=7.3.0"></script>
<script src="/js/schemes/pisces.js?v=7.3.0"></script>

<script src="/js/next-boot.js?v=7.3.0"></script>



  





















  

  
    
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    
  

  

  

</body>
</html>
