<!DOCTYPE html>





<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.3.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2">
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.3.0',
    exturl: false,
    sidebar: {"position":"right","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    }
  };
</script>

  <meta name="description" content="Self-Organizing Maps 1. Introduction Learning is a process by which the free parameters of a neural network are adapted through a process of stimulation by the environment in which the network is em">
<meta name="keywords" content="Optimization, Machine Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Chapter 3. Self-Organizing Maps">
<meta property="og:url" content="http://yoursite.com/2019/05/11/EE5904 Neural Network/3.SOM/index.html">
<meta property="og:site_name" content="Cheng-Zilong">
<meta property="og:description" content="Self-Organizing Maps 1. Introduction Learning is a process by which the free parameters of a neural network are adapted through a process of stimulation by the environment in which the network is em">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://yoursite.com/2019/05/11/EE5904%20Neural%20Network/3.SOM/assets/1555772820715.png">
<meta property="og:updated_time" content="2019-05-11T06:36:19.057Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 3. Self-Organizing Maps">
<meta name="twitter:description" content="Self-Organizing Maps 1. Introduction Learning is a process by which the free parameters of a neural network are adapted through a process of stimulation by the environment in which the network is em">
<meta name="twitter:image" content="http://yoursite.com/2019/05/11/EE5904%20Neural%20Network/3.SOM/assets/1555772820715.png">
  <link rel="canonical" href="http://yoursite.com/2019/05/11/EE5904 Neural Network/3.SOM/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Chapter 3. Self-Organizing Maps | Cheng-Zilong</title>
  <meta name="generator" content="Hexo 3.9.0">
  








  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Cheng-Zilong</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">Learning Notes</p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
      <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block post">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/05/11/EE5904 Neural Network/3.SOM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Cheng-Zilong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cheng-Zilong">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">Chapter 3. Self-Organizing Maps

          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2019-05-11 13:45:47 / Modified: 14:36:19" itemprop="dateCreated datePublished" datetime="2019-05-11T13:45:47+08:00">2019-05-11</time>
            </span>
          
            

            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/EE5904-Neural-Network/" itemprop="url" rel="index"><span itemprop="name">EE5904 Neural Network</span></a></span>

                
                
              
            </span>
          

          
            <span id="/2019/05/11/EE5904 Neural Network/3.SOM/" class="post-meta-item leancloud_visitors" data-flag-title="Chapter 3. Self-Organizing Maps" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
        
      
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2019/05/11/EE5904 Neural Network/3.SOM/#comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/2019/05/11/EE5904 Neural Network/3.SOM/" itemprop="commentCount"></span></a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h1 id="self-organizing-maps">Self-Organizing Maps</h1>
<h2 id="introduction">1. Introduction</h2>
<p>Learning is a process by which the free parameters of a neural network are adapted through a process of stimulation by the environment in which the network is embedded.</p>
<p>The topology-conserving mapping can be achieved by SOMs. The network is two layers network. There are only input layer and output layer without hidden layer. There is no hidden layer.</p>
<p>The location of neurons in the output layer is important.</p>
<h2 id="architecture">2. Architecture</h2>
<p>For each output neuron j, there are a set of synaptic weights <span class="math inline">\(w_{ji}\)</span> connected from all input neurons</p>
<h3 id="randomly-initialize-all-the-weights.">1. Randomly initialize all the weights.</h3>
<h3 id="select-input-vector-xx_1x_2dotsmx_n-from-the-training-set">2. Select input vector <span class="math inline">\(x=[x_1,x_2,\dotsm,x_n]\)</span> from the training set</h3>
<p>It can be done by choosing randomly from the training set or one by one in a deterministic manner like that for sequential learning.</p>
<h3 id="compare-x-with-weights-w_j-for-each-neuron-j-to-determine-winner">3. Compare x with weights <span class="math inline">\(w_j\)</span> for each neuron j to determine winner</h3>
<p>Find the best-matching neuron w(x), usually the neuron whose weight vector has smallest Euclidean distance from the input vector. <span class="math display">\[
i(x)=\arg \min _j||x-w_j||
\]</span> The winning neuron is that which is in some sense closet to the input sector.</p>
<h3 id="update-winner-so-that-it-becomes-more-like-x-together-with-the-winners-neighbor">4. Update winner so that it becomes more like x, together with the winner's neighbor</h3>
<p>The typical choice of topological neighborhood function <span class="math display">\[
h_{j,i(x)}=\exp (-\frac{d_{j,i}^2}{2\sigma^2})
\]</span> where <span class="math display">\[
d_{j,i}=\sqrt{(l-n)^2+(m-k)^2}
\]</span> if the position of the neuron is described by the index of the neuron in the matrix (2-d lattice)</p>
<h3 id="adjust-parameters-learning-rate-neighborhood-function">5. Adjust parameters: learning rate &amp; neighborhood function</h3>
<p>Another unique feature of the SOM algorithm is that the size of the topological neighborhood shrinks with time. <span class="math display">\[
\sigma(n)=\sigma_0\exp (-\frac{n}{\tau_1})
\]</span> where <span class="math inline">\(\tau_1\)</span> is a time-constant to control the decay rate of the effective width.</p>
<p>Time-varying neighborhood function <span class="math display">\[
h_{j,i(x)}=\exp (-\frac{d_{j,i}^2}{2\sigma(n)^2})
\]</span> It means that the influence of the winner on its neighbors decrease with time.</p>
<p>Parameters are adapted by <span class="math display">\[
w_j(n+1)=w_j(n)+\eta(n)h_{j,i(x)}(n)(x-w_j(n))
\]</span> That means the weight is the weighted average of the input and the current weight.</p>
<p>The synaptic weight vector <span class="math inline">\(w_i\)</span> of winning neuron i moves to the input vector x.</p>
<p>All the neurons in the neighborhood of the winning neuron also move to the input vector.</p>
<p>The learning-rate parameter <span class="math inline">\(\eta\)</span> should also decrease with time <span class="math display">\[
\eta(n)=\eta_0 \exp (-\frac{n}{\tau_2})
\]</span></p>
<h3 id="repeat-step-2-until-the-map-has-converged.">6. Repeat step 2 until the map has converged.</h3>
<h2 id="two-phases-of-the-adaptive-process">3. Two phases of the adaptive process</h2>
<h3 id="the-first-phase">1. The First Phase</h3>
<p>An ordering or self-organizing phase</p>
<p>The ordering phase may take as many as 1000 iterations and possibly more.</p>
<p>The learning rate should begin with a value close to 0.1; there after it should decrease gradually, but remain above 0.01. <span class="math display">\[
\eta_0=0.1\quad \tau_2=T\quad \eta(n)=0.1\exp(-\frac{n}{T})
\]</span> T is the total number of iterations for the first phase.</p>
<p>The neighborhood function should initially include almost all neurons, and then shrink with time. We may set the initial size of the width equal to the “radius” of the lattice. For instance if the size of the lattice is <span class="math inline">\(M\times N\)</span>, then the initial width can be set as <span class="math display">\[
\sigma_0=\frac{\sqrt{M^2+N^2}}{2}
\]</span> The time constant can be chosen as <span class="math display">\[
\tau_1=\frac{T}{\log (\sigma_0)}
\]</span> Then at the end, <span class="math inline">\(\sigma(T)=1\)</span></p>
<h3 id="the-second-phase">2. The Second Phase</h3>
<p>Convergence Phase</p>
<p>The second phase is needed to fine tune the feature map.</p>
<p>As a general rule, the number of iterations must be at least 500 times the number of neurons in the network. Thus, the convergence phase may have to go on for thousands and possibly tens of thousands of iterations.</p>
<p>For a good statistical accuracy, the learning parameter <span class="math inline">\(\eta(n)\)</span> should be kept at a small value, on the order of 0.01.</p>
<p>In many applications, the second phase is not needed if convergence of the parameters are not critical.</p>
<h2 id="summary">4. Summary</h2>
<p>For n-dimensional input space and m output neurons</p>
<ol type="1">
<li>Randomly initialize the weight vector <span class="math inline">\(w_i\)</span> for neuron</li>
<li>Sampling: choose an input vector x from the training set</li>
<li>Determine winner neuron k</li>
<li>Update all weight vectors of all neurons (include itself) in the neighborhood of the winning neuron</li>
<li>If convergence criterion met, Stop</li>
</ol>
<p>Example</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">X = <span class="built_in">randn</span>(<span class="number">800</span>,<span class="number">2</span>);</span><br><span class="line">s2 = sum(X.^<span class="number">2</span>,<span class="number">2</span>);</span><br><span class="line">trainX = (X.*<span class="built_in">repmat</span>(<span class="number">1</span>*(<span class="built_in">gammainc</span>(s2/<span class="number">2</span>,<span class="number">1</span>).^(<span class="number">1</span>/<span class="number">2</span>))./<span class="built_in">sqrt</span>(s2),<span class="number">1</span>,<span class="number">2</span>))';</span><br><span class="line"><span class="built_in">plot</span>(trainX(<span class="number">1</span>,:),trainX(<span class="number">2</span>,:),<span class="string">'+r'</span>); </span><br><span class="line">axis equal</span><br><span class="line"></span><br><span class="line">total_step_number = <span class="number">400000</span>;</span><br><span class="line">W = <span class="built_in">rand</span>(<span class="number">2</span>,<span class="number">64</span>); <span class="comment">%  row number (x-1)/8+1, column number (x-1)%8+1</span></span><br><span class="line">eta_0=<span class="number">0.1</span>; eta = eta_0; </span><br><span class="line">sigma_0 = <span class="number">4</span>; sigma = sigma_0;</span><br><span class="line"></span><br><span class="line">tau = <span class="number">8</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:(total_step_number/<span class="built_in">size</span>(trainX,<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">for</span> xx=trainX</span><br><span class="line">        [~,winner_index] = <span class="built_in">min</span>(vecnorm(xx-W));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> nn=<span class="number">1</span>:<span class="built_in">size</span>(W,<span class="number">2</span>) <span class="comment">%update neighbors</span></span><br><span class="line">            d_ji=norm([<span class="built_in">fix</span>((nn<span class="number">-1</span>)/<span class="number">8</span>+<span class="number">1</span>);<span class="built_in">mod</span>((nn<span class="number">-1</span>),<span class="number">8</span>)+<span class="number">1</span>]- ...</span><br><span class="line">                [<span class="built_in">fix</span>((winner_index<span class="number">-1</span>)/<span class="number">8</span>+<span class="number">1</span>);<span class="built_in">mod</span>((winner_index<span class="number">-1</span>),<span class="number">8</span>)+<span class="number">1</span>]);</span><br><span class="line">        </span><br><span class="line">            h_ji=<span class="built_in">exp</span>(-(d_ji^<span class="number">2</span>/(<span class="number">2</span>*sigma^<span class="number">2</span>)));</span><br><span class="line">            W(:,nn) =  W(:,nn) + eta*h_ji*(xx-W(:,nn));</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        eta = eta_0 * <span class="built_in">exp</span>(-(<span class="built_in">i</span>/(total_step_number/<span class="built_in">size</span>(trainX,<span class="number">2</span>))));</span><br><span class="line">        sigma = sigma_0 * <span class="built_in">exp</span>(-(<span class="built_in">i</span>/tau));</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="built_in">figure</span>(<span class="number">1</span>)</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line">axis equal</span><br><span class="line"><span class="built_in">plot</span>(trainX(<span class="number">1</span>,:),trainX(<span class="number">2</span>,:),<span class="string">'+r'</span>);</span><br><span class="line"><span class="built_in">plot</span>(W(<span class="number">1</span>,:),W(<span class="number">2</span>,:),<span class="string">'*b'</span>)</span><br><span class="line"></span><br><span class="line">result = <span class="built_in">zeros</span>(<span class="number">2</span>,<span class="number">8</span>,<span class="number">8</span>);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="number">64</span></span><br><span class="line">    result(:,<span class="built_in">fix</span>((<span class="built_in">i</span><span class="number">-1</span>)/<span class="number">8</span>+<span class="number">1</span>),<span class="built_in">mod</span>((<span class="built_in">i</span><span class="number">-1</span>),<span class="number">8</span>)+<span class="number">1</span>) = W(:,<span class="built_in">i</span>);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="number">8</span></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">j</span>=<span class="number">1</span>:<span class="number">7</span></span><br><span class="line">       <span class="built_in">plot</span>([result(<span class="number">1</span>,<span class="built_in">i</span>,<span class="built_in">j</span>),result(<span class="number">1</span>,<span class="built_in">i</span>,<span class="built_in">j</span>+<span class="number">1</span>)],[result(<span class="number">2</span>,<span class="built_in">i</span>,<span class="built_in">j</span>),result(<span class="number">2</span>,<span class="built_in">i</span>,<span class="built_in">j</span>+<span class="number">1</span>)],<span class="string">'*-'</span>);</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="number">7</span></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">j</span>=<span class="number">1</span>:<span class="number">8</span></span><br><span class="line">       <span class="built_in">plot</span>([result(<span class="number">1</span>,<span class="built_in">i</span>,<span class="built_in">j</span>),result(<span class="number">1</span>,<span class="built_in">i</span>+<span class="number">1</span>,<span class="built_in">j</span>)],[result(<span class="number">2</span>,<span class="built_in">i</span>,<span class="built_in">j</span>),result(<span class="number">2</span>,<span class="built_in">i</span>+<span class="number">1</span>,<span class="built_in">j</span>)],<span class="string">'*-'</span>);</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="assets/1555772820715.png" alt="Figure."><figcaption aria-hidden="true">Figure.</figcaption>
</figure>

    </div>

    
    
    
        
      

      <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2019/05/09/EE5904 Neural Network/2.RBFN/" rel="next" title="Chapter 2. Radial-Basis Function Networks">
                  <i class="fa fa-chevron-left"></i> Chapter 2. Radial-Basis Function Networks
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2019/05/13/EE5904 Neural Network/4.SVM/" rel="prev" title="Chapter 4. Support Vector Machine">
                  Chapter 4. Support Vector Machine <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </div>
  
  
  
  </article>

  </div>


          </div>
          
    
    <div class="comments" id="comments"></div>
  

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc" data-target="post-toc-wrap">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview" data-target="site-overview-wrap">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#self-organizing-maps"><span class="nav-text">Self-Organizing Maps</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#introduction"><span class="nav-text">1. Introduction</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#architecture"><span class="nav-text">2. Architecture</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#randomly-initialize-all-the-weights."><span class="nav-text">1. Randomly initialize all the weights.</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#select-input-vector-xx_1x_2dotsmx_n-from-the-training-set"><span class="nav-text">2. Select input vector \(x=[x_1,x_2,\dotsm,x_n]\) from the training set</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#compare-x-with-weights-w_j-for-each-neuron-j-to-determine-winner"><span class="nav-text">3. Compare x with weights \(w_j\) for each neuron j to determine winner</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#update-winner-so-that-it-becomes-more-like-x-together-with-the-winners-neighbor"><span class="nav-text">4. Update winner so that it becomes more like x, together with the winner&#39;s neighbor</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#adjust-parameters-learning-rate-neighborhood-function"><span class="nav-text">5. Adjust parameters: learning rate &amp; neighborhood function</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#repeat-step-2-until-the-map-has-converged."><span class="nav-text">6. Repeat step 2 until the map has converged.</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#two-phases-of-the-adaptive-process"><span class="nav-text">3. Two phases of the adaptive process</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#the-first-phase"><span class="nav-text">1. The First Phase</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#the-second-phase"><span class="nav-text">2. The Second Phase</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#summary"><span class="nav-text">4. Summary</span></a></li></ol></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Cheng-Zilong</p>
  <div class="site-description" itemprop="description"></div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">70</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span>
        </a>
      </div>
    
  </nav>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:zilongcheng@u.nus.edu" title="E-Mail &rarr; mailto:zilongcheng@u.nus.edu" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
    
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Cheng-Zilong</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.3.0</div>

        












        
      </div>
    </footer>
  </div>

  
    
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/jquery/index.js?v=3.4.1"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.3.0"></script><script src="/js/motion.js?v=7.3.0"></script>
<script src="/js/schemes/pisces.js?v=7.3.0"></script>

<script src="/js/next-boot.js?v=7.3.0"></script>



  





















  

  
    
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    
  

  

  


<script>
NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(item => {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'k1NFV6E2jjtcuFpWbPUwvs04-MdYXbMMI',
    appKey: 'oCso3hdINWUXi0EtP7BsCUoY',
    placeholder: 'Just go go',
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: true,
    lang: '' || 'zh-cn',
    path: location.pathname
  });
}, window.Valine);
</script>

</body>
</html>
