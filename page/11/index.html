<!DOCTYPE html>





<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.3.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2">
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.3.0',
    exturl: false,
    sidebar: {"position":"right","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    }
  };
</script>

  <meta name="keywords" content="Optimization, Machine Learning">
<meta property="og:type" content="website">
<meta property="og:title" content="Cheng-Zilong">
<meta property="og:url" content="http://yoursite.com/page/11/index.html">
<meta property="og:site_name" content="Cheng-Zilong">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Cheng-Zilong">
  <link rel="canonical" href="http://yoursite.com/page/11/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Cheng-Zilong</title>
  <meta name="generator" content="Hexo 3.9.0">
  








  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Cheng-Zilong</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">Learning Notes</p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            
  <div id="posts" class="posts-expand">
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/12/22/MA6268 Nonlinear Optimization/7.1 Nonlinear conic programming/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Cheng-Zilong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cheng-Zilong">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2020/12/22/MA6268 Nonlinear Optimization/7.1 Nonlinear conic programming/" class="post-title-link" itemprop="url">7. Nonlinear conic programming (1)</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2020-12-22 13:48:40" itemprop="dateCreated datePublished" datetime="2020-12-22T13:48:40+08:00">2020-12-22</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-11-13 10:18:24" itemprop="dateModified" datetime="2019-11-13T10:18:24+08:00">2019-11-13</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/MA6268-Nonlinear-Optimization/" itemprop="url" rel="index"><span itemprop="name">MA6268 Nonlinear Optimization</span></a></span>

                
                
              
            </span>
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="nonlinear-conic-programming">7. Nonlinear Conic Programming</h1>
<p>We consider the following optimization problem, <span class="math display">\[
\text{(OP)}\quad \begin{array}{rCl}
\min &amp; f(x)\\
\text{subject to}&amp; g(x)=0\\
&amp;h(x)\in \mathcal C,
\end{array}
\]</span> where <span class="math inline">\(f:\mathcal X\rightarrow \mathbb R,g:\mathcal X\rightarrow \mathcal U\)</span>, and <span class="math inline">\(h:\mathcal X\rightarrow \mathcal V\)</span> are continuously differentiable, <span class="math inline">\(\mathcal X,\mathcal U\)</span> and <span class="math inline">\(\mathcal V\)</span> are finite dimensional Euclidean spaces each equipped with a scalar product <span class="math inline">\(\langle \cdot,\cdot\rangle\)</span> and its induced norm <span class="math inline">\(||\cdot||\)</span>, and <span class="math inline">\(\mathcal C\subseteq \mathcal V\)</span> is a closed convex set in <span class="math inline">\(\mathcal V\)</span>.</p>
<p>Let <span class="math inline">\(\mathcal Y=\mathcal U\times \mathcal V\)</span>, <span class="math inline">\(\mathcal K=\{0^\mathcal U\}\times \mathcal C\subset \mathcal Y\)</span>. Define <span class="math inline">\(G:\mathcal X\rightarrow \mathcal Y\)</span> by <span class="math display">\[
G(X)=(g(X),h(X)),\quad X\in\mathcal X.
\]</span> The problem can be written as the following compact form, <span class="math display">\[
\text{(COP)}\quad \begin{array}{rCl}
\min &amp; f(X)\\
\text{subject to}&amp; G(X)\in\mathcal K.
\end{array}
\]</span> Define the Lagrangian function <span class="math inline">\(L:\mathcal X\times \mathcal Y\rightarrow \mathbb R\)</span> for (COP) by <span class="math display">\[
L(X,\mu)=f(X)-\langle \mu, G(X)\rangle,\quad X\in\mathcal X,\mu\in\mathcal Y.
\]</span> There is no constraint on <span class="math inline">\(\mu\)</span> for the general Lagrangian function. Therefore, here is <span class="math inline">\(y\in\mathcal Y\)</span>. We will give further explanation in the later.</p>
<p>The <strong>Lagrangian dual function</strong> is defined by <span class="math display">\[
\theta(\mu)=\inf\left\{L(X,\mu )\;|\; X\in\mathcal X\right\},
\]</span> which is an unconstrained function.</p>
<p>The dual problem is <span class="math display">\[
\max \{\theta(\mu)\;|\; \mu \in\mathcal K^*\},
\]</span> where <span class="math inline">\(\mathcal K^* =\mathcal U\times \mathcal C^*\)</span> is the dual cone of <span class="math inline">\(\mathcal K\)</span>. Note that <span class="math inline">\((\{0^\mathcal U\})^*=\mathcal U\)</span> and <span class="math inline">\(\mathbb S_+^n\)</span> is <strong>self-dual</strong>.</p>
<p>We can see in the conic programming, we only consider <span class="math inline">\(\mu\in \mathcal K^*\)</span> in the dual problem. However, if needed, we can also put this constraint to the Lagrangian dual function and Lagrangian function like what we usually do in the basic nonlinear programming.</p>
<p>We also define the Lagrangian function in the conic programming as <span class="math inline">\(L(x,\mu)=f(x)\textbf{ minus } \langle \mu,G(x)\rangle\)</span> <strong>instead of plus</strong>. This is for convenience because the cone is usually defined as “positive”, which means <span class="math inline">\(h(x)\succeq 0\)</span> in the conic programming <strong>instead of</strong> <span class="math inline">\(h(x)\le 0\)</span> in the basic nonlinear programming is the common case.</p>
<p><strong>Example</strong></p>
<p>If we have <span class="math inline">\(\mathcal X=\mathbb R^n\)</span>, <span class="math inline">\(\mathcal U=\mathbb R^m\)</span>, <span class="math inline">\(\mathcal V=\mathbb R^q\)</span> and <span class="math inline">\(\mathcal C=\mathbb R^q_+\)</span>. In this case, the problem reduces to the following, <span class="math display">\[
\text{(NLP)}\quad \begin{array}{rCl}
\min &amp; f(x)\\
\text{subject to}&amp; g(x)=0\\
&amp;h(x)\ge 0.
\end{array}
\]</span> If we denote <span class="math inline">\(G(x)=(g(x),h(x))\)</span>, <span class="math inline">\(\mathcal K=\{0^m\}\times \mathbb R^n_+\)</span>, there exists <span class="math inline">\(\mu\in\mathbb R^m\times \mathbb R^n\)</span>, such that the Lagrange function is defined as <span class="math display">\[
L(x,\mu)=f(x)-\langle \mu,G(x)\rangle.
\]</span> The Lagrange dual function is defined as <span class="math display">\[
\theta(\mu)=\min_x L(x,\mu)=\min_x\left(f(x)-\langle\mu,G(x)\rangle\right),\quad \mu\in\mathbb R^m\times \mathbb R^n.
\]</span> Since <span class="math inline">\(\left(\mathbb R^n_+\right)^*=\mathbb R^n_+\)</span>, the Lagrange dual problem is defined as <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\min &amp; \theta (\mu)\\
\text{subject to}&amp; \mu\in\mathcal K^*=\mathbb R^n\times \mathbb R^n_+.
\end{array}
\]</span> <strong>Example</strong> (semidefinite linear programming)</p>
<p>If <span class="math inline">\(\mathcal X=\mathbb S^n\)</span>, <span class="math inline">\(\mathcal U=\mathbb R^m\)</span>, <span class="math inline">\(\mathcal V=\mathbb S^n\)</span>, and <span class="math inline">\(f(X)=\langle C,X\rangle,\)</span> <span class="math inline">\(g(X)=\mathcal A(X)-b\)</span>, <span class="math inline">\(h(X)=X\)</span> and <span class="math inline">\(\mathcal C=\mathbb S_+^n\)</span>, then the problem (OP) reduces to the following linear semidefinite programming problem, <span class="math display">\[
\text{(SDP)}\quad \begin{array}{rCl}
\min &amp; \langle C,X\rangle\\
\text{subject to}&amp; \mathcal A(X)-b=0\\
&amp;X\succeq 0(X\in\mathbb S^n_+),
\end{array}
\]</span> where <span class="math inline">\(C\in \mathbb S^n\)</span>, <span class="math inline">\(\mathcal A:\mathbb S^n\rightarrow \mathbb R^m\)</span> is a linear mapping defined by <span class="math display">\[
\mathcal A(X)=
\begin{bmatrix}
\langle A_1,X\rangle \\ \vdots \\
\langle A_m,X\rangle
\end{bmatrix},\quad 
X\in\mathbb S^n,
\]</span> where <span class="math inline">\(A_k\in \mathbb S^n,k=1,\dotsm,m\)</span>, are the constraints matrices. Let <span class="math inline">\(\mathcal A^*:\mathbb R^m\rightarrow \mathbb S^n\)</span> be the adjoint of <span class="math inline">\(\mathcal A\)</span> defined by <span class="math display">\[
\mathcal A^*y=\sum_{k=1}^m y_kA_k,\quad y\in \mathbb R^m.
\]</span> This can be shown by the definition of the adjoint of operator. <span class="math display">\[
\begin{array}{rcl}
\langle \mathcal A^* y,X\rangle &amp;=&amp;\langle y,\mathcal A X\rangle\\
&amp;=&amp;\displaystyle\sum_{i=1}^m y_i\langle A_i,X\rangle \\
&amp;=&amp;\displaystyle\sum_{i=1}^m y_i\sum_{j=1}^ne_j^TA_iXe_j, \\
\mathbf 1^T\mathcal A^*yX \mathbf 1 &amp;=&amp; \displaystyle\sum_{i=1}^m y_i \mathbf 1^TA_iX\mathbf 1\\
&amp;=&amp; \mathbf 1^T\displaystyle\sum_{i=1}^m y_i A_iX\mathbf 1,
\end{array}
\]</span> Therefore, we have <span class="math inline">\(\mathcal A^*y=\sum_{i=1}^m y_iA_i\)</span>.</p>
<p>We have the Lagrange function, <span class="math display">\[
\begin{array}{rcl}
L(X,y,Z)&amp;=&amp;\langle C,X\rangle +\langle y,b-\mathcal A(X) \rangle+\langle Z,-X\rangle\\
&amp;=&amp;\langle y,b\rangle+\langle C-\mathcal A^*y-Z,X\rangle\quad X\in\mathbb S^n,y\in\mathbb R^n,Z\in\mathbb S^n.
\end{array}
\]</span> Then <span class="math display">\[
\begin{array}{rcl}
\theta(y,Z)&amp;=&amp;\displaystyle \inf_{X\in\mathbb S^n} \left\{\langle y,b\rangle+\langle C-\mathcal A^*y-Z,X\rangle\right\}\\
&amp;=&amp;\displaystyle\inf_{X\in\mathbb S^n} \left\{\langle y,b\rangle+\langle C-\mathcal A^*y-Z,X\rangle\right\}\\
&amp;=&amp; 
\begin{cases}
\langle y,b\rangle&amp;\text{if }C-\mathcal A^*y-Z=0\\
-\infty &amp; \text{otherwise.}
\end{cases}
\end{array}
\]</span> Therefore, the dual problem is given by, <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\max &amp; \langle y,b\rangle\\
\text{subject to}&amp; C-\mathcal A^*y-Z=0\\
&amp;Z\succeq 0.
\end{array}
\]</span> Also, we can consider the compact form. If we define <span class="math inline">\(G(X)=(\mathcal A(X)-b, X)\)</span>, <span class="math inline">\(\mathcal K=\{0^m\}\times \mathbb S^n_+\)</span>, then we have <span class="math display">\[
\text{(SDP)}\quad \begin{array}{rCl}
\min &amp; f(X)=\langle C,X\rangle\\
\text{subject to}&amp; G(X)\in\mathcal K.
\end{array}
\]</span> Then there exists <span class="math inline">\(\mu=(y,Z)\in\mathbb R^n\times \mathbb S^n\)</span>, such that the Lagrange function is defined as <span class="math display">\[
\begin{array}{rcl}
L(X,\mu)=L(X,y,Z)&amp;=&amp;f(X)-\langle \mu, G(X)\rangle\\
&amp;=&amp;\langle C,X\rangle-\langle y,\mathcal A(X)-b\rangle-\langle  Z,X\rangle\\
&amp;=&amp;\langle C,X\rangle-\langle \mathcal A^*(y), X\rangle+\langle y,b\rangle-\langle  Z,X\rangle\\
&amp;=&amp;\langle C-\mathcal A^*(y)-Z,X\rangle+\langle y,b\rangle.
\end{array}
\]</span> The we have the Lagrange dual function, <span class="math display">\[
\begin{array}{rcl}
\theta(y,Z)
&amp;=&amp; 
\begin{cases}
\langle y,b\rangle&amp;\text{if }C-\mathcal A^*y-Z=0\\
-\infty &amp; \text{otherwise.}
\end{cases}
\end{array}
\]</span> Then the Lagrange dual problem is <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\max &amp; \theta(y,Z)\\
\text{subject to}&amp; (y,Z)\in\mathcal K^*=\mathbb R^n\times \mathbb S^n_+,
\end{array}
\]</span> that is <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\max &amp; \langle y,b\rangle\\
\text{subject to}&amp; Z\in\mathbb S^n_+\\
&amp;C-\mathcal A^*y-Z=0.
\end{array}
\]</span> <strong>Example</strong></p>
<p>Let <span class="math inline">\(G\in\mathbb R^{p\times n}\)</span> and <span class="math inline">\(H\in\mathbb R^{q\times n}\)</span> for the linear map <span class="math inline">\(\mathcal A:\mathbb S^n\rightarrow \mathbb R^{p\times q}\)</span> defined by <span class="math inline">\(\mathcal A(X)=GXH^T\)</span>. Show that the adjoint map <span class="math inline">\(\mathcal A^*:\mathbb R^{p\times q} \rightarrow \mathbb S^n\)</span> is given by <span class="math inline">\(\mathcal A^*(Y)=\frac{1}{2}\left(G^TYH+H^TY^TG\right)\)</span>.</p>
<p>Proof. <span class="math display">\[
\begin{array}{rcl}
\langle \mathcal A(X),Y\rangle&amp;=&amp; \langle GXH^T,Y\rangle\\
&amp;=&amp; \text{tr}(HXG^TY)\\
&amp;=&amp; \text{tr}(XG^TYH)\\
&amp;=&amp; \frac{1}{2}\text{tr}\left(X(G^TYH+H^TY^TG)\right)\\
&amp;=&amp;\langle X,\frac{1}{2}(G^TYH+H^TY^TG)\rangle.
\end{array}
\]</span> Therefore, we have <span class="math inline">\(\mathcal A^*(Y)=\frac{1}{2}\left(G^TYH+H^TY^TG\right)\)</span>. (<strong>ATTENTION</strong>: <span class="math inline">\(\mathcal A^*:\mathbb R^{p\times q}\rightarrow \mathbb S^n\)</span>)</p>
<p><strong>Example</strong> (semidefinite programming least squares problem)</p>
<p>If <span class="math inline">\(f(x)=\frac{1}{2}||X-B||^2\)</span> where <span class="math inline">\(B\in \mathbb S^n\)</span> is a given matrix. <span class="math display">\[
\text{(SDPLS)}\quad \begin{array}{rCl}
\min &amp; \frac{1}{2}||X-B||^2\\
\text{subject to}&amp; \mathcal A(X)=b\\
&amp;X\succeq 0.
\end{array}
\]</span> In particular, when <span class="math inline">\(\mathcal A(X)=\text{diag} (X)\)</span> and <span class="math inline">\(b=e\)</span>, we get the nearest correlation matrix problem.</p>
<p>The problem can be denoted as <span class="math display">\[
\text{(SDPLS)}\quad \begin{array}{rCl}
\min &amp; \frac{1}{2}||X-B||^2\\
\text{subject to}&amp; G(X)\in \mathcal K,
\end{array}
\]</span> where <span class="math inline">\(G(X)=(\mathcal A(X)-b,X)\)</span> and <span class="math inline">\(\mathcal K=\{0^m\}\times \mathbb S_+^n\)</span>.</p>
<p>For <span class="math inline">\(X\in \mathbb S^n\)</span>, <span class="math inline">\(\mu = (y,Z)\in\mathcal Y=\mathbb R^m\times \mathbb S^n\)</span>, <span class="math display">\[
\begin{array}{rcl}
L(X,y,Z)&amp;=&amp;\frac{1}{2}||X-B||^2-\langle y,b-\mathcal A(X)\rangle -\langle Z,X\rangle\\
&amp;=&amp; \langle y,b\rangle +\frac{1}{2}||B||^2+\frac{1}{2}||X||^2-\langle \mathcal A^*(y)+Z+B,X\rangle,
\end{array}
\]</span> Thus <span class="math inline">\(\min\{L(X,y,Z)\;|\; X\in\mathbb S^n\}\)</span> can be found by setting, <span class="math display">\[
\nabla _XL(X,y,Z)=X-(B+Z+\mathcal A^*(y))=0\implies X=B+Z+\mathcal A^*(y).
\]</span> Then we have <span class="math display">\[
\begin{array}{rcl}
\theta (y,Z)&amp;=&amp;\min\{L(X,y,Z)\;|\; X\in\mathbb S^n\}\\
&amp;=&amp; \langle y,b\rangle +\frac{1}{2}||B||^2-\frac{1}{2}||B+Z+\mathcal A^*(y)||^2.
\end{array}
\]</span> The dual problem is given by <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\max &amp; \langle y,b\rangle +\frac{1}{2}||B||^2-\frac{1}{2}||B+Z+\mathcal A^*(y)||^2\\
\text{subject to}&amp; (y,Z)\in\mathcal K^*.
\end{array}
\]</span> Then we have <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\min &amp; -\langle y,b\rangle+\frac{1}{2}||B+Z+\mathcal A^*(y)||^2\\
\text{subject to}&amp; y\in\mathbb R^n\\
&amp; Z\in \mathbb S_+^n.
\end{array}
\]</span> We claim <strong>(This claim is very useful)</strong> <span class="math display">\[
G=\Pi_{\mathbb S_+^n} (G)-\Pi_{\mathbb S_+^n} (-G).
\]</span></p>
<p>This property can be easily checked by the property of proximal operator. Since we have <span class="math inline">\(\delta_K^*(x)=\delta_{K^*}(-x)\)</span>, let us check the proximal. <span class="math display">\[
\begin{array}{rcl}
P_{\delta_K^*}(y)&amp;=&amp;\arg\min_x\{\delta_K^*(x)+\frac{1}{2}||x-y||^2\}\\
&amp;=&amp;\arg\min_x\{\delta_{K^*}(-x)+\frac{1}{2}||x-y||^2\}\\
&amp;=&amp;-\arg\min_x\{\delta_{K^*}(x)+\frac{1}{2}||x-(-y)||^2\}\\
&amp;=&amp; -\Pi_{\delta_{K^*}}(-y).
\end{array}
\]</span> Therefore <span class="math display">\[
\begin{array}{rcl}
G&amp;=&amp;P_{\delta_{\mathbb S^n_+}}(G)+P_{(\delta_{\mathbb S^n_+})^*}(G)\\
&amp;=&amp; \Pi_{\mathbb S^n_+}(G)-\Pi_{(\mathbb S^n_+)^*}(-G)\\
&amp;=&amp; \Pi_{\mathbb S^n_+}(G)-\Pi_{\mathbb S^n_+}(-G).
\end{array}
\]</span></p>
<p>Then by using this claim, we have <span class="math display">\[
\begin{array}{l}
\min\left\{||B+Z+\mathcal A^*(y)||\;|\; Z\in\ \mathbb S_+^n\right\}
\\\quad =||B+\mathcal A^*(y)+\Pi_{\mathcal S_+^n}(-(B+\mathcal A^*(y)))||
\\\quad=||\Pi_{\mathbb S_+^n}(B+\mathcal A^*(y))||.
\end{array}
\]</span> Therefore, <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\min &amp; \phi(y)=-\langle y,b\rangle+\frac{1}{2}||\Pi_{\mathbb S_+^n}(B+\mathcal A^*(y))||^2\\
\text{subject to}&amp; y\in\mathbb R^n.
\end{array}
\]</span> In this case, the dual problem is unconstrained problem. Therefore, we can solve it by finding the root of the gradient, <span class="math display">\[
0=\nabla \phi(y)=-b+\mathcal A \Pi_{\mathbb S_+^n}(B+\mathcal A^* (y)).
\]</span> <strong>Example</strong> (Sparse regression problem) <span class="math display">\[
\min\{\frac{1}{2}||Ax-b||^2+\lambda ||x||_1\;|\; x\in\mathbb R^n\},
\]</span> where <span class="math inline">\(A\in\mathbb R^{m\times n}\)</span> and <span class="math inline">\(b\in\mathbb R^m\)</span> are given data. Let <span class="math inline">\(u=b-Ax\)</span>, then we have <span class="math display">\[
\text{(P)}\quad \begin{array}{rCl}
\min &amp; f(u)+g(x)\\
\text{subject to}&amp; u+Ax=b,
\end{array}
\]</span> where <span class="math inline">\(f(u)=\frac{1}{2}||u||^2\)</span> and <span class="math inline">\(g(x)=\lambda ||x||_1\)</span>.</p>
<p>The Lagrangian function is given as <span class="math display">\[
\begin{array}{rcl}
L(u,x,\xi)&amp;=&amp;f(u)+g(x)+\langle \xi,b-u-Ax\rangle\\
&amp;=&amp; f(u)-\langle \xi,u\rangle +g(x)-\langle A^T\xi,x\rangle +\langle \xi,b\rangle.
\end{array}
\]</span> The Lagrangian dual function is given as <span class="math display">\[
\theta(\xi)=\langle \xi,b\rangle+\min_u(f(u)-\langle \xi,u\rangle)+\min_x(g(x)-\langle A^T\xi,x\rangle)\\
=\langle \xi,b\rangle-\max_u(\langle \xi,u\rangle-f(u))-\max_x(\langle A^T\xi,x\rangle-g(x)).
\]</span> Both of the last two terms are conjugate functions. Therefore we have <span class="math display">\[
\theta(\xi)=\langle \xi,b\rangle-\frac{1}{2}||\xi||^2-\delta_{B_\lambda}(A^T\xi).
\]</span> Therefore, the dual problem is <span class="math display">\[
-\min -\langle\xi,b\rangle +\frac{1}{2}||\xi||^2+\delta_{B_\lambda}(A^T\xi).
\]</span> <strong>Definition</strong> (Lagrange Multipliers) <span class="math display">\[
L(x,\mu)=f(x)-\langle \mu, G(x)\rangle,\quad x\in\mathcal X,\mu\in\mathcal Y,
\]</span> where <span class="math inline">\(L\)</span> be the Lagrangian function for (COP). Assume that <span class="math inline">\(f\)</span> and <span class="math inline">\(G\)</span> are continuously differentiable. We say that <span class="math inline">\(\bar \mu \in\mathcal Y\)</span> is a Lagrange multiplier of (COP) at a feasible point <span class="math inline">\(\bar x\)</span>, if it satisfies the KKT condition, <span class="math display">\[
0=\nabla _xL(\bar x,\bar \mu)=\nabla f(\bar x)-\nabla G(\bar x)\bar \mu,\quad 0\in \bar \mu+N_\mathcal K(G(\bar x)),
\]</span> where <span class="math inline">\(N_\mathcal K (G(\bar x))\)</span> is the normal cone of <span class="math inline">\(\mathcal K\)</span> at <span class="math inline">\(G(\bar x)\in \mathcal Y\)</span>. We denote the set of all Lagrange multipliers at <span class="math inline">\(\bar x\)</span> as <span class="math inline">\(\mathcal M(\bar x)\)</span>. We call the pair <span class="math inline">\((\bar x,\bar \mu)\)</span> a KKT point.</p>
<p><strong>Remark</strong></p>
<ol type="1">
<li><p>If <span class="math inline">\(\mathcal C\)</span> is a closed convex cone, then <span class="math inline">\(\mathcal K = 0^{\mathcal U}\times \mathcal C\)</span> is a closed convex cone. <span class="math display">\[
\begin{array}{rcl}
-\bar \mu \in\mathcal N_\mathcal K(G(\bar x))&amp;\iff&amp; G(\bar x)\in\mathcal K,&amp;\langle -\bar \mu,d-G(\bar x)\rangle \le 0,&amp;&amp;\forall d\in\mathcal K
\end{array}
\]</span> We choose <span class="math inline">\(d=0\)</span> and <span class="math inline">\(d=G(\bar x)\)</span>. Then we have <span class="math display">\[
\begin{array}{rcl}
-\bar \mu \in\mathcal N_\mathcal K(G(\bar x))&amp;\iff&amp; G(\bar x)\in\mathcal K,&amp;\langle \bar \mu,G(\bar x)\rangle = 0,&amp;\langle \bar \mu,d\rangle\ge 0,&amp;\forall d\in\mathcal K\\
&amp;\iff&amp; G(\bar x)\in\mathcal K,&amp;\langle \bar \mu,G(\bar x)\rangle = 0,&amp;\bar \mu\in \mathcal K^*.
\end{array}
\]</span> In this case, the KKT conditions can be written as <span class="math display">\[
(G(\bar x)\in\mathcal K)\perp (\bar \mu \in\mathcal K^*).
\]</span></p></li>
<li><p>The set of multipliers <span class="math inline">\(\mathcal M(\bar x)\)</span> may be <strong>empty</strong> or <strong>unbounded</strong>.</p></li>
</ol>
<p><strong>Example</strong></p>
<p>For basic NLP, let <span class="math inline">\(\bar \mu=(\lambda,\rho)\)</span>, and <span class="math inline">\(G(x)=(g(x),h(x))\)</span>, <span class="math inline">\(\mathcal C=\mathbb R^p_+\)</span>, and <span class="math inline">\(\mathcal K=\{0^m\}\times \mathcal C\)</span>, we have KKT conditions, <span class="math display">\[
\begin{array}{rcl}
\nabla f(\bar x)-\nabla g(\bar x)\lambda -\nabla h(\bar x)\rho&amp;=&amp;0\\
G(\bar x)=(g(\bar x),h(\bar x))&amp;\in&amp; \mathcal K\\
\langle h(\bar x),\rho\rangle &amp;=&amp;0\\
\rho \in \mathcal C^*&amp;=&amp;\mathbb R_+^p.
\end{array}
\]</span> <strong>Example</strong></p>
<p>Given <span class="math inline">\(B\in\mathbb S^n\)</span>, consider the doubly nonnegative projection problem, <span class="math display">\[
\min \left\{\frac{1}{2}||X-B||^2\;|\; X\in\mathbb S_+^n\cap \mathcal N^n\right\}.
\]</span> The above problem can be rewritten as <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\min &amp; f(X)=\frac{1}{2}||X-B||^2\\
\text{subject to}&amp; G(X)=(X,X)\in\mathcal K=\mathbb S_+^n\times \mathcal N^n.
\end{array}
\]</span> The Lagrange function is for <span class="math inline">\(\mu=(Y,Z) \in \mathcal Y=\mathbb S^n\times \mathbb S^n\)</span>, <span class="math display">\[
\begin{array}{rcl}
L(X,\mu)=L(X,Y,Z)&amp;=&amp;\frac{1}{2}||X-B||^2-\langle \mu,G(X)\rangle\\
&amp;=&amp;\frac{1}{2}||X-B||^2-\langle Y,X\rangle-\langle Z,X\rangle.
\end{array}
\]</span> The Lagrange dual function is <span class="math display">\[
\begin{array}{rcl}
\theta(\mu)=\theta(Y,Z)&amp;=&amp;\min_{X\in\mathbb S^n} L(X,\mu)\\
&amp;=&amp;\min_{X\in\mathbb S^n}\left(\frac{1}{2}||X-B||^2-\langle Y,X\rangle-\langle Z,X\rangle\right)\\
&amp;=&amp;\min_{X\in\mathbb S^n}\left(\frac{1}{2}||X||^2-\langle B+Y+Z,X\rangle+\frac{1}{2}||B||^2\right)\\
&amp;=&amp;\frac{1}{2}\left(-||B+Y+Z||^2+||B||^2\right).
\end{array}
\]</span></p>
<p>Therefore the dual problem is <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\max &amp; \frac{1}{2}\left(-||B+Y+Z||^2+||B||^2\right)\\
\text{subject to}&amp; (Y,Z)\in\mathcal K^*=\mathbb S^n_+\times  \mathcal N^n.
\end{array}
\]</span> Therefore, the KKT conditions are given as <span class="math display">\[
0=\nabla _xL(\bar X,\bar Y,\bar Z)=\nabla f(\bar X)-\langle\nabla G(\bar X),(\bar Y,\bar Z)\rangle\\
\mathcal K\ni G(\bar X)\perp (\bar Y,\bar Z) \in \mathcal K^*.
\]</span> That is <span class="math display">\[
\bar X- B-\bar Y-\bar Z=0\\
\langle \bar X,\bar Y\rangle+\langle \bar X,\bar Z\rangle=0\\ 
\bar X\in \mathbb S^n_+\cap \mathcal N^n\\
(\bar Y,\bar Z)\in\mathbb S^n_+\times\mathcal N^n.
\]</span></p>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/12/22/MA6268 Nonlinear Optimization/6. Duality/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Cheng-Zilong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cheng-Zilong">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2020/12/22/MA6268 Nonlinear Optimization/6. Duality/" class="post-title-link" itemprop="url">6. Basic Lagrange Duality and Saddle Point Optimality Conditions</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2020-12-22 13:48:40" itemprop="dateCreated datePublished" datetime="2020-12-22T13:48:40+08:00">2020-12-22</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-11-11 20:26:54" itemprop="dateModified" datetime="2019-11-11T20:26:54+08:00">2019-11-11</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/MA6268-Nonlinear-Optimization/" itemprop="url" rel="index"><span itemprop="name">MA6268 Nonlinear Optimization</span></a></span>

                
                
              
            </span>
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>You can also refer to https://orandragon.github.io/2019/05/25/Convex%20Optimization/5.%20Duality/</p>
<h1 id="basic-lagrange-duality-and-saddle-point-optimality-conditions">Basic Lagrange Duality and Saddle Point Optimality Conditions</h1>
<p>Given an nonlinear programming problem, there is another nonlinear programming problem closely associated with it via the Lagrangian function. The former is called the <strong>primal problem</strong> and the latter is called the <strong>Lagrangian dual problem</strong>.</p>
<h2 id="lagrangian-dual-problem">6.1 Lagrangian dual problem</h2>
<p>Consider the following general nonlinear programming problem, which is known as a primal problem, <span class="math display">\[
\text{(P)}\quad \begin{array}{rCl}
\min &amp; f(x)\\
\text{subject to}&amp; g_i(x)=0,&amp;i=1,2,\dotsm,m\\
&amp;h_j(x)\le 0,&amp;j=1,2,\dotsm,p\\
&amp;x\in X,
\end{array}
\]</span> where <span class="math inline">\(X\subseteq \mathbb R^n\)</span>.</p>
<p><strong>Remark</strong></p>
<p><span class="math inline">\(x\in X\)</span> is to impose additional requirements that we may wish to handle separately. Some examples are</p>
<ol type="1">
<li><span class="math inline">\(X=\{x\in\mathbb R^n\;|\; x_i\ge 0,\;\forall i=1,2,\dotsm,n\}\)</span>. The nonnegativity constraints on the variables.</li>
<li><span class="math inline">\(X\)</span> could be a subset of $R^n $ with integer components.</li>
<li><span class="math inline">\(X=\mathbb R^n\)</span> if no special requirement.</li>
</ol>
<p>Let <span class="math display">\[
\begin{array}{rcl}
L(x,\lambda,\mu)&amp;=&amp; f(x)+\displaystyle{\sum_{i=1}^m\lambda_ig_i(x)+\sum_{j=1}^p\mu_jh_j(x)}\\
&amp;=&amp;f(x)+\lambda^T g(x)+\mu ^Th(x),
\end{array}
\]</span> where <span class="math inline">\(\mu\ge 0\)</span>.</p>
<p>Define <span class="math display">\[
\theta (\lambda,\mu)=\inf_x \left\{f(x)+\displaystyle{\sum_{i=1}^m\lambda_ig_i(x)+\sum_{j=1}^p\mu_jh_j(x)}\right\},
\]</span> which is called the <strong>Lagrange dual function</strong>.</p>
<p><strong>Remark</strong></p>
<ol type="1">
<li><p>Each equality constraint <span class="math inline">\(g_i(x)=0\)</span> is replaced by a term <span class="math inline">\(\lambda_ig_i(x)\)</span>, where <span class="math inline">\(\lambda_i\in \mathbb R,i=1,2,\dotsm,m\)</span>. This term gives a non-zero value whenever this equality is violated.</p></li>
<li><p>Each inequality constraint <span class="math inline">\(h_j(x)\le 0\)</span> is replaced by a term <span class="math inline">\(\mu_jh_j(x)\)</span>, where <span class="math inline">\(\mu_j\ge 0,j=1,2,\dotsm,p\)</span>. If an inequality constraint is violated, i.e., <span class="math inline">\(h_j(x)&gt;0\)</span>, then it is reflected by a positive value.</p></li>
<li><p>In evaluating <span class="math inline">\(\theta (\lambda,\mu)\)</span> for each <span class="math inline">\(\lambda,\mu\)</span>, the following unconstrained problem (Lagrangian dual subproblem) <span class="math display">\[
\begin{array}{rCl}
\min &amp; f(x)+\lambda^Tg(x)+\mu^T h(x)\\
\text{subject to} &amp;x\in X,
\end{array}
\]</span> must be solved.</p></li>
</ol>
<p>Suppose <span class="math inline">\(x^*\)</span> is an optimal solution of (P)​. Then <span class="math inline">\(g_i(x^*)=0\)</span> and <span class="math inline">\(h_j(x^*)\le 0\)</span>. Therefore, <span class="math display">\[
\theta(\lambda,\mu)\le f(x^*)+\mu^T h(x^*)\le f(x^*).
\]</span> This implies for any <span class="math inline">\(\lambda,\mu\)</span>, <span class="math inline">\(\theta(\lambda,\mu)\)</span> is the lower bound of the optimal objective value <span class="math inline">\(f^*(x)\)</span>.</p>
<p>We hope to derive the greatest lower bound for <span class="math inline">\(f(x^*)\)</span>. This leads to the following nonlinear programming problem which is called the <strong>Lagrangian dual problem</strong> (D)​, <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\max &amp; \theta(\lambda,\mu )=\displaystyle{\inf_x \left\{f(x)+\sum_{i=1}^m\lambda_ig_i(x)+\sum_{j=1}^p\mu_jh_j(x)\right\} }\\
\text{subject to}&amp; \lambda\in \mathbb R^m\\
&amp;\mu\in\mathbb R^p_+.
\end{array}
\]</span> <strong>Definition</strong> (Lagrange Dual Problem)</p>
<p>For a given primal nonlinear programming problem (P), <span class="math display">\[
\text{(P)}\quad \begin{array}{rCl}
\min &amp; f(x)\\
\text{subject to}&amp; g_i(x)=0,&amp;i=1,2,\dotsm,m\\
&amp;h_j(x)\le 0,&amp;j=1,2,\dotsm,p\\
&amp;x\in X,
\end{array}
\]</span> where <span class="math inline">\(X\subseteq \mathbb R\)</span>. The <strong>Lagrange Dual Problem</strong> (D) is the following nonlinear programming problem, <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\max &amp; \theta(\lambda,\mu )=\displaystyle{\inf_x \left\{f(x)+\sum_{i=1}^m\lambda_ig_i(x)+\sum_{j=1}^p\mu_jh_j(x)\right\} }\\
\text{subject to}&amp; \lambda\in \mathbb R^m\\
&amp;\mu\in\mathbb R^p_+.
\end{array}
\]</span> The dual variables <span class="math inline">\(\lambda_i\)</span> and <span class="math inline">\(\mu_j\)</span> are called <strong>Lagrangian dual variables</strong> or <strong>Lagrangian Multipliers</strong>.</p>
<p><strong>Remark</strong></p>
<ol type="1">
<li>Evaluation of <span class="math inline">\(\theta(\lambda,\mu)\)</span> can be called as the <strong>Lagrangian dual subproblem</strong>.</li>
<li>For general nonlinear programming problems, it is <strong>not true</strong> that one has an optimal solution, then the other will have an optimal solution. However, this is true for convex programming problems.</li>
<li>Under certain convexity assumptions and suitable constraint qualifications, the primal and dual problems have equal optimal objective value and hence it is possible to solve the primal problem indirectly by solving the dual problem. The dual problem is sometimes easier.</li>
</ol>
<p><strong>Example</strong></p>
<p>Obtain the Lagrangian dual problem of the following nonlinear programming problem (P), <span class="math display">\[
\text{(P)}\quad \begin{array}{rCl}
\min &amp; f(x)=x_1x_2x_3\\
\text{subject to}&amp; x_1-x_2+5x_3=6\\
&amp; x_1+2x_2^3\le 4\\
&amp;(x_1-3)^3-4x_2^2+x_3\le 0\\
&amp;x_1^2+x_2^2-x_3\le 4.
\end{array}
\]</span> The Lagrangian function is given by <span class="math display">\[
\begin{array}{rcl}
L(x,\lambda,\mu)&amp;=&amp;x_1x_2x_3\\
&amp;&amp;+\lambda (x_1-x_2+5x_3-6)\\
&amp;&amp;+\mu_1(x_1+2x_2^3-4)\\
&amp;&amp;+\mu_2[(x_1-3)^3-4x_2^2+x_3]\\
&amp;&amp;+\mu_3(x_1^2+x_2^2-x_3-4).
\end{array}
\]</span> The Lagrangian dual function is given by <span class="math display">\[
\theta (\lambda,\mu)=\min_x L(x,\lambda,\mu).
\]</span> The Lagrangian dual problem is given by <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\max &amp; \min_x L(x,\lambda,\mu)\\
\text{subject to}&amp; \mu\ge 0.
\end{array}
\]</span> <strong>Example</strong></p>
<p>Solve the following convex program and its Lagrangian dual problem. <span class="math display">\[
\text{(P)}\quad \begin{array}{rCl}
\min &amp; f(x)=x_1^2+x_2^2\\
\text{subject to}&amp; h(x)=-x_1-x_2+4\le 0,\\
&amp;x\in X=\left\{\begin{bmatrix}x_1\\x_2\end{bmatrix} \;\Bigg|\; x_1,x_2\ge 0\right\},
\end{array}
\]</span> Note that the optimal solution occurs at <span class="math inline">\(x^*=\begin{bmatrix}2\\2\end{bmatrix}\)</span>, and <span class="math inline">\(f(x^*)=8\)</span>.</p>
<p>The Lagrangian function is <span class="math display">\[
L(x,\mu)=x_1^2+x_2^2+\mu (-x_1-x_2+4).
\]</span> The Lagrangian dual problem is <span class="math display">\[
\begin{array}{rcl}
\theta(\mu)&amp;=&amp;\inf_{x_1,x_2\ge 0}\left\{x_1^2+x_2^2+\mu (-x_1-x_2+4)\right\}\\
&amp;=&amp;\inf_{x_1,x_2\ge 0}\left\{x_1^2-\mu x_1+x_2^2-\mu x_2+4 \mu \right\}\\
&amp;=&amp;\inf_{x_1\ge 0}\left\{x_1^2-\mu x_1\right\}+\inf_{x_2\ge 0}\left\{x_2^2-\mu x_2\right\}+4 \mu\\
&amp;=&amp;-\frac{\mu^2}{2}+4\mu\quad (x_1=\frac{\mu}{2},x_2=\frac{\mu}{2}).
\end{array}
\]</span> Thus the dual problem is <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\max &amp; \theta(\mu)=-\frac{\mu^2}{2}+4\mu\\
\text{subject to}&amp; \mu\ge 0.
\end{array}
\]</span> It is easy to see that <span class="math inline">\(\mu^*=4\)</span> and <span class="math inline">\(\theta(\mu^*)=8\)</span>. We can also obtain that <span class="math inline">\(x_1^*=x_2^*=\frac{\mu^*}{2}=2\)</span>.</p>
<p><strong>Remark</strong></p>
<p>In general, the dual function of a primal problem cannot be obtained explicitly. In this situation, the dual problem may include primal variables <span class="math inline">\((x)\)</span> as well as the dual variables <span class="math inline">\((\lambda,\mu)\)</span>.</p>
<p><strong>Example</strong></p>
<p>Consider the problem <span class="math display">\[
\text{(P)}\quad \begin{array}{rCl}
\min &amp; f(x)=\exp (x)\\
\text{subject to}&amp; x^2-1\le 0.
\end{array}
\]</span> For <span class="math inline">\(\mu\ge 0\)</span>, the Lagrangian dual function is <span class="math display">\[
\theta(\mu)=\inf_{x}\left(\exp(x)+\mu(x^2-1)\right),
\]</span> which is convex on <span class="math inline">\(\mathbb R\)</span>. Therefore, any stationary point will be a global minimizer. Then we have if <span class="math inline">\(\mu&gt;0\)</span>, <span class="math display">\[
\exp (x^*)+2\mu x^*=0,
\]</span> otherwise <span class="math inline">\((\mu=0)\)</span>, <span class="math display">\[
\theta(0)=0.
\]</span> Therefore, we have <span class="math display">\[
\theta(\mu)=
\begin{cases}
\exp(x)+\mu(x^2-1)&amp; \text{and}&amp;\exp(x)+2\mu x=0,&amp; \mu&gt;0\\
0&amp;&amp;&amp;\mu=0.
\end{cases}
\]</span> Therefore, the dual problem is <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\max &amp; \theta(\mu)=\exp (x)+\mu(x^2-1)\\
\text{subject to}&amp; \exp(x)+2\mu x=0\\&amp;\mu&gt;0\\&amp;x\in\mathbb R.
\end{array}
\]</span></p>
<h2 id="weak-and-strong-duality-theorems">6.2 Weak and strong duality theorems</h2>
<p>We shall discuss the relationship between a nonlinear programming problem and its Lagrangian dual problem for a primal minimization problem.</p>
<p><strong>Theorem</strong> (Weak Duality Theorem)</p>
<p>Consider the primal nonlinear programming problem (P). Let <span class="math inline">\(x\)</span> be a feasible point to (P) and <span class="math inline">\((\lambda,\mu)\)</span> be a feasible solution to (D). Then <span class="math display">\[
f(x)\ge \theta(\lambda,\mu).
\]</span> <strong>Corollary</strong></p>
<ol type="1">
<li><p><span class="math inline">\(\min\{f(x)\;|\; x\in S\}\ge \max \{\theta(\lambda,\mu)\;|\; \lambda\in\mathbb R^m,\mu\in \mathbb R^p_+\}\)</span>.</p></li>
<li><p>If <span class="math inline">\(x^*\)</span> is a feasible solution to (P) and <span class="math inline">\((\lambda^*,\mu^*)\)</span> is a feasible solution to (D) such that <span class="math display">\[
f(x^*)=\theta(\lambda^*,\mu^*),
\]</span> then <span class="math inline">\(x^*\)</span> is an optimal solution to (P) and <span class="math inline">\((\lambda^*,\mu^*)\)</span> is an optimal solution to (D).</p></li>
</ol>
<p>In general, the optimal primal objective value and the optimal dual objective value may not be equal. This leads to the following definition.</p>
<p><strong>Definition</strong> (Duality Gap)</p>
<p>The difference <span class="math display">\[
\min\{f(x)\;|\; x\in S\}-\max \{\theta(\lambda,\mu)\;|\; \mu \in \mathbb R_+^p\},
\]</span> is called the duality gap.</p>
<p><strong>Theorem</strong> (Strong Duality Theorem)</p>
<p>Consider the primal nonlinear programming problem. Suppose <span class="math inline">\(X\)</span> is a convex set, <span class="math inline">\(f,h_i,\;\forall i=1,\dotsm,p\)</span> are convex functions, and <span class="math inline">\(g_i,\;\forall i=1,\dotsm,m\)</span> are affine functions. If there exists <span class="math inline">\(\hat x\in X\)</span> such that <span class="math inline">\(h(\hat x)&lt;0\)</span>, <span class="math inline">\(g(\hat x)=0\)</span>, and <span class="math inline">\(0\in \text{int}(g(X))\)</span> where <span class="math inline">\(g(X)=\{g(x)\;|\; x\in X\}\)</span>. Then <span class="math display">\[
\inf \{f(x)\;|\;g(x)=0,h(x)\le 0,x\in X\}=\sup\{\theta(\lambda,\mu)\;|\; \mu \in\mathbb R^p_+,\lambda\in \mathbb R^m\}.
\]</span> Furthermore, if inf is finite, then sup is attained at some <span class="math inline">\(\lambda_*,\mu_*\)</span>. If inf is attained at <span class="math inline">\(x^*\)</span>, then <span class="math inline">\(\mu_*^Th(x^*)=0\)</span>.</p>
<h2 id="saddle-point-optimality-condition-and-kkt-conditions">6.3 Saddle point optimality condition and KKT conditions</h2>
<p>In this section, we discuss about the relationship between the saddle point of the Lagrangian function and KKT optimality conditions.</p>
<p><strong>Definition</strong> (Saddle point of <span class="math inline">\(L\)</span>)</p>
<p>A point <span class="math inline">\((x^*,\lambda^*,\mu^*)\)</span> is called a saddle point of the Lagrangian function <span class="math display">\[
L(x,\lambda,\mu)=f(x)+\lambda^Tg(x)+\mu^T h(x),
\]</span> if <span class="math inline">\(x^*\in X\)</span>, <span class="math inline">\(\mu^* \ge 0\)</span> and <span class="math display">\[
L(x^*,\lambda,\mu)\le L(x^*,\lambda^*,\mu^*)\le L(x,\lambda^*,\mu^*),
\]</span> for all <span class="math inline">\(x\in X\)</span> and all <span class="math inline">\((\lambda,\mu)\)</span> with <span class="math inline">\(\mu\ge0\)</span>.</p>
<p><strong>Remark</strong></p>
<ol type="1">
<li>For a fixed <span class="math inline">\(x^*\)</span>, <span class="math inline">\((\lambda^*,\mu ^*)\)</span> maximizes <span class="math inline">\(L(x^*,\lambda,\mu)\)</span> over all <span class="math inline">\((\lambda,\mu)\)</span> with <span class="math inline">\(\mu \ge 0\)</span>.</li>
<li>For a fixed <span class="math inline">\((\lambda^*,\mu^*)\)</span>, <span class="math inline">\(x^*\)</span> minimizes <span class="math inline">\(L(x,\lambda^*,\mu^*)\)</span> over all <span class="math inline">\(x\in X\)</span>.</li>
</ol>
<p><strong>Theorem</strong> (Saddle point optimality)</p>
<p>Suppose <span class="math inline">\((x^*,\lambda^*,\mu^*)\)</span> is a saddle point of the Lagrangian function <span class="math display">\[
L(x,\lambda,\mu)=f(x)+\lambda^Tg(x)+\mu^Th(x).
\]</span> Then <span class="math inline">\(x^*\)</span> and <span class="math inline">\((\lambda^*,\mu^*)\)</span> are optimal solutions of the primal problem (P) and the dual problem <span class="math inline">\((D),\)</span> respectively.</p>
<p><strong>Proof</strong></p>
<p>Suppose <span class="math inline">\((x^*,\lambda^*,\mu^*)\)</span> is a saddle point of the Lagrangian function. Then we have <span class="math display">\[
L(x^*,\lambda,\mu)\le L(x^*,\lambda^*,\mu^*)\le L(x,\lambda^*,\mu^*),
\]</span> for all <span class="math inline">\(x\in X\)</span> and all <span class="math inline">\((\lambda,\mu)\)</span> with <span class="math inline">\(\mu\ge0\)</span>. Thus we have <span class="math display">\[
f(x^*)+\lambda^Tg(x^*)+\mu^Th(x^*)\le f(x^*)+(\lambda^*)^Tg(x^*)+(\mu^*)^Th(x^*),
\]</span> for all <span class="math inline">\((\lambda,\mu)\)</span> with <span class="math inline">\(\mu\ge0\)</span>.</p>
<p>Firstly, we prove that <span class="math inline">\(x^*\)</span> is a feasible point, which means <span class="math display">\[
g(x^*)=0\\
h(x^*)&lt;0.
\]</span> Let <span class="math inline">\(\mu=\mu^*\)</span>, we have <span class="math display">\[
(\lambda-\lambda^*)^T g(x^*)\le 0, \;\forall \lambda \in \mathbb R^n.
\]</span> If <span class="math inline">\(g(x^*)\neq 0\)</span>, we can choose <span class="math inline">\(\lambda = \lambda^* +g(x^*)\)</span>, which leads to contradiction. Therefore, <span class="math inline">\(g(x^*)=0\)</span>.</p>
<p>Let <span class="math inline">\(\lambda=\lambda^*\)</span>, we have <span class="math display">\[
(\mu-\mu^*)^Th(x^*)\le 0,\;\forall \mu\ge 0.
\]</span> If <span class="math inline">\(h(x^*)&gt;0\)</span>, then we can choose <span class="math inline">\(\mu = \mu^*+ h(x^*)\)</span>, which leads to contradiction. Therefore, <span class="math inline">\(h(x^*)\le 0\)</span>.</p>
<p>Then we will prove <span class="math inline">\(x^*\)</span> is an optimal solution to (P).</p>
<p>Let <span class="math inline">\(\mu = 0\)</span>, we have <span class="math inline">\((\mu^*)^T h(x^*)\ge 0\)</span>. Since <span class="math inline">\(\mu^*\ge 0\)</span> and <span class="math inline">\(h(x^*)\le 0\)</span>, we also have <span class="math inline">\((\mu^*)^T h(x^*)\le 0\)</span>. Therefore, <span class="math inline">\((\mu^*)^T h(x^*)= 0\)</span>.</p>
<p>Then we have <span class="math display">\[
f(x^*)=L(x^*,\lambda^*,\mu^*)\le L(x,\lambda^*,\mu^*),
\]</span> for every <span class="math inline">\(x\in S\)</span>. Therefore <span class="math inline">\(f(x^*)\le \inf\{L(x,\lambda^*,\mu^*)\}=\theta(\lambda^*,\mu^*)\)</span>.</p>
<p>On the other hand, <span class="math display">\[
\theta(\lambda^*,\mu^*)\le \max\{\theta(\lambda,\mu)\;|\;\mu\ge 0\}\le \min \{f(x)\;|\; x\in S\}=f(x^*).
\]</span> Therefore, we have <span class="math display">\[
f(x^*)=\theta(\lambda^*,\mu^*).
\]</span> Q.E.D.</p>
<p><strong>Corollary</strong></p>
<p>Suppose <span class="math inline">\((x^*,\lambda^*,\mu^*)\)</span>, with <span class="math inline">\(x^* \in \text{int}(X)\)</span> and <span class="math inline">\(\mu^*\ge 0\)</span>, is a saddle point of <span class="math inline">\(L(x,\lambda,\mu)\)</span>, then <span class="math inline">\(x^*\)</span> is a feasible solution to (P) and <span class="math inline">\((x^*,\lambda^*,\mu^*)\)</span> satisfies the KKT conditions.</p>
<h2 id="convex-program">6.4 Convex Program</h2>
<p>The converse of the above corollary is not true in general. However, for a convex programming problem, the following result gives the relationship between a KKT point and a saddle point of the Lagrangian function.</p>
<p><strong>Theorem</strong> (A KKT point of a convex program is a saddle point)</p>
<p>Let <span class="math inline">\(S\)</span> be a feasible region of <span class="math display">\[
\text{(CP)}\quad \begin{array}{rCl}
\min &amp; f(x)\\
\text{subject to}&amp; g_i(x)=0,&amp;i=1,2,\dotsm,m\\
&amp;h_j(x)\le 0,&amp;j=1,2,\dotsm,p\\
&amp;x\in X\subseteq \mathbb R^n.
\end{array}
\]</span> Suppose <span class="math inline">\(x^*\)</span> is a KKT point, i.e., there exists <span class="math inline">\(\lambda^*\in\mathbb R^n,\mu^*\ge 0\)</span> such that <span class="math display">\[
\nabla f(x^*)+\sum_{i=1}^m \lambda_i^*\nabla g_i(x^*)+\sum_{j=1}^p \mu_j^*\nabla  h_j(x^*)=0\\
\mu_j^* h_j(x^*)=0,\;\forall j=1,\dotsm,p.
\]</span> Then <span class="math inline">\((x^*,\lambda^*,\mu^*)\)</span> us a saddle point of the Lagrangian function <span class="math inline">\(L(x,\lambda,\mu)\)</span>, i.e., <span class="math display">\[
L(x^*,\lambda,\mu)\le L(x^*,\lambda^*,\mu^*)\le L(x,\lambda^*,\mu^*),
\]</span> for all <span class="math inline">\(x\in X\)</span> and all <span class="math inline">\((\lambda,\mu)\)</span> with <span class="math inline">\(\mu\ge0\)</span>.</p>
<p><strong>Corollary</strong></p>
<p>Consider the convex problem (CP). If <span class="math inline">\((x^*,\lambda^*,\mu^*)\)</span> is a KKT point, then <span class="math inline">\(x^*\)</span> and <span class="math inline">\((\lambda^*,\mu^*)\)</span> are optimal solutions of the primal problem (P) and the dual problem <span class="math inline">\((D),\)</span> respectively.</p>
<p>Proof.</p>
<p>By combining the two theorems.</p>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/10/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/10/">10</a><span class="page-number current">11</span><a class="page-number" href="/page/12/">12</a><span class="space">&hellip;</span><a class="page-number" href="/page/43/">43</a><a class="extend next" rel="next" href="/page/12/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>


          </div>
          

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc" data-target="post-toc-wrap">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview" data-target="site-overview-wrap">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Cheng-Zilong</p>
  <div class="site-description" itemprop="description"></div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">85</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">categories</span>
        </a>
      </div>
    
  </nav>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:zilongcheng@u.nus.edu" title="E-Mail &rarr; mailto:zilongcheng@u.nus.edu" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
    
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Cheng-Zilong</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.3.0</div>

        












        
      </div>
    </footer>
  </div>

  
    
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/jquery/index.js?v=3.4.1"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.3.0"></script><script src="/js/motion.js?v=7.3.0"></script>
<script src="/js/schemes/pisces.js?v=7.3.0"></script>

<script src="/js/next-boot.js?v=7.3.0"></script>



  





















  

  
    
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    
  

  

  

</body>
</html>
