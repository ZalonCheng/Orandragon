<!DOCTYPE html>





<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.3.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2">
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.3.0',
    exturl: false,
    sidebar: {"position":"right","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    }
  };
</script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Orandragon&#39;s Blog">
<meta property="og:url" content="http://yoursite.com/page/21/index.html">
<meta property="og:site_name" content="Orandragon&#39;s Blog">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Orandragon&#39;s Blog">
  <link rel="canonical" href="http://yoursite.com/page/21/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Orandragon's Blog</title>
  <meta name="generator" content="Hexo 3.9.0">
  








  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Orandragon's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            
  <div id="posts" class="posts-expand">
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/12/22/EE5904 Neural Network/3.SOM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Orange+Dragon">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Orandragon's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2020/12/22/EE5904 Neural Network/3.SOM/" class="post-title-link" itemprop="url">Untitled</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2020-12-22 13:45:47" itemprop="dateCreated datePublished" datetime="2020-12-22T13:45:47+08:00">2020-12-22</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-04-20 23:12:22" itemprop="dateModified" datetime="2019-04-20T23:12:22+08:00">2019-04-20</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/EE5904-Neural-Network/" itemprop="url" rel="index"><span itemprop="name">EE5904 Neural Network</span></a></span>

                
                
              
            </span>
          

          
            <span id="/2020/12/22/EE5904 Neural Network/3.SOM/" class="post-meta-item leancloud_visitors" data-flag-title="" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
        
      
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2020/12/22/EE5904 Neural Network/3.SOM/#comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/2020/12/22/EE5904 Neural Network/3.SOM/" itemprop="commentCount"></span></a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="self-organizing-maps">Self-Organizing Maps</h1>
<h2 id="introduction">1. Introduction</h2>
<p>Learning is a process by which the free parameters of a neural network are adapted through a process of stimulation by the environment in which the network is embedded.</p>
<p>The topology-conserving mapping can be achieved by SOMs. The network is two layers network. There are only input layer and output layer without hidden layer. There is no hidden layer.</p>
<p>The location of neurons in the output layer is important.</p>
<h2 id="architecture">2. Architecture</h2>
<p>For each output neuron j, there are a set of synaptic weights <span class="math inline">\(w_{ji}\)</span> connected from all input neurons</p>
<h3 id="randomly-initialize-all-the-weights.">1. Randomly initialize all the weights.</h3>
<h3 id="select-input-vector-xx_1x_2dotsmx_n-from-the-training-set">2. Select input vector <span class="math inline">\(x=[x_1,x_2,\dotsm,x_n]\)</span> from the training set</h3>
<p>It can be done by choosing randomly from the training set or one by one in a deterministic manner like that for sequential learning.</p>
<h3 id="compare-x-with-weights-w_j-for-each-neuron-j-to-determine-winner">3. Compare x with weights <span class="math inline">\(w_j\)</span> for each neuron j to determine winner</h3>
<p>Find the best-matching neuron w(x), usually the neuron whose weight vector has smallest Euclidean distance from the input vector. <span class="math display">\[
i(x)=\arg \min _j||x-w_j||
\]</span> The winning neuron is that which is in some sense closet to the input sector.</p>
<h3 id="update-winner-so-that-it-becomes-more-like-x-together-with-the-winners-neighbor">4. Update winner so that it becomes more like x, together with the winner's neighbor</h3>
<p>The typical choice of topological neighborhood function <span class="math display">\[
h_{j,i(x)}=\exp (-\frac{d_{j,i}^2}{2\sigma^2})
\]</span> where <span class="math display">\[
d_{j,i}=\sqrt{(l-n)^2+(m-k)^2}
\]</span> if the position of the neuron is described by the index of the neuron in the matrix (2-d lattice)</p>
<h3 id="adjust-parameters-learning-rate-neighborhood-function">5. Adjust parameters: learning rate &amp; neighborhood function</h3>
<p>Another unique feature of the SOM algorithm is that the size of the topological neighborhood shrinks with time. <span class="math display">\[
\sigma(n)=\sigma_0\exp (-\frac{n}{\tau_1})
\]</span> where <span class="math inline">\(\tau_1\)</span> is a time-constant to control the decay rate of the effective width.</p>
<p>Time-varying neighborhood function <span class="math display">\[
h_{j,i(x)}=\exp (-\frac{d_{j,i}^2}{2\sigma(n)^2})
\]</span> It means that the influence of the winner on its neighbors decrease with time.</p>
<p>Parameters are adapted by <span class="math display">\[
w_j(n+1)=w_j(n)+\eta(n)h_{j,i(x)}(n)(x-w_j(n))
\]</span> That means the weight is the weighted average of the input and the current weight.</p>
<p>The synaptic weight vector <span class="math inline">\(w_i\)</span> of winning neuron i moves to the input vector x.</p>
<p>All the neurons in the neighborhood of the winning neuron also move to the input vector.</p>
<p>The learning-rate parameter <span class="math inline">\(\eta\)</span> should also decrease with time <span class="math display">\[
\eta(n)=\eta_0 \exp (-\frac{n}{\tau_2})
\]</span></p>
<h3 id="repeat-step-2-until-the-map-has-converged.">6. Repeat step 2 until the map has converged.</h3>
<h2 id="two-phases-of-the-adaptive-process">3. Two phases of the adaptive process</h2>
<h3 id="the-first-phase">1. The First Phase</h3>
<p>An ordering or self-organizing phase</p>
<p>The ordering phase may take as many as 1000 iterations and possibly more.</p>
<p>The learning rate should begin with a value close to 0.1; there after it should decrease gradually, but remain above 0.01. <span class="math display">\[
\eta_0=0.1\quad \tau_2=T\quad \eta(n)=0.1\exp(-\frac{n}{T})
\]</span> T is the total number of iterations for the first phase.</p>
<p>The neighborhood function should initially include almost all neurons, and then shrink with time. We may set the initial size of the width equal to the “radius” of the lattice. For instance if the size of the lattice is <span class="math inline">\(M\times N\)</span>, then the initial width can be set as <span class="math display">\[
\sigma_0=\frac{\sqrt{M^2+N^2}}{2}
\]</span> The time constant can be chosen as <span class="math display">\[
\tau_1=\frac{T}{\log (\sigma_0)}
\]</span> Then at the end, <span class="math inline">\(\sigma(T)=1\)</span></p>
<h3 id="the-second-phase">2. The Second Phase</h3>
<p>Convergence Phase</p>
<p>The second phase is needed to fine tune the feature map.</p>
<p>As a general rule, the number of iterations must be at least 500 times the number of neurons in the network. Thus, the convergence phase may have to go on for thousands and possibly tens of thousands of iterations.</p>
<p>For a good statistical accuracy, the learning parameter <span class="math inline">\(\eta(n)\)</span> should be kept at a small value, on the order of 0.01.</p>
<p>In many applications, the second phase is not needed if convergence of the parameters are not critical.</p>
<h2 id="summary">4. Summary</h2>
<p>For n-dimensional input space and m output neurons</p>
<ol type="1">
<li>Randomly initialize the weight vector <span class="math inline">\(w_i\)</span> for neuron</li>
<li>Sampling: choose an input vector x from the training set</li>
<li>Determine winner neuron k</li>
<li>Update all weight vectors of all neurons (include itself) in the neighborhood of the winning neuron</li>
<li>If convergence criterion met, Stop</li>
</ol>
<p>Example</p>
<figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">X = <span class="built_in">randn</span>(<span class="number">800</span>,<span class="number">2</span>);</span><br><span class="line">s2 = sum(X.^<span class="number">2</span>,<span class="number">2</span>);</span><br><span class="line">trainX = (X.*<span class="built_in">repmat</span>(<span class="number">1</span>*(<span class="built_in">gammainc</span>(s2/<span class="number">2</span>,<span class="number">1</span>).^(<span class="number">1</span>/<span class="number">2</span>))./<span class="built_in">sqrt</span>(s2),<span class="number">1</span>,<span class="number">2</span>))';</span><br><span class="line"><span class="built_in">plot</span>(trainX(<span class="number">1</span>,:),trainX(<span class="number">2</span>,:),<span class="string">'+r'</span>); </span><br><span class="line">axis equal</span><br><span class="line"></span><br><span class="line">total_step_number = <span class="number">400000</span>;</span><br><span class="line">W = <span class="built_in">rand</span>(<span class="number">2</span>,<span class="number">64</span>); <span class="comment">%  row number (x-1)/8+1, column number (x-1)%8+1</span></span><br><span class="line">eta_0=<span class="number">0.1</span>; eta = eta_0; </span><br><span class="line">sigma_0 = <span class="number">4</span>; sigma = sigma_0;</span><br><span class="line"></span><br><span class="line">tau = <span class="number">8</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:(total_step_number/<span class="built_in">size</span>(trainX,<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">for</span> xx=trainX</span><br><span class="line">        [~,winner_index] = <span class="built_in">min</span>(vecnorm(xx-W));</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> nn=<span class="number">1</span>:<span class="built_in">size</span>(W,<span class="number">2</span>) <span class="comment">%update neighbors</span></span><br><span class="line">            d_ji=norm([<span class="built_in">fix</span>((nn<span class="number">-1</span>)/<span class="number">8</span>+<span class="number">1</span>);<span class="built_in">mod</span>((nn<span class="number">-1</span>),<span class="number">8</span>)+<span class="number">1</span>]- ...</span><br><span class="line">                [<span class="built_in">fix</span>((winner_index<span class="number">-1</span>)/<span class="number">8</span>+<span class="number">1</span>);<span class="built_in">mod</span>((winner_index<span class="number">-1</span>),<span class="number">8</span>)+<span class="number">1</span>]);</span><br><span class="line">        </span><br><span class="line">            h_ji=<span class="built_in">exp</span>(-(d_ji^<span class="number">2</span>/(<span class="number">2</span>*sigma^<span class="number">2</span>)));</span><br><span class="line">            W(:,nn) =  W(:,nn) + eta*h_ji*(xx-W(:,nn));</span><br><span class="line">        <span class="keyword">end</span></span><br><span class="line">        eta = eta_0 * <span class="built_in">exp</span>(-(<span class="built_in">i</span>/(total_step_number/<span class="built_in">size</span>(trainX,<span class="number">2</span>))));</span><br><span class="line">        sigma = sigma_0 * <span class="built_in">exp</span>(-(<span class="built_in">i</span>/tau));</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="built_in">figure</span>(<span class="number">1</span>)</span><br><span class="line"><span class="built_in">hold</span> on</span><br><span class="line">axis equal</span><br><span class="line"><span class="built_in">plot</span>(trainX(<span class="number">1</span>,:),trainX(<span class="number">2</span>,:),<span class="string">'+r'</span>);</span><br><span class="line"><span class="built_in">plot</span>(W(<span class="number">1</span>,:),W(<span class="number">2</span>,:),<span class="string">'*b'</span>)</span><br><span class="line"></span><br><span class="line">result = <span class="built_in">zeros</span>(<span class="number">2</span>,<span class="number">8</span>,<span class="number">8</span>);</span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="number">64</span></span><br><span class="line">    result(:,<span class="built_in">fix</span>((<span class="built_in">i</span><span class="number">-1</span>)/<span class="number">8</span>+<span class="number">1</span>),<span class="built_in">mod</span>((<span class="built_in">i</span><span class="number">-1</span>),<span class="number">8</span>)+<span class="number">1</span>) = W(:,<span class="built_in">i</span>);</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="number">8</span></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">j</span>=<span class="number">1</span>:<span class="number">7</span></span><br><span class="line">       <span class="built_in">plot</span>([result(<span class="number">1</span>,<span class="built_in">i</span>,<span class="built_in">j</span>),result(<span class="number">1</span>,<span class="built_in">i</span>,<span class="built_in">j</span>+<span class="number">1</span>)],[result(<span class="number">2</span>,<span class="built_in">i</span>,<span class="built_in">j</span>),result(<span class="number">2</span>,<span class="built_in">i</span>,<span class="built_in">j</span>+<span class="number">1</span>)],<span class="string">'*-'</span>);</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="number">7</span></span><br><span class="line">    <span class="keyword">for</span> <span class="built_in">j</span>=<span class="number">1</span>:<span class="number">8</span></span><br><span class="line">       <span class="built_in">plot</span>([result(<span class="number">1</span>,<span class="built_in">i</span>,<span class="built_in">j</span>),result(<span class="number">1</span>,<span class="built_in">i</span>+<span class="number">1</span>,<span class="built_in">j</span>)],[result(<span class="number">2</span>,<span class="built_in">i</span>,<span class="built_in">j</span>),result(<span class="number">2</span>,<span class="built_in">i</span>+<span class="number">1</span>,<span class="built_in">j</span>)],<span class="string">'*-'</span>);</span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<figure>
<img src="assets/1555772820715.png" alt="Figure."><figcaption aria-hidden="true">Figure.</figcaption>
</figure>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/12/22/EE5904 Neural Network/2.RBFN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Orange+Dragon">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Orandragon's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2020/12/22/EE5904 Neural Network/2.RBFN/" class="post-title-link" itemprop="url">Untitled</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2020-12-22 13:45:47" itemprop="dateCreated datePublished" datetime="2020-12-22T13:45:47+08:00">2020-12-22</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-04-20 22:15:06" itemprop="dateModified" datetime="2019-04-20T22:15:06+08:00">2019-04-20</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/EE5904-Neural-Network/" itemprop="url" rel="index"><span itemprop="name">EE5904 Neural Network</span></a></span>

                
                
              
            </span>
          

          
            <span id="/2020/12/22/EE5904 Neural Network/2.RBFN/" class="post-meta-item leancloud_visitors" data-flag-title="" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
        
      
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2020/12/22/EE5904 Neural Network/2.RBFN/#comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/2020/12/22/EE5904 Neural Network/2.RBFN/" itemprop="commentCount"></span></a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="radial-basis-function-networks">Radial-Basis Function Networks</h1>
<h2 id="introduction">1. Introduction</h2>
<p>The activation of a hidden unit is determined by the distance between the input vector and a prototype vector, the center. <span class="math display">\[
\varphi(||x-c||)=\varphi(r)
\]</span> Given a set of N data points and a set of N target values.</p>
<p>The goal is to find a function <span class="math inline">\(f(x)\)</span> that pass through all the training data points.</p>
<p>There are infinite number of solutions and RBFN is just one solution.</p>
<p>For the RBFN, we have <span class="math display">\[
f(x)=\sum_{i=1}^N w_i\varphi(||x-x_i||)
\]</span></p>
<h2 id="how-to-determine-the-weights">2. How to Determine the Weights</h2>
<p>It becomes a typical algebraic problem. <span class="math display">\[
f(x_j)=\sum_{i=1}^{N}w_i\varphi(||x_j-x_i||)=d_j
\]</span> Then we can expand the equation to a matrix form <span class="math display">\[
\begin{bmatrix}
\varphi_{11}  &amp; \varphi_{12} &amp; \dotsm &amp; \varphi_{1N}\\
\varphi_{21}  &amp; \varphi_{22} &amp; \dotsm &amp; \varphi_{2N}\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
\varphi_{N1}  &amp; \varphi_{N2} &amp; \dotsm &amp; \varphi_{NN}\\
\end{bmatrix}
\begin{bmatrix}
w_1\\w_2\\\vdots\\w_N
\end{bmatrix}=
\begin{bmatrix}
d_1\\d_2\\\vdots\\d_N
\end{bmatrix}
\]</span> Then we can have <span class="math display">\[
w=\Phi^{-1}d
\]</span> Once we have the weight, we have function that represents a continuous differentiable surface that pass exactly through each data point.</p>
<h2 id="commonly-used-radial-basis-functions">3. Commonly Used Radial Basis Functions</h2>
<p>Gaussian Function <span class="math display">\[
\varphi(r)=\exp (-\frac{r^2}{2\sigma^2})
\]</span> Inverse Multi-Quadric Function <span class="math display">\[
\varphi(r)=(r^2+\sigma^2)^{-0.5}
\]</span> But the network perform poorly for the noisy data for the perfect tracking and large date sets the network will be very cost.</p>
<p>To summarize,</p>
<ol type="1">
<li>For a given set containing N points</li>
<li>Choose a RBF function <span class="math inline">\(\varphi\)</span></li>
<li>Calculate <span class="math inline">\(\varphi_{ji}=\varphi(||x_j-x_i||)\)</span></li>
<li>Obtain the interpolation matrix <span class="math inline">\(\Phi\)</span></li>
<li>Solve the linear equation <span class="math inline">\(\Phi w=d\)</span></li>
<li>Get the Unique solution <span class="math inline">\(w\)</span></li>
</ol>
<h2 id="train-the-network">4. Train the Network</h2>
<p>However, the network requires one hidden unit for each training data pattern, and so for large datasets the network will become very costly to evaluate. Therefore, it is not necessary to use the sampling points as the centers. We choose some sampling points <span class="math inline">\(\mu_i\)</span> and then we have <span class="math display">\[
f(x)=\sum_{i=1}^Mw_i\varphi_i(||x-\mu_i||)+b\\
\]</span></p>
<p>Let <span class="math inline">\(\varphi_0=1\)</span>, then the bias can be included in the vector. We have <span class="math display">\[
f(x)=\sum_{i=0}^Mw_i\varphi_i(||x-\mu_i||)\\
\]</span> Then the centers, spread parameters, and the weights can be learned by training as that for MLP.</p>
<p>For the case of Gaussian basis functions, we have <span class="math display">\[
\varphi_i(||x-\mu_i||)=\exp(-\frac{||x-\mu_i||^2}{2\sigma_i^2})
\]</span> In which we have basis center <span class="math inline">\(\mu_i\)</span> and standard deviations <span class="math inline">\(\sigma_i\)</span>.</p>
<p>The aim is to develop a process for finding the appropriate values of the weights <span class="math inline">\(w_i\)</span> and the centers and spreads <span class="math inline">\(\mu_i\)</span> and <span class="math inline">\(\sigma_i\)</span> .</p>
<p>We hope to find the parameters <span class="math inline">\(w_i,\mu_i,\sigma_i\)</span> such that the cost function <span class="math display">\[
E(w)=\sum_{i=1}^N(d(i)-y(i))^2
\]</span> is minimized.</p>
<p>There are two stages to tune the parameters.</p>
<p>Stage 1,</p>
<p>Use unsupervised learning methods to find center <span class="math inline">\(\mu_i\)</span> and spread <span class="math inline">\(\sigma_i\)</span></p>
<p>Stage 2,</p>
<p>Use supervised learning methods to find weight values between hidden and output units.</p>
<h2 id="finding-the-output-weights">5. Finding the Output Weights</h2>
<p>Given the hidden unit activations <span class="math inline">\(\varphi(x,\mu_i,\sigma_i)\)</span> is fixed while we determine the output weight <span class="math inline">\(w_i\)</span> <span class="math display">\[
\begin{bmatrix}
\varphi_0(x_1) &amp; \varphi_1(x_1) &amp; \dotsm &amp; \varphi_M(x_1)\\
\varphi_0(x_2) &amp; \varphi_1(x_2) &amp; \dotsm &amp; \varphi_M(x_2)\\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
\varphi_0(x_N) &amp; \varphi_1(x_N) &amp; \dotsm &amp; \varphi_M(x_N)
\end{bmatrix}
\begin{bmatrix}
w_0\\w_1\\\vdots\\w_M
\end{bmatrix}=
\begin{bmatrix}
d_1\\d_2\\\vdots\\d_N
\end{bmatrix}
\]</span> That is <span class="math inline">\(\Phi w=d\)</span></p>
<p>We can solve this problem by linear least squares <span class="math display">\[
w=(\Phi^T\Phi)^{-1}\Phi^Td
\]</span></p>
<h2 id="finding-the-center-and-spread">6. Finding the Center and Spread</h2>
<p>There are numerous approaches in the literature to find the center and spread for the first stage.</p>
<p>The simplest and quickest approach to setting the RBF parameters is to take their centers as fixed at M points selected at random from the N data points.</p>
<p>Specially, we can use RBFs centered at <span class="math inline">\(\mu_i\)</span> defined by <span class="math display">\[
\varphi_i(x)=\exp (-\frac{M}{d_{max}^2}||x-\mu_i||^2)
\]</span> That means the spread is <span class="math display">\[
\sigma_i=\frac{d_{max}}{\sqrt{2M}}
\]</span> We can also use K-means clustering</p>
<p>K-means clustering,</p>
<ol type="1">
<li>Initialization. Choose random values for the initial centers.</li>
<li>Sampling. Draw a sample vector from the training set.</li>
<li>Assignment. Compute the distance from the vector to each center and assign the vector to the closet center.</li>
<li>Updating. After all vectors are assigned to a center. Calculate the new center by the assigned vectors.</li>
<li>Do the previous steps until converged.</li>
</ol>
<h2 id="supervised-rbf-network-training">7. Supervised RBF Network Training</h2>
<p>The obvious approach is to perform gradient decent on a sum squared output error function as we did for MLPs. <span class="math display">\[
E=\frac{1}{2}\sum_{j=1}^N(e_j)^2\\
e_j=d_j-y(x_j)=d_j-\sum_{i=0}^Mw_i\varphi_i(x_j,\mu_i,\sigma_i)
\]</span> Then we can use the gradient decent method, <span class="math display">\[
\Delta w=-\eta g(n)
\]</span></p>
<h2 id="regularization-theory-for-rbf-networks">8. Regularization Theory for RBF Networks</h2>
<p>Cost function <span class="math display">\[
F(w)=\frac{1}{2}\sum_{i=1}^N(y(i)-d(i))^2+\frac{1}{2}\lambda||w||^2=\frac{1}{2}(\Phi w-d)^T(\Phi w-d)+\frac{1}{2}\lambda w^Tw
\]</span> We hope to get the optimal solution for w <span class="math display">\[
\frac{\partial F(w)}{\partial w}=0
\]</span> Then we have <span class="math display">\[
w=(\Phi^T\Phi+\lambda I)^{-1}\Phi^Td
\]</span></p>
<p>where <span class="math inline">\(\lambda\)</span> is the regularization factor.</p>
<p>RBFN can also be used in classification problem.</p>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/20/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/20/">20</a><span class="page-number current">21</span><a class="page-number" href="/page/22/">22</a><span class="space">&hellip;</span><a class="page-number" href="/page/36/">36</a><a class="extend next" rel="next" href="/page/22/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>


          </div>
          

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc" data-target="post-toc-wrap">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview" data-target="site-overview-wrap">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Orange+Dragon</p>
  <div class="site-description" itemprop="description"></div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">71</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span>
        </a>
      </div>
    
  </nav>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:zilongcheng@u.nus.edu" title="E-Mail &rarr; mailto:zilongcheng@u.nus.edu" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
    
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Orange+Dragon</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.3.0</div>

        












        
      </div>
    </footer>
  </div>

  
    
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/jquery/index.js?v=3.4.1"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.3.0"></script><script src="/js/motion.js?v=7.3.0"></script>
<script src="/js/schemes/pisces.js?v=7.3.0"></script>

<script src="/js/next-boot.js?v=7.3.0"></script>



  





















  

  
    
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    
  

  

  


<script>
NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(item => {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'k1NFV6E2jjtcuFpWbPUwvs04-MdYXbMMI',
    appKey: 'oCso3hdINWUXi0EtP7BsCUoY',
    placeholder: 'Just go go',
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: true,
    lang: '' || 'zh-cn',
    path: location.pathname
  });
}, window.Valine);
</script>

</body>
</html>
