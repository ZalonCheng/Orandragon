<!DOCTYPE html>





<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.3.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2">
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.3.0',
    exturl: false,
    sidebar: {"position":"right","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    }
  };
</script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Orandragon&#39;s Blog">
<meta property="og:url" content="http://yoursite.com/page/23/index.html">
<meta property="og:site_name" content="Orandragon&#39;s Blog">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Orandragon&#39;s Blog">
  <link rel="canonical" href="http://yoursite.com/page/23/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Orandragon's Blog</title>
  <meta name="generator" content="Hexo 3.9.0">
  








  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Orandragon's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            
  <div id="posts" class="posts-expand">
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/12/22/EE5907 Pattern Recognition/10.Gaussian Mixture Model and Boosting/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Orange+Dragon">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Orandragon's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2020/12/22/EE5907 Pattern Recognition/10.Gaussian Mixture Model and Boosting/" class="post-title-link" itemprop="url">Untitled</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2020-12-22 13:46:13" itemprop="dateCreated datePublished" datetime="2020-12-22T13:46:13+08:00">2020-12-22</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-04-27 17:14:06" itemprop="dateModified" datetime="2019-04-27T17:14:06+08:00">2019-04-27</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/EE5907-Pattern-Recognition/" itemprop="url" rel="index"><span itemprop="name">EE5907 Pattern Recognition</span></a></span>

                
                
              
            </span>
          

          
            <span id="/2020/12/22/EE5907 Pattern Recognition/10.Gaussian Mixture Model and Boosting/" class="post-meta-item leancloud_visitors" data-flag-title="" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
        
      
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2020/12/22/EE5907 Pattern Recognition/10.Gaussian Mixture Model and Boosting/#comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/2020/12/22/EE5907 Pattern Recognition/10.Gaussian Mixture Model and Boosting/" itemprop="commentCount"></span></a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="gaussian-mixture-model-and-boosting">Gaussian Mixture Model and Boosting</h1>
<p>A generative model learns the joint probability distribution <span class="math inline">\(p(x,y)\)</span> and a discriminative model learns the conditional probability distribution <span class="math inline">\(p(x|y)\)</span></p>
<h2 id="gaussian-mixture-model-gmm">1. Gaussian Mixture Model (GMM)</h2>
<p>GMM: the weighted sum of a number of Gaussians where the weights are determined by a distribution <span class="math inline">\(\pi\)</span>. <span class="math display">\[
\begin{array}{lll}
p(x)&amp;=&amp;\pi_1 N(x|\mu_1,\Sigma_1)+\pi_2 N(x|\mu_2,\Sigma_2)+\dotsm+\pi_K N(x|\mu_K,\Sigma_K)\\
&amp;=&amp; \sum_{i=1}^K \pi_iN(x|\mu_i,\Sigma_i)
\end{array}
\]</span> The ==Expectation-maximization algorithm== (EM) is a method for finding maximum likelihood (or maximum a posteriori) estimate of parameters in statistical model, where the model depends on unobserved latent variables.</p>
<p>EM is a iterative method which alternates between performing and Expectation (E) Step and Maximization (M) Step.</p>
<p>E-Step: Computes the expectation of the log-likelihood evaluated using the current estimated distributions for the latent variables based on the parameters inferred from previous step.</p>
<p>M-Step: Computes parameters maximizing the expected log-likelihood from the E-Step. These parameters are then used to determine the distribution of the latent variables in the next E-Step.</p>
<p>It seems like a K-means algorithm.</p>
<p>==Example==</p>
<p>Let events be ''grades in a class'' <span class="math display">\[
P(A)=0.5\\p(B)=\mu\\P(C)=2\mu\\P(D)=0.5-3\mu\\P(a,b,c,d|\mu)=K(0.5)^a \mu^b (2\mu)^c (0.5-3\mu)^d
\]</span> We hope to get the max like <span class="math inline">\(\mu\)</span> <span class="math display">\[
\log P=\log K+a\log0.5 + b\log \mu + c \log(2\mu)+d\log (0.5-3\mu)\\
\frac{\partial \log P}{\partial \mu}=\frac{b}{\mu}+\frac{c}{\mu}-\frac{3d}{0.5-3\mu}=0\\
\mu=\frac{b+c}{6(b+c+d)}
\]</span> If the class got A=14,B=6,C=9,D=10, then we have <span class="math inline">\(\mu=\frac{1}{10}\)</span></p>
<p>If we have a latent variable in the problem, A+B=h, C=c, D=d</p>
<p>Then the probability is <span class="math display">\[
P(h,c,d|\mu,b)=K(0.5)^{h-b}\mu^{b}(2\mu)^c (0.5-3\mu)^d\\
\log P=\log K+(h-b)\log 0.5+b\log \mu + c \log(2\mu)+d\log (0.5-3\mu)\\
\]</span> E-Step</p>
<p>If we know <span class="math inline">\(\mu\)</span>, then we can get the expected b <span class="math display">\[
E_\mu(b)=\frac{\mu}{0.5+\mu}h
\]</span> M-Step</p>
<p>If we know b, then we can get the optimal <span class="math inline">\(\mu\)</span> <span class="math display">\[
\mu_b=\frac{E_\mu(b)+c}{6(E_\mu(b)+c+d)}
\]</span> Then if we iterate between E-Step and M-Step, the values will be converged to a local minimum.</p>
<p>Then we can use this algorithm to solve the GMM problems</p>
<p>We define <span class="math display">\[
\pi_i=p(w_i)\quad \sum_i \pi_i=1\\
z_i=p(w_i|x)=\frac{p(w_i)p(x|w_i)}{\sum_{j=1}^Kp(w_j)p(x|w_j)}\\
z_k^n=p(w_k|x_n)=\frac{\pi_kN(x_n|\mu_k,\Sigma_k)}{\sum_{j=1}^K\pi_jN(x_n|\mu_j,\Sigma_j)}
\]</span> Then the hidden variables <span class="math inline">\(z_k^n\)</span> indicating which component <span class="math inline">\(k\)</span> the datum <span class="math inline">\(n\)</span> is sampled from</p>
<p>Identify the likelihood <span class="math display">\[
P(x_1,\dotsm,x_N|\pi,\mu)=\prod_{n=1}^NP(x_n|\pi,\mu)\\
=\prod_{n=1}^N \sum_{k=1}^K P(x_n|w_k,\mu_k)P(\omega_k)\\
\log P =\sum_{n=1}^N\log \left[\sum_{k=1}^K P(x_n|w_k,\mu_k)P(\omega_k)\right]
\]</span> Set the partials to zero, we have (Similarly for the other parameters) <span class="math display">\[
\mu_k=\frac{\sum_{n=1}^Nz_k^nx_n}{\sum_{n=1}^Nz_k^n}\\
\Sigma_k=\frac{\sum_{n=1}^N z_k^n (x_n-\mu_k)(x_n-\mu_k)^T}{\sum_{n=1}^N z_k^n}\\
\pi_k=\frac{\sum_{n=1}^Nz_k^n}{N}
\]</span> Therefore,</p>
<p>E-Step: <span class="math display">\[
z_k^n=p(w_k|x_n)=\frac{\pi_kN(x_n|\mu_k,\Sigma_k)}{\sum_{j=1}^K\pi_jN(x_n|\mu_j,\Sigma_j)}
\]</span> M-Step: <span class="math display">\[
\mu_k=\frac{\sum_{n=1}^Nz_k^nx_n}{\sum_{n=1}^Nz_k^n}\\
\Sigma_k=\frac{\sum_{n=1}^N z_k^n (x_n-\mu_k)(x_n-\mu_k)^T}{\sum_{n=1}^N z_k^n}\\
\pi_k=\frac{\sum_{n=1}^Nz_k^n}{N}
\]</span></p>
<h2 id="boosting">2. Boosting</h2>
<p>Easy to implement, not requires external optimization tools</p>
<p>Boosting fits the additive model <span class="math display">\[
F(x)=f_1(x)+f_2(x)+f_3(x)+\dotsm
\]</span> by minimizing the exponential loss <span class="math display">\[
J(F)=\sum_{t=1}^Ne^{-y_tF(x_t)}
\]</span> Sequential Procedure. At each step m we add <span class="math display">\[
F(x)\leftarrow F(x)+f_m(x)
\]</span> to minimize the residual loss <span class="math display">\[
(\phi_m)=\arg\min_{\phi}\sum_{t=1}^N J(y_t,F(x_t)+f(x_t;\phi))
\]</span> At each iteration, we choose <span class="math inline">\(f_m(x)\)</span> that minimizes the cost <span class="math display">\[
J(F+f_m)=\sum_{t=1}^Ne^{-y_t(F(x_t)+f_m(x_t))}
\]</span> Instead of doing exact optimization, gentle Boosting minimizes the approximation of the error <span class="math display">\[
J(F)\propto \sum_{t=1}^Ne^{-y_tF(x_t)}(y_t-f_m(x_t))^2
\]</span></p>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/12/22/EE5907 Pattern Recognition/1. Probability/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Orange+Dragon">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Orandragon's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2020/12/22/EE5907 Pattern Recognition/1. Probability/" class="post-title-link" itemprop="url">Untitled</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2020-12-22 13:46:13" itemprop="dateCreated datePublished" datetime="2020-12-22T13:46:13+08:00">2020-12-22</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-05-03 20:16:26" itemprop="dateModified" datetime="2019-05-03T20:16:26+08:00">2019-05-03</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/EE5907-Pattern-Recognition/" itemprop="url" rel="index"><span itemprop="name">EE5907 Pattern Recognition</span></a></span>

                
                
              
            </span>
          

          
            <span id="/2020/12/22/EE5907 Pattern Recognition/1. Probability/" class="post-meta-item leancloud_visitors" data-flag-title="" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
        
      
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2020/12/22/EE5907 Pattern Recognition/1. Probability/#comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/2020/12/22/EE5907 Pattern Recognition/1. Probability/" itemprop="commentCount"></span></a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="types-of-machine-learning">1. Types of Machine Learning</h2>
<p>Supervised Learning: Great if we know what we what to predict</p>
<p>Unsupervised learning: Great if we want to discover something new</p>
<h2 id="design-cycle">2. Design Cycle</h2>
<p>Data collection</p>
<p>Preprocessing: Image enhancement, remove background, segmentation</p>
<p>Divide data into training and test sets (Feature Extraction, Train classifier)</p>
<p>Re-visit previous steps if performance unsatisfactory</p>
<h2 id="probability-review">3. Probability Review</h2>
<p>A random variable x is a quantity that is uncertain.</p>
<p>If x is discrete, then the probability of x <span class="math inline">\(p(x)\)</span> is probability mass function (pmf)</p>
<p>if x is continuous, then the probability of x <span class="math inline">\(p(x)\)</span> is probability distribution function (pdf)</p>
<p><span class="math inline">\(p(x,y)\)</span> is joint probability distribution of x and y. we have <span class="math display">\[
p(y)=\int_x p(x,y)dx\quad or\quad p(y)=\sum_xp(x,y)
\]</span> This is called marginalization.</p>
<p>Suppose we observe y to be <span class="math inline">\(y_1\)</span> , then <span class="math inline">\(p(x|y=y_1)\)</span> is how likely x will take on various values given this observation, that read as conditional probability of x given y is equal to <span class="math inline">\(y_1\)</span> . We have <span class="math display">\[
p(x|y)=\frac{p(x,y)}{p(y)}=\frac{p(y|x)p(x)}{\int_xp(x,y)dx}=\frac{p(y|x)p(x)}{\int_xp(y|x)p(x)dx}
\]</span></p>
<h2 id="discrete-distributions">4. Discrete Distributions</h2>
<p>==Bernoulli Distribution== <span class="math display">\[
P(x)=\lambda^x(1-\lambda)^{1-x}
\]</span> where x=0, 1</p>
<p>Bernoulli Distribution describes situation where only two possible outcomes x=0, 1</p>
<p>==Categorical Distribution== <span class="math display">\[
P(x=k)=\lambda_k
\]</span> Categorical Distribution describes situation where K possible outcomes</p>
<p>==Binomial Distribution==</p>
<p>The binomial distribution with parameters n and p is the discrete probability distribution of the number of successes in a sequence of n independent experiments, each asking a yes–no question, and each with its own boolean-valued outcome: a random variable containing a single bit of information: success/yes/true/one (with probability p) or failure/no/false/zero (with probability q = 1 − p). <span class="math display">\[
P(x=k)=\left(
\begin{array}{c}
n\\
k
\end{array}
\right)p^{k}(1-p)^k
\]</span> ==Multinomial Distribution==</p>
<p>The multinomial distribution is a generalization of the binomial distribution. For example, it models the probability of counts for rolling a k-sided die n times. For n independent trials each of which leads to a success for exactly one of k categories, with each category having a given fixed success probability, the multinomial distribution gives the probability of any particular combination of numbers of successes for the various categories. <span class="math display">\[
\begin{array}{ccc}
P(X_1=x_1,X_2=x_2,X_3=x_3\dotsm)=\frac{n!}{x_1!x_2!\dotsm x_k!}p_1^{x_1}p_2^{x_2}\dotsm p_k^{x_k}\quad when \sum_{i=1}^kx_i=n\\
otherwise\quad P(X_1=x_1,X_2=x_2,X_3=x_3\dotsm)=0
\end{array}
\]</span> ==Poisson Distribution==</p>
<p>The Poisson distribution is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time or space if these events occur with a known constant rate and independently of the time since the last event. <span class="math display">\[
P(x=k)=e^{-\lambda}\frac{\lambda^k}{k!}
\]</span></p>
<h2 id="continuous-distributions">5. Continuous Distributions</h2>
<p>==Gaussian Distribution (Normal Distribution)==</p>
<p>It states that averages of samples of observations of random variables independently drawn from independent distributions converge in distribution to the normal, that is, they become normally distributed when the number of observations is sufficiently large <span class="math display">\[
P(x|\mu,\sigma^2)=\frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}
\]</span> ==Exponential Distribution==</p>
<p>The exponential distribution is the probability distribution that describes the time between events in a Poisson point process. <span class="math display">\[
P(X=x)=\lambda e^{-\lambda x}
\]</span> ==Gamma Distribution==</p>
<p>The gamma distribution is a two-parameter family of continuous probability distributions. The exponential distribution, Erlang distribution, and chi-squared distribution are special cases of the gamma distribution. <span class="math display">\[
P(x|\alpha,\beta)=\frac{\beta^\alpha x^{\alpha-1}e^{-\beta x}}{\Gamma(\alpha)}
\]</span> where <span class="math inline">\(\Gamma(\alpha)\)</span> is the Gamma Function.</p>
<p>==Beta Distribution==</p>
<p>The beta distribution is a family of continuous probability distributions defined on the interval [0, 1] parametrized by two positive shape parameters, denoted by α and β, that appear as exponents of the random variable and control the shape of the distribution. It is a special case of the Dirichlet distribution.</p>
<p>The beta distribution has been applied to model the behavior of random variables limited to intervals of finite length in a wide variety of disciplines.</p>
<p>In Bayesian inference, the beta distribution is the conjugate prior probability distribution for the Bernoulli, binomial, negative binomial and geometric distributions. For example, the beta distribution can be used in Bayesian analysis to describe initial knowledge concerning probability of success such as the probability that a space vehicle will successfully complete a specified mission. The beta distribution is a suitable model for the random behavior of percentages and proportions. <span class="math display">\[
P(x|\alpha,\beta)=\frac{1}{B(\alpha,\beta)}x^{\alpha-1}(1-x)^{\beta-1}
\]</span> where <span class="math inline">\(B(\alpha,\beta)\)</span> is Beta Function defined by <span class="math display">\[
B(\alpha,\beta)=\frac{\Gamma(\alpha)\Gamma(\beta)}{\Gamma(\alpha+\beta)}
\]</span> ==Dirichlet Distribution==</p>
<p>the Dirichlet distribution often denoted as Dir(<span class="math inline">\(\alpha\)</span>) is a family of continuous multivariate probability distributions parameterized by a vector <span class="math inline">\(\alpha\)</span> of positive reals. It is a multivariate generalization of the beta distribution, hence its alternative name of Multivariate Beta distribution (MBD). <span class="math display">\[
P(x|\alpha)=\frac{1}{B(\alpha)}\prod_{i=1}^Kx_i^{\alpha_i-1}
\]</span></p>
<h2 id="bayes-rule">5. Bayes' Rule</h2>
<p>For continuous <span class="math display">\[
p(x,y)=p(x)p(y|x)=p(y)p(x|y) \implies \\
p(y|x)=\frac{p(y)p(x|y)}{p(x)}=\frac{p(y)p(x|y)}{\int p(x,y)dy}=\frac{p(y)p(x|y)}{\int p(y)p(x|y) dy}
\]</span> For discrete <span class="math display">\[
p(x,y)=p(x)p(y|x)=p(y)p(x|y) \implies \\
p(y|x)=\frac{p(y)p(x|y)}{p(x)}=\frac{p(y)p(x|y)}{\sum_y p(x,y)}=\frac{p(y)p(x|y)}{\sum_y p(y)p(x|y) }
\]</span> Denotion <span class="math display">\[
\underbrace{p(y|x)}_\text{Posterior}=\frac{\overbrace{p(y)}^\text{Prior}\quad\overbrace{p(x|y)}^\text{Liklihood}}{\underbrace{p(x)}_\text{Evidence}}
\]</span> Prior: What we know before seeing x</p>
<p>Posterior: What we know after seeing x</p>
<p>Likelihood: Propensity for observing a certain value of x given certain value of y</p>
<p>Evidence: Make sure the left hand is a valid distribution</p>
<h2 id="expectation">6. Expectation</h2>
<p>Definition of expectation <span class="math display">\[
E(f(x))=\sum_xf(x)p(x)\\
E(f(x))=\int_xf(x)p(x)dx\\
\]</span> Definition of mean <span class="math display">\[
E(x)=\int_xxp(x)dx=\mu_x
\]</span> Definition of variance <span class="math display">\[
E((x-\mu_x)^2)=\int_x(x-\mu_x)^2p(x)dx=\sigma_x^2
\]</span> then <span class="math inline">\(\sigma_x\)</span> is called standard deviation</p>
<p>Definition of covariance <span class="math display">\[
E((x-\mu_x)(y-\mu_y))=\int\int(x-\mu_x)(y-\mu_y)p(x,y)dxdy=Cov(x,y)
\]</span> Some important conclusions for expectation <span class="math display">\[
E(af(x)+bf(y))=aE(f(x))+bE(f(y))\\
Cov(x,y)=E(xy)-E(x)E(y)\\
Var(x)=Cov(x,x)=E(x^2)-E^2(x)
\]</span> Definition of Conditional Expectation <span class="math display">\[
E(f(x,y)|y)=E_{p(x|y)}[f(x,y)]=\sum_xf(x,y)p(x|y)
\]</span> Definition of Conditional Independece <span class="math display">\[
p(x_1,x_2|x_3)=p(x_1|x_3)p(x_2|x_3)
\]</span> Attention!</p>
<p><span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are independent does not imply <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are conditionally independent given <span class="math inline">\(x_3\)</span>.</p>
<p><span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are independent given <span class="math inline">\(x_3\)</span> does not imply <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span> are independent.</p>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/22/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/22/">22</a><span class="page-number current">23</span><a class="page-number" href="/page/24/">24</a><span class="space">&hellip;</span><a class="page-number" href="/page/36/">36</a><a class="extend next" rel="next" href="/page/24/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>


          </div>
          

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc" data-target="post-toc-wrap">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview" data-target="site-overview-wrap">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Orange+Dragon</p>
  <div class="site-description" itemprop="description"></div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">71</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span>
        </a>
      </div>
    
  </nav>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:zilongcheng@u.nus.edu" title="E-Mail &rarr; mailto:zilongcheng@u.nus.edu" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
    
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Orange+Dragon</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.3.0</div>

        












        
      </div>
    </footer>
  </div>

  
    
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/jquery/index.js?v=3.4.1"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.3.0"></script><script src="/js/motion.js?v=7.3.0"></script>
<script src="/js/schemes/pisces.js?v=7.3.0"></script>

<script src="/js/next-boot.js?v=7.3.0"></script>



  





















  

  
    
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    
  

  

  


<script>
NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(item => {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'k1NFV6E2jjtcuFpWbPUwvs04-MdYXbMMI',
    appKey: 'oCso3hdINWUXi0EtP7BsCUoY',
    placeholder: 'Just go go',
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: true,
    lang: '' || 'zh-cn',
    path: location.pathname
  });
}, window.Valine);
</script>

</body>
</html>
