<!DOCTYPE html>





<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.3.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2">
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.3.0',
    exturl: false,
    sidebar: {"position":"right","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    }
  };
</script>

  <meta name="keywords" content="Optimization, Machine Learning">
<meta property="og:type" content="website">
<meta property="og:title" content="Cheng-Zilong">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="Cheng-Zilong">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Cheng-Zilong">
  <link rel="canonical" href="http://yoursite.com/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Cheng-Zilong</title>
  <meta name="generator" content="Hexo 3.9.0">
  








  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Cheng-Zilong</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">Learning Notes</p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            
  <div id="posts" class="posts-expand">
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/12/22/MA6268 Nonlinear Optimization/8.4 A symmetric Gauss-Seidel based semi-proximal ADMMALM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Cheng-Zilong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cheng-Zilong">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2020/12/22/MA6268 Nonlinear Optimization/8.4 A symmetric Gauss-Seidel based semi-proximal ADMMALM/" class="post-title-link" itemprop="url">8. ADMM methods for convex composite conic programming (2)</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2020-12-22 13:48:40" itemprop="dateCreated datePublished" datetime="2020-12-22T13:48:40+08:00">2020-12-22</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-11-21 20:27:26" itemprop="dateModified" datetime="2019-11-21T20:27:26+08:00">2019-11-21</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/MA6268-Nonlinear-Optimization/" itemprop="url" rel="index"><span itemprop="name">MA6268 Nonlinear Optimization</span></a></span>

                
                
              
            </span>
          

          
            <span id="/2020/12/22/MA6268 Nonlinear Optimization/8.4 A symmetric Gauss-Seidel based semi-proximal ADMMALM/" class="post-meta-item leancloud_visitors" data-flag-title="8. ADMM methods for convex composite conic programming (2)" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
        
      
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2020/12/22/MA6268 Nonlinear Optimization/8.4 A symmetric Gauss-Seidel based semi-proximal ADMMALM/#comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/2020/12/22/MA6268 Nonlinear Optimization/8.4 A symmetric Gauss-Seidel based semi-proximal ADMMALM/" itemprop="commentCount"></span></a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="a-symmetric-gauss-seidel-based-semi-proximal-admmalm">8.4 A symmetric Gauss-Seidel based semi-proximal ADMM/ALM</h2>
<p>Let us consider the following convex composite quadratic programming, <span class="math display">\[
\text{(P)}\quad \begin{array}{rCl}
\min &amp; \theta(y_1)+f(y_1,y_2,\dotsm,y_p)+\varphi(z_1)+g(z_1,z_2,\dotsm,z_q)\\
\text{subject to}&amp; \mathcal A_1^* y_1+\mathcal A_2^*y_2+\dotsm+\mathcal A_p^*y_p+\mathcal B_1^*z_1+\mathcal B_2^*z_2+\dotsm+\mathcal B_q^*z_q=c,
\end{array}
\]</span> where</p>
<ol type="1">
<li><span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> are given nonnegative integers, <span class="math inline">\(c\in\mathcal X\)</span> is a given vector.</li>
<li><span class="math inline">\(\theta:\mathcal Y_1\rightarrow (-\infty,\infty]\)</span> and <span class="math inline">\(\varphi:\mathcal Z_1\rightarrow (-\infty,\infty]\)</span> are simple closed proper convex functions in the sense that their proximal mapping can be relatively <strong>easy</strong> to compute.</li>
<li><span class="math inline">\(f:\mathcal Y_1\times \mathcal Y_2\times \dotsm\times \mathcal Y_p\rightarrow \mathbb R\)</span> and <span class="math inline">\(g:\mathcal Z_1\times \mathcal Z_2\times \dotsm\times \mathcal Z_q\rightarrow \mathbb R\)</span> are convex quadratic functions.</li>
<li><span class="math inline">\(\mathcal A_i:\mathcal X\rightarrow \mathcal Y_i,\;i=1,\dotsm,p\)</span> and <span class="math inline">\(\mathcal B_j:\mathcal X\rightarrow \mathcal Z_j,\;j=1,\dotsm,q\)</span> are linear maps.</li>
<li><span class="math inline">\(\mathcal Y_1.\dotsm,\mathcal Y_p\)</span>, <span class="math inline">\(\mathcal Z_1,\dotsm,\mathcal Z_q\)</span> and <span class="math inline">\(\mathcal X\)</span> are real finite dimensional Euclidean spaces each equipped with an inner product <span class="math inline">\(\langle \cdot,\cdot\rangle\)</span> and its induced norm <span class="math inline">\(||\cdot||\)</span>.</li>
</ol>
<p>Define <span class="math inline">\(\mathcal Y=\mathcal Y_1\times \mathcal Y_2\times \dotsm\times \mathcal Y_p\)</span> and <span class="math inline">\(\mathcal Z=\mathcal Z_1\times \mathcal Z_2\times \dotsm\times \mathcal Z_q\)</span>. Define <span class="math inline">\(y=(y_1,\dotsm,y_p)\in\mathcal Y\)</span> and <span class="math inline">\(z=(z_1,\dotsm,z_q)\in\mathcal Z\)</span>. Define the linear maps <span class="math inline">\(\mathcal A:\mathcal X\rightarrow \mathcal Y\)</span> and <span class="math inline">\(\mathcal B:\mathcal X\rightarrow \mathcal Z\)</span> such that the adjoint maps are given by <span class="math display">\[
\mathcal A^* y=\sum_{i=1}^p \mathcal A_i^* y_i,\;\forall y\in\mathcal Y\\
\mathcal B^* y=\sum_{j=1}^p \mathcal B_j^* z_j,\;\forall z\in\mathcal Z.
\]</span> Then the problem can be denoted in a more compact form, <span class="math display">\[
\text{(P)}\quad \begin{array}{rCl}
\min &amp; \theta(y_1)+f(y)+\varphi(z_1)+g(z)\\
\text{subject to}&amp; \mathcal A^*y+\mathcal B^*z=c.
\end{array}
\]</span> Assume the convex quadratic functions <span class="math inline">\(f:\mathcal Y\rightarrow \mathbb R\)</span> and <span class="math inline">\(g:\mathcal Z\rightarrow \mathbb R\)</span> are given by <span class="math display">\[
f(y)=\frac{1}{2}\langle y,\mathcal Py\rangle -\langle b_f,y\rangle\\
g(z)=\frac{1}{2}\langle z,\mathcal Qz\rangle -\langle b_g,z\rangle.
\]</span> Here <span class="math inline">\(\mathcal P\)</span> and <span class="math inline">\(\mathcal Q\)</span> are self-adjoint positive semidefinite linear operator defined on <span class="math inline">\(\mathcal Y\)</span> and <span class="math inline">\(\mathcal Z\)</span>, respectively. For later discussion, we write <span class="math display">\[
\mathcal P=\left(
\begin{array}{cccc}
\mathcal P_{11} &amp; \mathcal P_{12} &amp; \dotsm &amp; \mathcal P_{1p}\\
\mathcal P_{12}^* &amp; \mathcal P_{22} &amp; \dotsm &amp; \mathcal P_{2p}\\
\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\
\mathcal P_{p1}^* &amp; \mathcal P_{p2}^* &amp; \dotsm &amp; \mathcal P_{pp}
\end{array}
\right)\quad 
\mathcal Q=\left(
\begin{array}{cccc}
\mathcal Q_{11} &amp; \mathcal Q_{12} &amp; \dotsm &amp; \mathcal Q_{1p}\\
\mathcal Q_{12}^* &amp; \mathcal Q_{22} &amp; \dotsm &amp; \mathcal Q_{2p}\\
\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\
\mathcal Q_{q1}^* &amp; \mathcal Q_{q2}^* &amp; \dotsm &amp; \mathcal Q_{qq}
\end{array}
\right),
\]</span> where <span class="math inline">\(\mathcal P_{ij}:\mathcal Y_j\rightarrow \mathcal Y_i\)</span> for <span class="math inline">\(i=1,\dotsm,p\)</span>, <span class="math inline">\(j\le i\)</span> and <span class="math inline">\(\mathcal Q_{mn}:\mathcal Z_n\rightarrow \mathcal Z_m\)</span> for <span class="math inline">\(m=1,\dotsm,q\)</span>, <span class="math inline">\(n\le m\)</span> are linear operators. For simplicity, we further write <span class="math display">\[
\theta_f(y)=\theta(y_1)+f(y)\\
\varphi_g(z)=\varphi (z_1)+g(z).
\]</span> Let <span class="math inline">\(\sigma &gt;0\)</span> be given. The augmented Lagrangian function is given as, for any <span class="math inline">\((y,z,x)\in\mathcal Y,\mathcal Z,\mathcal X\)</span>, <span class="math display">\[
\mathcal L_\sigma (y,z;x)=\theta_f(y)+\varphi_g(z)+\langle x,\mathcal A^* y+\mathcal B^*z-c\rangle +\frac{\sigma}{2}||\mathcal A^* y+\mathcal B^* z-c||^2.
\]</span> We first introduce two self-adjoint semidefinite linear operators <span class="math inline">\(\mathcal S_1\)</span> and <span class="math inline">\(\mathcal T_1\)</span> to handle the convex, possibly nonsmoothed, functions <span class="math inline">\(\theta(y_1)\)</span> and <span class="math inline">\(\varphi(z_1)\)</span>. Let <span class="math inline">\(\mathcal F_1\)</span> and <span class="math inline">\(\mathcal S_1\)</span> be self-adjoint operator on <span class="math inline">\(\mathcal Y_1\)</span> such that <span class="math display">\[
\mathcal F_1=\mathcal S_1+\sigma^{-1}\mathcal P_{11}+\mathcal A_1\mathcal A_1^*\succ 0
\]</span> and the following well-defined optimization problem (subproblem), <span class="math display">\[
\min _{y_1} \theta(y_1)+\frac{\sigma}{2}||y_1-\bar y_1||^2_{\mathcal F_1}
\]</span> can be easily solved for any <span class="math inline">\(\bar y_1\in\text{dom}(\theta)\)</span>. Similarly, define the self-adjoint semidefinite linear operator <span class="math inline">\(\mathcal G_1\)</span> and <span class="math inline">\(\mathcal T_1\)</span> on <span class="math inline">\(\mathcal Z_1\)</span> such that <span class="math display">\[
\mathcal G_1=\mathcal T_1+\sigma ^{-1}\mathcal Q_{11}+\mathcal B_1\mathcal B_1^*\succ0
\]</span> and the optimal solution to the following problem, <span class="math display">\[
\min_{z_1} \varphi(z_1)+\frac{\sigma}{2}||z_1-\bar z_1||^2_{\mathcal G_1}
\]</span> can be easily obtained for any <span class="math inline">\(\bar z_1\in\text{dom}(\varphi)\)</span>. Then for <span class="math inline">\(i=2,\dotsm,p\)</span>, let <span class="math inline">\(\mathcal F_i\)</span> be a self-adjoint positive definite linear operator such that it is a majorization of <span class="math inline">\(\sigma^{-1}\mathcal P_{ii}+\mathcal A_i\mathcal A_i^*\)</span>, i.e., <span class="math display">\[
\mathcal F_i\succeq \sigma^{-1}\mathcal P_{ii}+\mathcal A_i\mathcal A_i^*,\quad i=1,\dotsm,p.
\]</span> In practice, we would choose <span class="math inline">\(\mathcal F_i\)</span> in such a way that its inverse can be computed at a moderate cost. Define <span class="math display">\[
\mathcal S_i=\mathcal F_i-\sigma^{-1}\mathcal P_{ii}-\mathcal A_i\mathcal A_i^*\succeq 0,\quad i=1,\dotsm,p.
\]</span> Note that for numerical efficiency, we need the self-adjoint positive semidefinite linear operator <span class="math inline">\(\mathcal S_i\)</span> to be as small as possible for each <span class="math inline">\(i=1,\dotsm,p\)</span>. Similarly, for <span class="math inline">\(j=2,\dotsm,p\)</span>, let <span class="math inline">\(\mathcal G_j\)</span> be a self-adjoint positive definite linear operator on <span class="math inline">\(\mathcal Z_j\)</span> that majorizes <span class="math inline">\(\sigma^{-1}\mathcal Q_{jj}+\mathcal B_j\mathcal B_j^*\)</span> in such a way that <span class="math inline">\(\mathcal G^{-1}\)</span> can be computed relatively easily. Define <span class="math display">\[
\mathcal T_j=\mathcal G_j-\sigma ^{-1}\mathcal Q_{jj}-\mathcal B_j\mathcal B_K^*\succeq 0,\quad j=1,\dotsm,q.
\]</span> <strong>My thinking</strong></p>
<p>Firstly, let us see how we can use sPADMM to solve this problem. We only analyze one of the blocks of the sPADMM here. <span class="math display">\[
\begin{array}{rcl}y^{k+1}&amp;=&amp;\arg\min_y\left\{\mathcal L_\sigma(y,z^k;x^k)+\frac{1}{2}||y-y^k||_{\mathcal S_\mathcal M}\right\}\\&amp;=&amp; \arg\min_y\left\{\theta(y_1)+\frac{1}{2}\langle y,\mathcal Py\rangle -\langle b_f,y\rangle+\frac{\sigma}{2}||\mathcal A^*y+\mathcal B^*z^{k}-c+\sigma^{-1}x^{k}||^2+\frac{1}{2}||y-y^k||_{\mathcal S_\mathcal M}\right\}\\&amp;=&amp; \arg\min_y\left\{\theta(y_1)+\frac{1}{2}\langle y,(\mathcal P+\sigma \mathcal A\mathcal A^*)y\rangle-\langle b,y\rangle+\frac{1}{2}||y-y^k||_{\mathcal S_\mathcal M}\right\}\\\end{array}.
\]</span> Define <span class="math display">\[
\mathcal H=\left(\begin{array}{cccc}\mathcal P_{11} &amp; \mathcal P_{12} &amp; \dotsm &amp; \mathcal P_{1p}\\\mathcal P_{12}^* &amp; \mathcal P_{22} &amp; \dotsm &amp; \mathcal P_{2p}\\\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\\mathcal P_{p1}^* &amp; \mathcal P_{p2}^* &amp; \dotsm &amp; \mathcal P_{pp}\end{array}\right)+\sigma \left(\begin{array}{cccc}\mathcal A_1\mathcal A_1^* &amp; \mathcal A_1\mathcal A_2^* &amp; \dotsm &amp; \mathcal A_1\mathcal A_p^*\\\mathcal A_2\mathcal A_1^* &amp; \mathcal A_2\mathcal A_2^* &amp; \dotsm &amp; \mathcal A_2\mathcal A_p^*\\\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\\mathcal A_p\mathcal A_1^* &amp; \mathcal A_p\mathcal A_2^* &amp; \dotsm &amp; \mathcal A_p\mathcal A_p^*\\\end{array}\right)\\=\left(\begin{array}{cccc}\mathcal P_{11}+\sigma \mathcal A_1\mathcal A_1^* &amp; \mathcal P_{12}+\sigma \mathcal A_1\mathcal A_2^* &amp; \dotsm &amp; \mathcal P_{1p}+\sigma \mathcal A_1\mathcal A_p^*\\\mathcal P_{21}+\sigma \mathcal A_2\mathcal A_1^* &amp; \mathcal P_{22}+\sigma \mathcal A_2\mathcal A_2^* &amp; \dotsm &amp; \mathcal P_{2p}+\sigma \mathcal A_2\mathcal A_p^*\\\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\\mathcal P_{p1}+\sigma \mathcal A_p\mathcal A_1^* &amp; \mathcal P_{p2}+\sigma \mathcal A_p\mathcal A_2^* &amp; \dotsm &amp; \mathcal P_{pp}+\sigma \mathcal A_p\mathcal A_p^*\\\end{array}\right).
\]</span> And define <span class="math display">\[
\mathcal U&#39;=\left(\begin{array}{cccc}0 &amp; \mathcal P_{12}+\sigma \mathcal A_1\mathcal A_2^* &amp; \dotsm &amp; \mathcal P_{1p}+\sigma \mathcal A_1\mathcal A_p^*\\0 &amp; 0 &amp; \dotsm &amp; \mathcal P_{2p}+\sigma \mathcal A_2\mathcal A_p^*\\\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\0 &amp; 0 &amp; \dotsm &amp; 0\\\end{array}\right)\\\mathcal D&#39;=\left(\begin{array}{cccc}\mathcal P_{11}+\sigma \mathcal A_1\mathcal A_1^* &amp; 0 &amp; \dotsm &amp; 0\\0 &amp; \mathcal P_{22}+\sigma \mathcal A_2\mathcal A_2^* &amp; \dotsm &amp; 0\\\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\0 &amp; 0 &amp; \dotsm &amp; \mathcal P_{pp}+\sigma \mathcal A_p\mathcal A_p^*\\\end{array}\right).
\]</span> Then sGS method can be applied to solve this subproblem if <span class="math inline">\(\mathcal S_\mathcal M\)</span> is chosen as <span class="math inline">\({\mathcal S_\mathcal M} = \mathcal U&#39;(\mathcal D&#39;)^{-1} (\mathcal U&#39;)^*\)</span>.</p>
But if this decomposition is applied, the subproblem to <span class="math inline">\(y^{k+1}_1\)</span> will be very difficult to solve because of the non-smooth function <span class="math inline">\(\theta(y_1)\)</span>. The subproblem is denoted as $$
<span class="math display">\[\begin{array}{rcl}
y_{1}^{k+1}&amp;=&amp;\operatorname{argmin}_{y_{1}} \mathcal{L}_{\sigma}\left(\left(y_{1}, \bar{y}_{\geq 2}^{k}\right), z^{k} ; x^{k}\right),\\
&amp;=&amp; \operatorname{argmin}_{y_{1}} \theta(y_1)+f(y)+\varphi_g(z)+\langle x,\mathcal A^* y+\mathcal B^*z-c\rangle +\frac{\sigma}{2}||\mathcal A^* y+\mathcal B^* z-c||^2\\

&amp;=&amp; \operatorname{argmin}_{y_{1}} \theta(y_1)+\frac{1}{2}\langle y,\mathcal Py\rangle -\langle b_f,y\rangle+\langle x,\mathcal A^* y\rangle +\frac{\sigma}{2}||\mathcal A^* y+\mathcal B^* z-c||^2\\

&amp;=&amp; \operatorname{argmin}_{y_{1}} \theta(y_1)+\frac{1}{2}\langle y,(\mathcal P+\sigma \mathcal A^*\mathcal A)y\rangle -\langle b,y\rangle
\end{array}\]</span>
<span class="math display">\[
which is a non-smooth function. To solve this problem is as difficult as to solve the original problem. Therefore we hope to introduce the regulation part to each of the subproblems, especially the subproblem to  $y^{k+1}_1$, to make the subproblems easy to solve. The form we hope the subproblem to be is
\]</span>
<span class="math display">\[\begin{array}{rcl}
y_{1}^{k+1}
&amp;=&amp; \operatorname{argmin}_{y_{1}} \theta(y_1)+||y_1-y_1^k||^2_\mathcal {SS},
\end{array}\]</span>
<p>$$ where <span class="math inline">\(\mathcal {SS}\)</span> is chosen from some positive definite symmetric matrices such that this problem can become a proximal operator to the function <span class="math inline">\(\theta\)</span>. Now let us see how we can achieve this goal.</p>
<p>We consider the following problem by introducing another regulation part <span class="math inline">\(\mathcal S\)</span>. <span class="math display">\[
\begin{array}{rcl}
y^{k+1}&amp;=&amp; \arg\min_y\left\{\theta(y_1)+\frac{1}{2}\langle y,(\mathcal P+\sigma \mathcal A\mathcal A^*)y\rangle-\langle b,y\rangle
+\underbrace{\frac{1}{2}||y-y^k||_{\mathcal S}}_{\text{New Part}}+\frac{1}{2}||y-y^k||_{\mathcal S_\mathcal M}\right\}\\\end{array},
\]</span> where <span class="math inline">\(\mathcal S=\text{diag}(\mathcal S_1,\mathcal S_2,\dotsm,\mathcal S_p)\)</span>.</p>
<p>Then we need to modify <span class="math inline">\(\mathcal D\)</span> such that the sGS can be applied. Therefore, <span class="math inline">\(\mathcal D&#39;\)</span> is redefined as <span class="math display">\[
\mathcal D&#39;=\left(\begin{array}{cccc}\mathcal S_1+\mathcal P_{11}+\sigma \mathcal A_1\mathcal A_1^* &amp; 0 &amp; \dotsm &amp; 0\\0 &amp; \mathcal S_2+\mathcal P_{22}+\sigma \mathcal A_2\mathcal A_2^* &amp; \dotsm &amp; 0\\\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\0 &amp; 0 &amp; \dotsm &amp; \mathcal S_p+\mathcal P_{pp}+\sigma \mathcal A_p\mathcal A_p^*\\\end{array}\right).
\]</span> If we hope to be consistent with the above text, we need to let the <span class="math inline">\(\sigma\)</span> go outside.</p>
<p>Define <span class="math inline">\(\sigma \mathcal D=\mathcal D&#39;\)</span>, and <span class="math inline">\(\sigma \mathcal U=\mathcal U&#39;\)</span>. Then we have <span class="math display">\[
\mathcal D=\left(\begin{array}{cccc}\mathcal S_1+\sigma^{-1}\mathcal P_{11}+ \mathcal A_1\mathcal A_1^* &amp; 0 &amp; \dotsm &amp; 0\\0 &amp; \mathcal S_2+\sigma^{-1}\mathcal P_{22}+ \mathcal A_2\mathcal A_2^* &amp; \dotsm &amp; 0\\
\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\0 &amp; 0 &amp; \dotsm &amp; \mathcal S_p+\sigma^{-1}\mathcal P_{pp}+ \mathcal A_p\mathcal A_p^*\\\end{array}\right)\\
\mathcal U=\left(\begin{array}{cccc}
0 &amp; \sigma^{-1}\mathcal P_{12}+ \mathcal A_1\mathcal A_2^* &amp; \dotsm &amp; \sigma^{-1}\mathcal P_{1p}+ \mathcal A_1\mathcal A_p^*\\
0 &amp; 0 &amp; \dotsm &amp; \sigma^{-1}\mathcal P_{2p}+ \mathcal A_2\mathcal A_p^*\\
\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\0 &amp; 0 &amp; \dotsm &amp; 0
\end{array}\right).
\]</span> If we choose <span class="math inline">\(\mathcal S_i=\mathcal F_i-\sigma^{-1}\mathcal P_{ii}-\mathcal A_i\mathcal A_i^*\succeq 0,\quad i=1,\dotsm,p\)</span>, then we have <span class="math display">\[
\mathcal D=
\begin{bmatrix}
\mathcal F_1 &amp; 0 &amp; \dotsm &amp; 0\\
0 &amp; \mathcal F_2 &amp; \dotsm &amp; 0\\
\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\
0 &amp; 0 &amp; \dotsm &amp; \mathcal F_p
\end{bmatrix}.
\]</span> Then we have <span class="math inline">\(\mathcal S_\mathcal M=\mathcal U\mathcal D^{-1}\mathcal U^*\)</span>, and the subproblems we need to solve can be denoted as <span class="math display">\[
\begin{array}{rcl}
\bar y_i^k &amp;=&amp;\arg\min _{y_i}\mathcal L_\sigma ((y^k_{\le i-1},y_i,\bar y^k_{\ge i+1}),z^k;x^k)+\frac{\sigma}{2}||y_i-y_i^k||_{\mathcal S_i}^2\\
y_1^{k+1}&amp;=&amp;\arg\min_{y_1}\mathcal L_\sigma((y_1,\bar y^k_{\ge 2},z_k;x^k)+\frac{\sigma}{2}||y_1-y_1^k||_{\mathcal S_1}^2. 
\end{array}
\]</span></p>
<p><strong>Proposition</strong></p>
<p>For any <span class="math inline">\(k\ge 0\)</span>, the point <span class="math inline">\((x^{k+1},y^{k+1},z^{k+1})\)</span> obtained by sGS-sPADMM for solving the problem can be generated exactly according to the following iteration, <span class="math display">\[
\begin{array}{rcl}
y^{k+1}&amp;=&amp; \arg\min_y\{\mathcal L_\sigma (y,z^k;x^k)+\frac{\sigma}{2}||y-y^k||^2_{\mathcal S+\mathcal S_\mathcal M}\}\\
z^{k+1}&amp;=&amp; \arg\min_z\{\mathcal L_\sigma (y^{k+1},z;x^k)+\frac{\sigma}{2}||y-y^k||^2_{\mathcal T+\mathcal T_\mathcal N}\}\\
x^{k+1}&amp;=&amp; x^k+\tau\sigma (\mathcal A^* y^{k+1}+\mathcal B^* z^{k+1}-c).
\end{array}
\]</span> Proof.</p>
<p>It is straightforward to prove it.</p>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/12/22/MA6268 Nonlinear Optimization/8. ADMM methods for convex composite conic programming/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Cheng-Zilong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cheng-Zilong">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2020/12/22/MA6268 Nonlinear Optimization/8. ADMM methods for convex composite conic programming/" class="post-title-link" itemprop="url">8. ADMM methods for convex composite conic programming (1)</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2020-12-22 13:48:40" itemprop="dateCreated datePublished" datetime="2020-12-22T13:48:40+08:00">2020-12-22</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-11-16 17:23:26" itemprop="dateModified" datetime="2019-11-16T17:23:26+08:00">2019-11-16</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/MA6268-Nonlinear-Optimization/" itemprop="url" rel="index"><span itemprop="name">MA6268 Nonlinear Optimization</span></a></span>

                
                
              
            </span>
          

          
            <span id="/2020/12/22/MA6268 Nonlinear Optimization/8. ADMM methods for convex composite conic programming/" class="post-meta-item leancloud_visitors" data-flag-title="8. ADMM methods for convex composite conic programming (1)" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
        
      
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2020/12/22/MA6268 Nonlinear Optimization/8. ADMM methods for convex composite conic programming/#comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/2020/12/22/MA6268 Nonlinear Optimization/8. ADMM methods for convex composite conic programming/" itemprop="commentCount"></span></a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="admm-methods-for-convex-composite-conic-programming">8. ADMM methods for convex composite conic programming</h1>
<h2 id="a-generic-2-block-semi-proximal-admm">8.1 A generic 2-block semi-proximal ADMM</h2>
<p>Let <span class="math inline">\(\mathcal X\)</span>, <span class="math inline">\(\mathcal Y\)</span>, and <span class="math inline">\(\mathcal Z\)</span> be finite dimensional real Euclidean spaces. Let <span class="math inline">\(f:\mathcal Y\rightarrow (-\infty,+\infty]\)</span> and <span class="math inline">\(g:\mathcal Z\rightarrow (-\infty,+\infty]\)</span> be closed proper convex functions, <span class="math inline">\(\mathcal A:\mathcal X\rightarrow \mathcal Y\)</span> and <span class="math inline">\(\mathcal B:\mathcal X\rightarrow \mathcal Z\)</span> be linear maps. Let <span class="math inline">\(\partial f\)</span> and <span class="math inline">\(\partial g\)</span> be the subdifferential mappings of <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span>, respectively. Since both <span class="math inline">\(\partial f\)</span> and <span class="math inline">\(\partial g\)</span> are maximally monotone, there exists two self-adjoint and positive semidefinite operators <span class="math inline">\(\Sigma_f\)</span> and <span class="math inline">\(\Sigma_g\)</span> such that for all <span class="math inline">\(y,y’\in\text{dom}(f)\)</span>, <span class="math inline">\(\xi\in\partial f(y)\)</span>, and <span class="math inline">\(\xi&#39;\in\partial f(y&#39;)\)</span>, <span class="math display">\[
\langle \xi-\xi&#39;,y-y&#39;\rangle \ge ||y-y&#39;||^2_{\Sigma_f}
\]</span> and for all <span class="math inline">\(z,z’\in\text{dom}(g)\)</span>, <span class="math inline">\(\zeta\in\partial g(z)\)</span>, and <span class="math inline">\(\zeta&#39;\in\partial g(z&#39;)\)</span>, <span class="math display">\[
\langle \zeta-\zeta&#39;,z-z&#39;\rangle \ge ||z-z&#39;||^2_{\Sigma_g}.
\]</span> Consider the convex optimization problem with the following 2-block separable structure <span class="math display">\[
\text{(P)}\quad \begin{array}{rCl}
\min &amp; f(y)+g(z)\\
\text{subject to}&amp; \mathcal A^*y+\mathcal B^*z=c.
\end{array}
\]</span> The dual problem is given by <span class="math display">\[
\text{(D)}\quad \max\left\{-\langle c,x\rangle-f^*(-\mathcal Ax)-g^*(-\mathcal Bx)\right\}.
\]</span> The augmented Lagrangian function associated with (P) is given as follows, for any <span class="math inline">\((y,z,x)\in\mathcal Y\times \mathcal Z\times \mathcal X\)</span>, <span class="math display">\[
\begin{array}{rcl}
\mathcal L_\sigma(y,z;x)&amp;=&amp;f(y)+g(z)+\langle x,\mathcal A^*y+\mathcal B^*z-c\rangle+\frac{\sigma}{2}||\mathcal A^*y+\mathcal B^*z-c||^2\\
&amp;=&amp; f(y)+g(z)+\frac{\sigma}{2}||\mathcal A^*y+\mathcal B^*z-c+\sigma^{-1}x||^2-\frac{1}{2\sigma}||x||^2
\end{array}
\]</span> <strong>Algorithm</strong></p>
<p>Let <span class="math inline">\(\sigma&gt;0\)</span> and <span class="math inline">\(\tau \in(0,\infty)\)</span> be given parameters. Let <span class="math inline">\(\mathcal S\)</span> and <span class="math inline">\(\mathcal T\)</span> be given self-adjoint positive semidefinite (not necessarily positive definite) linear operators defined on <span class="math inline">\(\mathcal Y\)</span> and <span class="math inline">\(\mathcal Z\)</span>, respectively. Choose <span class="math inline">\((x^0,y^0,z^0)\in\mathcal X\times \text{dom}(f)\times \text{dom}(g)\)</span>. For <span class="math inline">\(k=0,1,2,\dotsm\)</span>, perform the <span class="math inline">\(k\)</span>th iteration as follows,</p>
<p><strong>Step 1</strong> <span class="math display">\[
\begin{array}{rcl}
y^{k+1}&amp;=&amp;\arg\min_y\mathcal L_\sigma(y,z^k;x^k)+\frac{1}{2}||y-y^k||^2_\mathcal S\\
&amp;=&amp;\arg\min_y\mathcal f(y)+g(z^{k})+\frac{\sigma}{2}||\mathcal A^*y+\mathcal B^*z^{k}-c+\sigma^{-1}x^{k}||^2-\frac{1}{2\sigma}||x^{k}||^2+\frac{1}{2}||y-y^k||^2_\mathcal S\\
&amp;=&amp;\arg\min_y\mathcal f(y)+\frac{\sigma}{2}||\mathcal A^*y+\mathcal B^*z^{k}-c+\sigma^{-1}x^{k}||^2+\frac{1}{2}||y-y^k||^2_\mathcal S.
\end{array}
\]</span></p>
<p><strong>Step 2</strong> <span class="math display">\[
   z^{k+1}=\arg\min_z\mathcal L_\sigma(y^{k+1},z;x^k)+\frac{1}{2}||z-z^k||^2_\mathcal T.
\]</span> <strong>Step 3</strong> <span class="math display">\[
x^{k+1}=x^k+\tau\sigma(\mathcal A^*y^{k+1}+\mathcal B^* z^{k+1}-c).
\]</span> ### 8.1.1 Literature review</p>
<p>When <span class="math inline">\(\mathcal S=0\)</span> and <span class="math inline">\(\mathcal T=0\)</span>, algorithm sPADMM reduces to the classic 2-block ADMM for solving the problem.</p>
<h3 id="convergence-of-spadmm">8.1.2 Convergence of sPADMM</h3>
<p>For the convergence of the 2-block semi-proximal ADMM, we need the following assumption.</p>
<p><strong>Assumption</strong></p>
<p>There exists <span class="math inline">\((\hat y,\hat z)\in \text{relint}(\text{dom}(f)\times\text{dom}(g))\)</span> such that <span class="math inline">\(\mathcal A^*\hat y+\mathcal B^*\hat z=c\)</span>.</p>
<p>Suppose that the CQ holds. Then we know that <span class="math inline">\((\bar y,\bar z)\in\text{dom}(f)\times \text{dom}(g)\)</span> is an optimal solution to the problem if and only if there exists a Lagrange multiplier <span class="math inline">\(\bar x\in\mathcal X\)</span> such that <span class="math inline">\((\bar x,\bar y,\bar z)\)</span> is a solution to the following KKT system, <span class="math display">\[
0\in\mathcal Ax+\partial f(y)\\
0\in\mathcal Bx+\partial g(z)\\
\mathcal A^*y+\mathcal B^*z-c=0.
\]</span> For simplicity, we define <span class="math display">\[
\begin{cases}
H(y,z)=\mathcal A^*y+\mathcal B^*z\\
\theta (x,y,z;x&#39;,y&#39;,z&#39;)=(\tau \sigma)^{-1}||x-x&#39;||^2+||y-y&#39;||^2_\mathcal S+||z-z&#39;||^2_{\mathcal T}+\sigma||\mathcal B^*(z-z&#39;)||^2.
\end{cases}
\]</span> <strong>Theorem</strong></p>
<p>Suppose that the solution set of problem is nonempty and the assumption holds.</p>
<p>Assume that <span class="math inline">\(\mathcal S\)</span> and <span class="math inline">\(\mathcal T\)</span> are chosen such that the sequence <span class="math inline">\(\{(x^k,y^k,z^k)\}\)</span> generated by sPADMM is well defined.</p>
<p>Let <span class="math inline">\((\bar x,\bar y,\bar z)\)</span> be a solution to the KKT system.</p>
<p>For <span class="math inline">\(k=0,1,\dotsm\)</span>, we denote <span class="math display">\[
\begin{cases}
x_e^k=x^k-\bar x\\
y_e^k=y^k-\bar y\\
z_e^k=z^k-\bar z,
\end{cases}
\]</span> and <span class="math display">\[
\begin{cases}
\psi_{k+1}=\theta(x^{k+1},y^{k+1},z^{k+1};\bar x,\bar y,\bar z)+||z^{k+1}-z^k||^2_\mathcal T\\
\delta_{k+1}=\min(\tau,1+\tau-\tau^2)\sigma||\mathcal B^*(z^{k+1}-z^k)||^2+||z^{k+1}-z^k||^2_\mathcal T\\
t_{k+1}=\delta_{k+1}+||y^{k+1}-y^k||^2_\mathcal S+2||y^{k+1}-\bar y||^2_{\Sigma_f}+2||z^{k+1}-\bar z||^2_{\Sigma_g}.
\end{cases}
\]</span> Then the following results hold,</p>
<ol type="1">
<li><p>if <span class="math inline">\(\tau\in(0,1]\)</span>, we have for <span class="math inline">\(k\ge 1\)</span> that <span class="math display">\[
\begin{array}{l}
\left[\psi_{k+1}+(1-\tau)\sigma||H(y^{k+1},z^{k+1})-c||^2\right]\\
\quad-\left[\psi_k+(1-\tau)\sigma||H(y^k,z^k)-c||^2\right]\\
\le -\left[t_{k+1}+\sigma||H(y^{k+1},z^{k+1})-c||^2\right];
\end{array}
\]</span></p></li>
<li><p>If <span class="math inline">\(\tau &gt;1\)</span>, we have for <span class="math inline">\(k\ge 1\)</span> that <span class="math display">\[
\begin{array}{l}
\left[\psi_{k+1}+(1-\tau^{-1})\sigma||H(y^{k+1},z^{k+1})-c||^2\right]\\
\quad-\left[\psi_k+(1-\tau^{-1})\sigma||H(y^k,z^k)-c||^2\right]\\
\le -\left[t_{k+1}+\tau^{-1}(1+\tau-\tau^{-2})\sigma||H(y^{k+1},z^{k+1})-c||^2\right];
\end{array}
\]</span></p></li>
<li><p>Suppose the either of the following condition holds,</p>
<ol type="1">
<li><span class="math inline">\(\tau\in(0,(1+\sqrt5)/2)\)</span></li>
<li><span class="math inline">\(\tau \ge (1+\sqrt 5)/2\)</span> and <span class="math inline">\(\displaystyle\sum_{k=0}^\infty ||x^{k+1}-x^k||^2&lt;\infty\)</span>.</li>
</ol>
<p>Then the sequence <span class="math display">\[
    \left\{||x_e^{k+1}||^2+||y_{e}^{k+1}||^2_{\Sigma_f+\mathcal S+\sigma\mathcal A\mathcal A^*}+||z_e^{k+1}||^2_{\Sigma_g+\mathcal T+\sigma\mathcal B\mathcal B^*}\right\}
\]</span> is bounded.</p>
<p>Moreover, if <span class="math inline">\((x^\infty,y^\infty,z^\infty)\)</span> is an accumulation point of <span class="math inline">\(\{(x^k,y^k,z^k)\}\)</span>. Then <span class="math inline">\((x^\infty,y^\infty,z^\infty)\)</span> is a solution of the KKT system, and <span class="math display">\[
    \lim_{k\rightarrow \infty}\left(||x_e^{k+1}||^2+||y_{e}^{k+1}||^2_{\Sigma_f+\mathcal S+\sigma\mathcal A\mathcal A^*}+||z_e^{k+1}||^2_{\Sigma_g+\mathcal T+\sigma\mathcal B\mathcal B^*}\right)=0,
\]</span> where in the definition of <span class="math inline">\((x^k_e,y^k_e,z^k_e)\)</span>, the point is replaced by <span class="math inline">\((x^\infty,y^\infty,z^\infty)\)</span>. Consequently, if both <span class="math inline">\(\Sigma_f+\mathcal S+\sigma\mathcal A\mathcal A^*\)</span> and <span class="math inline">\(\Sigma_g+\mathcal T+\sigma\mathcal B\mathcal B^*\)</span> are positive definite, then the sequence <span class="math inline">\(\{(x^k,y^k,z^k)\}\)</span>, which is automatically well-defined, converge to a unique limit, say <span class="math inline">\((x^\infty,y^\infty,z^\infty)\)</span> with <span class="math inline">\((y^\infty,z^\infty)\)</span> solving (P) and <span class="math inline">\((x^\infty)\)</span> solving (D), respectively.</p></li>
<li><p>If <strong>y-part</strong> is vacuous, then we have that for all <span class="math inline">\(k\ge0\)</span>, <span class="math display">\[
    \begin{array}{l}
    (\tau\sigma)^{-1}||x^{k+1}-\bar x||^2+||z^{k+1}-\bar z||^2_\mathcal T\\
    \le (\tau\sigma)^{-1}||x^{k}-\bar x||^2+||z^{k}-\bar z||^2_\mathcal T\\
    \quad-\left[(2-\tau)\sigma||\mathcal B^*z^{k+1}-c||^2+||z^{k+1}-z^k||^2_\mathcal T+2||z^{k+1}-\bar z||^2_{\Sigma_g}\right].
    \end{array}
 \]</span> The corresponding result in part 3 also holds.</p></li>
</ol>
<p>Proof.</p>
<p>Since both <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> are proper closed convex functions and an infinite sequence <span class="math inline">\(\{(x^k,y^k,z^k)\}\)</span> is assumed to be generated by sPADMM, we have for <span class="math inline">\(k&gt;0\)</span>, by using the algorithm, <span class="math display">\[
\begin{array}{l}
0\in\mathcal Ax^{k}+\partial f(y^{k+1})+\mathcal S(y^{k+1}-y^k)\\
0\in\mathcal Bx^{k}+\partial g(z^{k+1})+\mathcal T(z^{k+1}-z^k)\\
x^{k+1}=x^k+\tau\sigma(\mathcal A^*y^{k+1}+\mathcal B^* z^{k+1}-c)\\
\;\:\:\:\;\;\;\:\:=x^k+\tau\sigma(H(y^{k+1},z^{k+1})-c)\\
0=H(y^{k+1},z^{k+1})-c-(\tau\sigma)^{-1}(x^{k+1}-x^k),
\end{array}
\]</span> we have</p>
<p>Not done yet.</p>
<h3 id="admm-for-solving-the-dual-problem-d-of-the-sparse-regression-problem">8.1.3 ADMM for solving the dual problem (D) of the sparse regression problem</h3>
<p>Consider the sparse regression problem, <span class="math display">\[
\min\left\{\frac{1}{2}||Ax-b||^2+\lambda||x||_1\;|\; x\in\mathbb R^n\right\},
\]</span> where <span class="math inline">\(A\in \mathbb R^{m\times n}\)</span> and <span class="math inline">\(b\in\mathbb R^m\)</span> are given data. The equivalent problem can be denoted as <span class="math display">\[
\text{(P)}\quad \begin{array}{rCl}
\min &amp; f(u)+g(x)\\
\text{subject to}&amp; u+Ax=b.
\end{array}
\]</span> where <span class="math inline">\(f(u)=\frac{1}{2}||u||^2\)</span> and <span class="math inline">\(g(x)=\lambda||x||_1\)</span>. Then we consider how to derive the dual problem.</p>
<p>The Lagrangian function can be denoted as <span class="math display">\[
\begin{array}{rcl}
\mathcal L(u,x;\xi)&amp;=&amp;f(u)+g(x)+\langle \xi,b-u-Ax\rangle\\
&amp;=&amp; f(u)-\langle \xi,u\rangle+g(x)-\langle A^T\xi,x\rangle +\langle \xi,b\rangle.
\end{array}
\]</span> The Lagrangian dual function can be denoted as <span class="math display">\[
\begin{array}{rcl}
\min_{u,x}\mathcal L(u,x;\xi) &amp;=&amp; \langle \xi,b\rangle+\min_u \left\{f(u)-\langle \xi,u\right\rangle\}+\min_x\{g(x)-\langle A^T\xi,x\rangle \}\\ 
&amp;=&amp; \langle \xi,b\rangle-\frac{1}{2}||\xi||^2-\delta_{B_\lambda}(A^T\xi),
\end{array}
\]</span> where <span class="math inline">\(B_\lambda =\{v\in\mathbb R^n\;|\; ||v||_\infty\le \lambda\}\)</span>.</p>
<p>The Lagrangian dual problem can be denoted as (we define <span class="math inline">\(v+A^T\xi=0\)</span>) <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\max &amp; \langle \xi,b\rangle-\frac{1}{2}||\xi||^2-\delta_{B_\lambda}(v)\\
\text{subject to}&amp; A^T\xi+v=0
\end{array}\\\iff\\
\text{(D)}\quad \begin{array}{rCl}
\min &amp; -\langle \xi,b\rangle+\frac{1}{2}||\xi||^2+\delta_{B_\lambda}(v)\\
\text{subject to}&amp; A^T\xi+v=0.
\end{array}
\]</span> Now we can apply the 2-block ADMM to solve (D). In this case, we have <span class="math inline">\(f(\xi)=-\langle b,\xi\rangle+\frac{1}{2}||\xi||^2\)</span>, <span class="math inline">\(g(v)=\delta_{B_{\lambda}}(v)\)</span>, <span class="math inline">\(\mathcal B=I\)</span> and <span class="math inline">\(c=0\)</span>. The augmented Lagrangian function is given by</p>
<p><span class="math display">\[
\begin{array}{rcl}
\mathcal L_\sigma(\xi,u;x) &amp;=&amp; -\langle b,\xi\rangle+\frac{1}{2}||\xi||^2+\delta_{B_{\lambda}}(v)+\langle x,A^T\xi+v\rangle+\frac{\sigma}{2}||A^T\xi+v||^2\\
&amp;=&amp;-\langle b,\xi\rangle+\frac{1}{2}||\xi||^2+\delta_{B_{\lambda}}(v)+\frac{\sigma}{2}||A^T\xi+v+\sigma^{-1}x||^2-\frac{1}{2\sigma}||x||^2.
\end{array}
\]</span> Then we can use 2-block ADMM to solve this problem.</p>
<p><strong>Step 1</strong> <span class="math display">\[
\begin{array}{rcl}
\xi^{k+1}&amp;=&amp; \arg\min _\xi \mathcal L_\sigma (\xi,v^k;x^k)\\
&amp;=&amp; \arg\min_\xi \left\{-\langle b,\xi\rangle+\dfrac{1}{2}||\xi||^2+\dfrac{\sigma}{2}||A^T\xi+v+\sigma^{-1}x||^2\right\}.
\end{array}
\]</span> From the optimality condition, we know that <span class="math inline">\(\xi^{k+1}\)</span> is the solution of the subproblem <span class="math display">\[
(I+\sigma A A^T)\xi=b-\sigma A(v^k+\sigma^{-1} x^k).
\]</span> <strong>Step 2</strong> <span class="math display">\[
\begin{array}{rcl}
v^{k+1}&amp;=&amp; \arg\min _v \mathcal L_\sigma (\xi^{k+1},v;x^k)\\
&amp;=&amp; \arg\min_v \left\{\delta_{B_{\lambda}}(v)+\frac{\sigma}{2}||A^T\xi+v+\sigma^{-1}x||^2\right\}\\
&amp;=&amp; \Pi_{B_{\lambda}}(-A^T\xi^{k+1}-\sigma^{-1}x^k).
\end{array}
\]</span> <strong>Step 3</strong> <span class="math display">\[
x^{k+1}=x^k+\tau\sigma (A^* \xi^{k+1}+v^{k+1}),
\]</span> where <span class="math inline">\(\tau \in(0,\frac{1+\sqrt 5}{2})\)</span> is the stepsize. In practice, for faster convergence, we take <span class="math inline">\(\tau = 1.618\)</span>.</p>
<p><strong>Step 4</strong></p>
<p>For a given tolerance <span class="math inline">\(\varepsilon\)</span>, check the relative KKT residual, if <span class="math display">\[
\max\left\{\frac{||R_p^{k+1}||}{1+||b||},\frac{||R_d^{k+1}||}{1+||v^k||},\frac{||R_c^{k+1}||}{1+||x^k||+||v^k||}\right\}\le \varepsilon,
\]</span> stop.</p>
<p>The KKT conditions are <span class="math display">\[
Ax-b+\xi=0,\quad 0\in x+\partial g(v),\quad A^T\xi+v=0.
\]</span></p>
<p>Thus to measure whether the computed iterate <span class="math inline">\((\xi^k,v^k,x^k)\)</span> is a good solution, we compute the KKT residual, <span class="math display">\[
\begin{array}{rcl}
R_p^k&amp;=&amp;||Ax^k+\xi^k-b||,\\
R_d^k&amp;=&amp;||A^T\xi^k+v^k||,\\
R_c^k&amp;=&amp;|| v^k-\Pi_{B_\lambda}(v^k-x^k)||.
\end{array}
\]</span></p>
<p><strong>Remark</strong></p>
<p>If <span class="math inline">\(||A^Tb||_\infty \le \lambda\)</span>, then we have <span class="math inline">\(x^*=0\)</span>, <span class="math inline">\(\xi^*=b\)</span>, and <span class="math inline">\(v^*=-A^Tb\)</span>. Since we have <span class="math inline">\(v^*\in B_\lambda\)</span>, we have <span class="math display">\[
v^*=\Pi_{B_\lambda}(v^*)=\Pi_{B_\lambda}(v^*-x^*).
\]</span></p>
<h3 id="linearized-admm-for-solving-the-primal-problem-p-of-the-sparse-regression-problem">8.1.4 Linearized ADMM for solving the primal problem (P) of the sparse regression problem</h3>
<p>One may attempt to apply the 2-block ADMM to the primal problem (P). But we will see that the subproblem corresponding to <span class="math inline">\(x^{k+1}\)</span> is very difficult to solve.</p>
<p>The augmented Lagrangian function associated with (P) is given by <span class="math display">\[
\begin{array}{rcl}
\mathcal L_\sigma (u,x;y) &amp;=&amp; f(u)+g(x)+\langle y,u+Ax-b\rangle +\frac{\sigma}{2}||u+Ax-b||^2\\
&amp;=&amp; f(u)+g(x)+\frac{\sigma}{2}||u+Ax-b+\sigma^{-1}y||^2-\frac{1}{2\sigma}||y||^2.
\end{array}
\]</span> The linearized 2-block ADMM for solving the problem (P) is given as follows.</p>
<strong>Step 1</strong> <span class="math display">\[
\begin{array}{rcl}
u^{k+1}&amp;=&amp; \arg\min _u\mathcal L_\sigma (u,x^k;y^k)\\
&amp;=&amp; \arg\min _u \{\frac{1}{2}||u||^2+\frac{\sigma}{2}||u+Ax^k-b+\sigma^{-1}y^k||^2\}.
\end{array}
\]</span> Then we have <span class="math display">\[
u^{k+1}=\frac{-\sigma}{1+\sigma}(Ax^k-b+\sigma^{-1}y^k).
\]</span> <strong>Step 2</strong> <span class="math display">\[
\begin{array}{rcl}
x^{k+1}&amp;=&amp;\arg \min_{x} \left\{ L_\sigma (u^{k+1},x;y^k)+\frac{\sigma}{2}||x-x^k||^2_\mathcal T\right\}\\
&amp;=&amp; \arg\min_x \left\{\lambda ||x||_1+\frac{\sigma}{2}||u^{k+1}+Ax-b+\sigma^{-1}y^k||^2+\frac{\sigma}{2}||x-x^k||^2_\mathcal T\right\}.
\end{array}
\]</span> Observe that if <span class="math inline">\(\mathcal T=0\)</span>, solving the subproblem is as difficult as solving the original problem. Suppose we choose <span class="math display">\[
\mathcal T=\rho I-A^TA
\]</span> where <span class="math inline">\(\rho\)</span> denotes the largest eigenvalue of <span class="math inline">\(A^TA\)</span>. Such a choice of <span class="math inline">\(\mathcal T\)</span> reduces the semi-proximal ADMM to the so-called linearized ADMM. Then we reduce the subproblem to $$
<span class="math display">\[\begin{array}{rcl}
x^{k+1}&amp;=&amp;\arg\min_x\left\{
\begin{array}{l}
\lambda ||x||_1+\frac{\sigma}{2}||Ax+u^{k+1}-b+\sigma^{-1}y^k||^2+\frac{\sigma}{2}||x-x^k||^2_\mathcal T
\end{array}\]</span>
<p>}\</p>
&amp;=&amp; _x{
<span class="math display">\[\begin{array}{l}
\lambda ||x||_1+\frac{\sigma }{2}\left(\langle x,A^TAx\rangle+2\langle x,A^T(u^{k+1}-b+\sigma^{-1}y^k)\rangle\\
+\langle x,(\rho I-A^TA)x\rangle -2\langle x,(\rho I-A^TA)x^k\rangle 
\right)
\end{array}\]</span>
<p>}\</p>
&amp;=&amp; _x{
<span class="math display">\[\begin{array}{l}
\lambda ||x||_1+\frac{\sigma }{2}\left(\rho\langle x,x\rangle +2\langle x,A^T(u^{k+1}-b+\sigma^{-1}y^k)-(\rho I-A^TA)x^k\rangle\right)
\end{array}\]</span>
<p>}\</p>
<p>&amp;=&amp; _x{||x||_1+||x-h||^2}(), \end{array} <span class="math display">\[
where
\]</span> h=x<sup>k-</sup>{-1 }A<sup>T(u</sup>{k+1}+Ax<sup>k-b+</sup>{-1}y^k). <span class="math display">\[
**Step 3**
\]</span> y<sup>{k+1}=y</sup>k+()(Ax<sup>{k+1}+u</sup>{k+1}-b). $$</p>
<h2 id="directly-extended-admm-for-multi-block-convex-programming-problem">8.2 Directly extended ADMM for multi-block convex programming problem</h2>
<p>It is natural for one directly extend the 2-block ADMM. But it does not work.</p>
<h2 id="a-symmetric-gauss-seidel-decomposition-theorem">8.3 A symmetric Gauss-Seidel decomposition theorem</h2>
<p>Let <span class="math inline">\(s\ge 2\)</span> be a given integer and <span class="math inline">\(\mathcal X=\mathcal X_1\times \mathcal X_2\times \dotsm\times \mathcal X_s\)</span>. For any <span class="math inline">\(x\in\mathcal X\)</span> we write <span class="math inline">\(x=(x_1,x_2,\dotsm,x_s)\in\mathcal X\)</span>. Let <span class="math inline">\(\mathcal H:\mathcal X\rightarrow \mathcal X\)</span> be a given self-adjoint positive semidefinite linear operator. Consider the following decomposition <span class="math display">\[
\mathcal Hx = 
\left[\begin{array}{rcl}
\mathcal H_{11}&amp;\mathcal H_{12}&amp; \dotsm&amp; \mathcal H_{1s}\\
\mathcal H_{12}^*&amp;\mathcal H_{22}&amp; \dotsm&amp; \mathcal H_{2s}\\
\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\
\mathcal H_{1s}^*&amp;\mathcal H_{2s}^*&amp; \dotsm&amp; \mathcal H_{ss}
\end{array}\right]
\begin{bmatrix}
x_1\\x_2\\ \vdots \\ x_s
\end{bmatrix},
\]</span> where <span class="math inline">\(\mathcal H_{ii}:\mathcal X_i\rightarrow \mathcal X_i,\; i=1,\dotsm,s\)</span> are self-adjoint positive semidefinite linear operator, <span class="math inline">\(\mathcal H_{ij}:\mathcal X_j\rightarrow \mathcal X_i,\; i=1,\dotsm,s-1,j&gt;i\)</span> are linear maps. Here, we further assume that <span class="math display">\[
\mathcal H_{ii}\succ 0,\quad \forall i=1,\dotsm,s.
\]</span></p>
<p>Define <span class="math display">\[
x_{\le i}=(x_1,x_2,\dotsm,x_i),\; x_{\ge i}=(x_i,x_{i+1},\dotsm,x_s),\; i=0,\dotsm,s+1
\]</span> with the convention that <span class="math inline">\(x_{\le 0}=x_{\ge s+1}=\emptyset\)</span>.</p>
<p>Denote the linear operator <span class="math inline">\(\mathcal U,\mathcal D:\mathcal X\rightarrow \mathcal X\)</span> by <span class="math display">\[
\mathcal U=
\begin{bmatrix}
0 &amp; \mathcal H_{12} &amp; \dotsm &amp; \mathcal H_{1s}\\
&amp;\ddots &amp; \dotsm&amp;\vdots\\
&amp;&amp; 0 &amp;\mathcal H_{(s-1)s}\\
&amp;&amp;&amp;0
\end{bmatrix}\quad \mathcal D=\text{diag}(\mathcal H_{11},\mathcal H_{22},\dotsm,\mathcal H_{ss}).
\]</span> Then we have <span class="math inline">\(\mathcal H=\mathcal D+\mathcal U+\mathcal U^*\)</span> and <span class="math inline">\(\mathcal D\succ 0\)</span>. Let <span class="math inline">\(r=(r_1,r_2,\dotsm,r_s)\in\mathcal X\)</span> be given. Define the convex quadratic function <span class="math inline">\(h:\mathcal X\rightarrow \mathbb R\)</span> by <span class="math display">\[
h(x)=\frac{1}{2}\langle x,\mathcal Hx\rangle -\langle r,x\rangle ,\quad x\in \mathcal X.
\]</span> Let <span class="math inline">\(\phi:\mathcal X_1\rightarrow (-\infty,\infty]\)</span> be a given closed proper convex function. Define the following self-adjoint positive semidefinite linear operator <span class="math inline">\(\mathcal T:\mathcal X\rightarrow \mathcal X\)</span> as <span class="math display">\[
\mathcal T=\mathcal U\mathcal D^{-1}\mathcal U^*.
\]</span></p>
<p>Denote <span class="math inline">\(\delta&#39; = (\delta_1&#39;,\dotsm,\delta_s&#39;)\)</span> and <span class="math inline">\(\delta^+=(\delta_1^+,\dotsm,\delta_s^+)\)</span> with <span class="math inline">\(\delta_1&#39;=\delta_1^+\)</span>. Denote <span class="math display">\[
\Delta(\delta&#39;,\delta^+)=\delta&#39;+(\mathcal D+\mathcal U)\mathcal D^{-1}(\delta^+-\delta&#39;).
\]</span> Let <span class="math inline">\(\bar x\)</span> be given. Define <span class="math display">\[
\begin{array}{rcl}
x^+ &amp;=&amp;\arg\min_x\left\{\phi(x_1)+h(x)+\frac{1}{2}||x-\bar x||_\mathcal T^2-\langle x,\Delta (\delta&#39;,\delta^+)\rangle\right\}\\
&amp;=&amp; \arg\min_x\left\{\phi(x_1)+\frac{1}{2}\langle x,\mathcal Hx\rangle -\langle r,x\rangle+\frac{1}{2}||x-\bar x||_\mathcal T^2-\langle x,\Delta (\delta&#39;,\delta^+)\rangle\right\}\\
\end{array}
\]</span> The optimality condition for <span class="math inline">\(x^+\)</span> is <span class="math display">\[
(\mathcal H+\mathcal T)x=r-\gamma +\mathcal T \bar x+\Delta(\delta&#39;,\delta^+),
\]</span> where <span class="math inline">\(\gamma = (\gamma_1,0,\dotsm,0)\)</span>, <span class="math inline">\(\gamma_1 \in \partial \phi(x_1)\)</span>.</p>
<p>The meaning of <span class="math inline">\(\Delta(\delta&#39;,\delta^+)\)</span> is some numerical error when we solve the subproblem, since the subproblem cannot be solved exactly precisely.</p>
<p>The following theorem describe an equivalent symmetric Gauss-Seidel procedure for computing <span class="math inline">\(x^+\)</span>.</p>
<p><strong>Theorem</strong> (sGS Decomposition)</p>
<p>Assume that <span class="math inline">\(\mathcal H_{ii}\succ 0,\; \forall i=1,\dotsm,s\)</span> holds. Then we have <span class="math display">\[
\mathcal H+\mathcal T=(\mathcal D+\mathcal U)\mathcal D^{-1}(\mathcal D+\mathcal U^*)\succ 0.
\]</span> Furthermore, for <span class="math inline">\(i=s,\dotsm,2\)</span>, define <span class="math inline">\(x&#39;_i\in\mathcal X_i\)</span> by <span class="math display">\[
\begin{array}{rcl}
x_i&#39; &amp;=&amp; \arg\min_{x_i\in\mathcal X_i} \{\phi(\bar x_1)+h(\bar x_{\le i-1},x_i,x&#39;_{\ge i+1})-\lang\delta_i&#39;,x_i\rangle\}\\
&amp;=&amp;\mathcal H_{ii}^{-1}(r_i+\delta_i&#39;-\sum_{j=1}^{i-1} \mathcal H_{ji}^*\bar x_j-\sum_{j=i+1}^s \mathcal H_{ij}x&#39;_j).
\end{array}
\]</span> Then the optimal solution <span class="math inline">\(x^+\)</span> defined by <span class="math display">\[
x^+=\arg\min_x\left\{\phi(x_1)+h(x)+\frac{1}{2}||x-\bar x||_\mathcal T^2-\left\langle x,\Delta (\delta&#39;,\delta^+)\right\rangle\right\},
\]</span> can be obtained exactly via <span class="math display">\[
\begin{cases}
x_1^+ &amp; = &amp; \arg\min_{x_1}\phi(x_1)+h(x_1,x&#39;_{\ge 2})-\langle \delta_1^+,x_1\rangle\\
x_i^+&amp;=&amp; \arg\min _{x_i} \phi(x_1^+)+h(x^+_{\le i-1},x_i,x&#39;_{\ge i+1})-\langle \delta_i^+,x_i\rangle\\
&amp;=&amp; \mathcal H_{ii}^{-1}(r_i+\delta_i&#39;-\sum_{j=1}^{i-1} \mathcal H_{ji}^* x_j^+-\sum_{j=i+1}^s \mathcal H_{ij}x&#39;_j), \quad i=2,\dotsm,s.
\end{cases}
\]</span> Proof.</p>
<p>It is obvious <span class="math inline">\(\mathcal H+\mathcal T=(\mathcal D+\mathcal U)\mathcal D^{-1}(\mathcal D+\mathcal U^*)\succ 0\)</span>.</p>
<p>Then <span class="math display">\[
\begin{array}{rcl}
x_i&#39; &amp;=&amp; \arg\min_{x_i\in\mathcal X_i} \{\phi(\bar x_1)+h(\bar x_{\le i-1},x_i,x&#39;_{\ge i+1})-\lang\delta_i&#39;,x_i\rangle\}\\
&amp;=&amp; \arg\min_{x_i\in\mathcal X_i} \left\{\begin{array}{l}
\frac{1}{2}\langle (\bar x_1,\dotsm,\bar x_{i-1},x_i,x&#39;_{i+1},\dotsm,x&#39;_s),\mathcal H(\bar x_1,\dotsm,\bar x_{i-1},x_i,x&#39;_{i+1},\dotsm,x&#39;_s)\rangle \\
-\langle r,(\bar x_1,\dotsm,\bar x_{i-1},x_i,x&#39;_{i+1},\dotsm,x&#39;_s)\rangle\\
-\lang\delta_i&#39;,x_i\rangle
\end{array}\right\}\\
&amp;=&amp; \arg\min_{x_i\in\mathcal X_i} \left\{\begin{array}{l}
\frac{1}{2}(
\sum_{j=1}^{i-1} x_i\mathcal H_{ji}^*\bar x_j+x_i\mathcal H_{ii}x_i+\sum_{j=i+1}^s x_i\mathcal H_{ij}x&#39;_j\\
+\sum_{j=1}^{i-1}  x_i\mathcal H_{ji}^*\bar x_j+\sum_{j=i+1}^s x_i\mathcal H_{ij}x_j&#39;)\\
-\langle\delta_i&#39;+r_i,x_i\rangle
\end{array}\right\}\\
&amp;=&amp; \arg\min_{x_i\in\mathcal X_i} \left\{\begin{array}{l}
\sum_{j=1}^{i-1} x_i\mathcal H_{ji}^*\bar x_j+\frac{1}{2}x_i\mathcal H_{ii}x_i+\sum_{j=i+1}^s x_i\mathcal H_{ij}x&#39;_j-\langle\delta_i&#39;+r_i,x_i\rangle
\end{array}\right\}.
\end{array}
\]</span> The optimality condition is given by <span class="math display">\[
\sum_{j=1}^{i-1} \mathcal H_{ji}^*\bar x_j+\mathcal H_{ii}x_i+\sum_{j=i+1}^s \mathcal H_{ij}x&#39;_j-\delta_i&#39;-r_i=0.
\]</span> Then we have <span class="math display">\[
x_i&#39;=\mathcal H_{ii}^{-1}\left(r_i+\delta_i&#39;-\sum_{j=1}^{i-1} \mathcal H_{ji}^*\bar x_j-\sum_{j=i+1}^s \mathcal H_{ij}x&#39;_j\right).
\]</span> The remaining part is to prove that <span class="math display">\[
\begin{cases}
x_1^+ &amp; = &amp; \arg\min_{x_1}\phi(x_1)+h(x_1,x&#39;_{\ge 2})-\langle \delta_1^+,x_1\rangle\\
x_i^+ &amp; = &amp; \mathcal H_{ii}^{-1}(r_i+\delta_i&#39;-\sum_{j=1}^{i-1} \mathcal H_{ji}^* x_j^+-\sum_{j=i+1}^s \mathcal H_{ij}x&#39;_j), \quad i=2,\dotsm,s
\end{cases}
\]</span> is equivalent to <span class="math display">\[
x^+=\arg\min_x\left\{\phi(x_1)+h(x)+\frac{1}{2}||x-\bar x||_\mathcal T^2-\langle x,\Delta (\delta,\delta^+)\rangle\right\}.
\]</span> We define <span class="math display">\[
\begin{array}{rcl}
x_1&#39;&amp;=&amp;\arg\min_{x_1} \phi(x_1)+h(x_1,x&#39;_{\ge 2})-\langle \delta_1,x_1\rangle\\
&amp;=&amp; \arg\min_{x_1} \phi(x_1)+h(x_1,x&#39;_{\ge 2})-\langle \delta_1^+,x_1\rangle\\
&amp;=&amp; x_1^+.
\end{array}
\]</span> Since we have <span class="math inline">\(\delta_1=\delta^+_1\)</span>, and we check the optimality condition we have <span class="math display">\[
\begin{cases}
\mathcal H_{11} x_1&#39;&amp;=&amp;r_1-\gamma _1+\delta _1&#39;-\sum_{j=2}^{s}\mathcal H_{ij}x_j&#39;\\
\mathcal H_{11}x_1^+&amp;=&amp;r_1-\gamma _1+\delta _1^+-\sum_{j=2}^{s}\mathcal H_{ij}x_j&#39;.
\end{cases}
\]</span> By using $ x_1'=H_{11}^{-1}(r_1-<em>1+<em>1'-</em>{j=2}^{s}H</em>{1j}x_j')$ and <span class="math inline">\(x_i&#39;=\mathcal H_{ii}^{-1}\left(r_i+\delta_i&#39;-\sum_{j=1}^{i-1} \mathcal H_{ji}^*\bar x_j-\sum_{j=i+1}^s \mathcal H_{1j}x&#39;_j\right)\)</span>, we have <span class="math display">\[
\begin{array}{rcccl}
\mathcal H_{11} x_1&#39;&amp;=&amp;r_1&amp;-\gamma _1&amp;+\delta _1&#39;&amp;&amp;-\sum_{j=2}^{s}\mathcal H_{1j}x_j&#39;\\
\mathcal H_{22}x_2&#39;&amp;=&amp;r_2&amp;-0&amp;+\delta_2&#39;&amp;- \mathcal H_{12}^*\bar x_1&amp;-\sum_{j=3}^s \mathcal H_{2j}x&#39;_j\\
&amp;\vdots&amp;\\
\mathcal H_{(s-1)(s-1)}x_{s-1}&#39;&amp;=&amp;r_{s-1}&amp;-0&amp;+\delta_{s-1}&#39;&amp;-\sum_{j=1}^{s-2} \mathcal H_{j({s-1})}^*\bar x_j&amp;- \mathcal H_{(s-1)s}x&#39;_s\\
\mathcal H_{ss} x_s&#39;&amp;=&amp;r_s&amp;-0&amp;+\delta_s&#39;&amp;-\sum_{j=1}^{s-1} \mathcal H_{js}^*\bar x_j.
\end{array}
\]</span> Then we have <span class="math display">\[
\mathcal D x&#39;=r-\gamma+\delta&#39;-\mathcal U^* \bar x-\mathcal Ux&#39;\\
\iff\\
(\mathcal D+\mathcal U)x&#39;=r-\gamma +\delta&#39;-\mathcal U^*\bar x.
\]</span> From <span class="math display">\[
\begin{cases}
x_1^+ &amp; = &amp; \arg\min_{x_1}\phi(x_1)+h(x_1,x&#39;_{\ge 2})-\langle \delta_1^+,x_1\rangle\\
x_i^+ &amp; = &amp; \mathcal H_{ii}^{-1}(r_i+\delta_i&#39;-\sum_{j=1}^{i-1} \mathcal H_{ji}^* x_j^+-\sum_{j=i+1}^s \mathcal H_{ij}x&#39;_j), \quad i=2,\dotsm,s
\end{cases}
\]</span> and <span class="math display">\[
\mathcal H_{11}x_1^+=r_1-\gamma _1+\delta _1^+-\sum_{j=2}^{s}\mathcal H_{ij}x_j&#39;,
\]</span> we have <span class="math display">\[
(\mathcal D+\mathcal U^*)x^+=r-\gamma +\delta^+-\mathcal U x&#39;.
\]</span> Since we have <span class="math inline">\(x&#39;=(\mathcal D+\mathcal U)^{-1}(r-\gamma +\delta&#39;-\mathcal U^*\bar x)\)</span>, we have <span class="math display">\[
\begin{array}{rcl}
(\mathcal D+\mathcal U^*)x^+&amp;=&amp;r-\gamma +\delta^+-\mathcal U (\mathcal D+\mathcal U)^{-1}(r-\gamma +\delta&#39;-\mathcal U^*\bar x)\\
&amp;=&amp; ((\mathcal D+\mathcal U)(\mathcal D+\mathcal U)^{-1} -\mathcal U (\mathcal D+\mathcal U)^{-1})(r-\gamma) +\mathcal U (\mathcal D+\mathcal U)^{-1}\mathcal U^*\bar x+\delta^+-\mathcal U (\mathcal D+\mathcal U)^{-1}\delta&#39;\\
&amp;=&amp; \mathcal D(\mathcal D+\mathcal U)^{-1}(r-\gamma) +\mathcal U (\mathcal D+\mathcal U)^{-1}\mathcal U^*\bar x+\delta^+-\mathcal U (\mathcal D+\mathcal U)^{-1}\delta&#39;.
\end{array}
\]</span> Then we have <span class="math display">\[
\begin{array}{rcl}
(\mathcal D+\mathcal U)\mathcal D^{-1}(\mathcal D+\mathcal U^*)x^+
&amp;=&amp;r-\gamma +(\mathcal D+\mathcal U)\mathcal D^{-1}\mathcal U (\mathcal D+\mathcal U)^{-1}\mathcal U^*\bar x+\delta^+-(\mathcal D+\mathcal U)\mathcal D^{-1}\mathcal U (\mathcal D+\mathcal U)^{-1}\delta&#39;,
\end{array}
\]</span> We have the fact <span class="math display">\[
\begin{array}{rcl}
(\mathcal D+\mathcal U)\mathcal D^{-1}\mathcal U (\mathcal D+\mathcal U)^{-1}&amp;=&amp;
(\mathcal U+\mathcal U \mathcal D^{-1}\mathcal U) (\mathcal D+\mathcal U)^{-1}\\
&amp;=&amp; \mathcal U(\mathcal D+\mathcal U)^{-1}+\mathcal U\mathcal D^{-1}\mathcal U (\mathcal D+\mathcal U)^{-1}\\
&amp;=&amp; \mathcal U(\mathcal D+\mathcal U)^{-1}+\mathcal U(\mathcal D^{-1}-(\mathcal D+\mathcal U)^{-1})\\
&amp;=&amp; \mathcal U\mathcal D^{-1}.\\
\end{array}
\]</span> Then we have <span class="math display">\[
\begin{array}{rcl}
(\mathcal H+\mathcal T)x^+
&amp;=&amp;r-\gamma +\mathcal T\bar x+\delta^++\Delta(\delta&#39;,\delta^+).
\end{array}
\]</span> Q.E.D.</p>
<p><strong>Example</strong> <span class="math display">\[
\min\{p(x_1)+\frac{1}{2}\langle x,\mathcal Px\rangle -\langle g,x\rangle\;|\; \mathcal Ax=d\},
\]</span> where <span class="math inline">\(\mathcal P\)</span> is a positive semidefinite linear operator on <span class="math inline">\(\mathcal X\)</span>, and <span class="math inline">\(\mathcal A:\mathcal X\rightarrow \mathcal Y\)</span> is a given linear map, and <span class="math inline">\(g\in\mathcal X\)</span>, and <span class="math inline">\(d\in\mathcal Y\)</span> are given data. The Lagrangian function is given as <span class="math display">\[
\mathcal L_\sigma (x;y)=p(x_1)+\frac{1}{2}\langle x,\mathcal Px\rangle -\langle g,x\rangle+\frac{\sigma }{2} ||\mathcal Ax-d+\sigma ^{-1}y||^2-\frac{1}{2\sigma}||y||^2.
\]</span> Proximal ALM method is given as</p>
<p><strong>Step 1</strong> <span class="math display">\[
\begin{array}{rcl}
x^{k+1}&amp;=&amp;\arg\min_x\{\mathcal L_\sigma(x;y^k)+\frac{1}{2}||x-x^k||_\mathcal T^2\;|\; x\in\mathcal X\}\\
&amp;=&amp;\arg\min_x\{p(x_1)+
\frac{1}{2}\langle x,\mathcal Px\rangle -\langle g,x\rangle+
\frac{\sigma }{2} ||\mathcal Ax-d+\sigma ^{-1}y||^2
+\frac{1}{2}||x-x^k||_\mathcal T^2\;|\; x\in\mathcal X\}\\
&amp;=&amp;\arg\min_x\{p(x_1)+
\frac{1}{2}\langle x,\mathcal Px\rangle -\langle g,x\rangle
+\frac{\sigma}{2}\langle x,\mathcal A^*\mathcal Ax\rangle
+\sigma\langle x,\mathcal A^*(-d+\sigma^{-1}y)\rangle
+\frac{1}{2}||x-x^k||_\mathcal T^2\;|\; x\in\mathcal X\}\\
&amp;=&amp;\arg\min_x\{p(x_1)
+\frac{1}{2}\langle x,(\mathcal P+\sigma \mathcal A^*\mathcal A)x\rangle
-\langle g+ \mathcal A^*(\sigma d-y),x\rangle
+\frac{1}{2}||x-x^k||_\mathcal T^2\;|\; x\in\mathcal X\}.
\end{array}
\]</span> If we define <span class="math inline">\(b = g+ \mathcal A^*(\sigma d-y)\)</span>, then we have <span class="math display">\[
x^{k+1}=\arg\min _x \left\{p(x_1)
+\frac{1}{2}\langle x,(\mathcal P+\sigma \mathcal A^*\mathcal A)x\rangle
-\langle b,x\rangle
+\frac{1}{2}||x-x^k||_\mathcal T^2\;|\; x\in\mathcal X\right\}.
\]</span> Then if we choose <span class="math inline">\(\mathcal T= \mathcal T_{\mathcal P+\sigma \mathcal A^*\mathcal A}\)</span>, sGS decomposition can be applied.</p>
<p><strong>Step 2</strong></p>
<p>Compute <span class="math inline">\(y^{k+1}=y^k+\tau\sigma (\mathcal Ax^k-d)\)</span>, where <span class="math inline">\(\tau\in(0,2)\)</span> is the dual step-length.</p>
<p><strong>Example</strong></p>
<p>The important class of standard convex quadratic semidefinite programming (QSDP) in the dual form is given by <span class="math display">\[
\min\left\{\frac{1}{2}\langle W,\mathcal HW\rangle -\langle h,\xi\rangle \;|\; Z+\mathcal B^*\xi+\mathcal H W=C,\xi\in\mathbb R^p,Z\in\mathbb S^n_+,W\in\mathcal W\right\},
\]</span> where <span class="math inline">\(\mathcal H:\mathbb S^n\rightarrow \mathbb S^n\)</span> is a self-adjoint positive semidefinite linear operator.</p>
<p>In this problem, we have <span class="math display">\[
\mathcal Ax = \left[
\begin{array}{rcl}
I &amp;\mathcal B^* &amp; \mathcal H
\end{array}
\right]
\left(
\begin{array}{c}
Z\\ \xi\\  W
\end{array}
\right)=C\\
\mathcal P = \text{diag}(0,0,\mathcal H).
\]</span> Then we have <span class="math display">\[
\mathcal Q = \mathcal P+\sigma \mathcal A^*\mathcal A = 
\begin{bmatrix}
0,0,0\\
0,0,0\\
0,0,\mathcal H
\end{bmatrix}+
\sigma 
\begin{bmatrix}
I\\\mathcal B\\\mathcal H
\end{bmatrix}
\begin{bmatrix}
I&amp;\mathcal B^*&amp;\mathcal H
\end{bmatrix}=
\sigma 
\begin{bmatrix}
I &amp; \mathcal B^* &amp;\mathcal H \\
\mathcal B &amp; \mathcal B\mathcal B^*&amp;\mathcal B\mathcal H\\
\mathcal H &amp; \mathcal H\mathcal B^* &amp; \sigma^{-1}\mathcal H+\mathcal H^2
\end{bmatrix}.
\]</span></p>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/36/">36</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>


          </div>
          

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc" data-target="post-toc-wrap">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview" data-target="site-overview-wrap">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Cheng-Zilong</p>
  <div class="site-description" itemprop="description"></div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">71</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span>
        </a>
      </div>
    
  </nav>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:zilongcheng@u.nus.edu" title="E-Mail &rarr; mailto:zilongcheng@u.nus.edu" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
    
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Cheng-Zilong</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.3.0</div>

        












        
      </div>
    </footer>
  </div>

  
    
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/jquery/index.js?v=3.4.1"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.3.0"></script><script src="/js/motion.js?v=7.3.0"></script>
<script src="/js/schemes/pisces.js?v=7.3.0"></script>

<script src="/js/next-boot.js?v=7.3.0"></script>



  





















  

  
    
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    
  

  

  


<script>
NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(item => {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'k1NFV6E2jjtcuFpWbPUwvs04-MdYXbMMI',
    appKey: 'oCso3hdINWUXi0EtP7BsCUoY',
    placeholder: 'Just go go',
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: true,
    lang: '' || 'zh-cn',
    path: location.pathname
  });
}, window.Valine);
</script>

</body>
</html>
