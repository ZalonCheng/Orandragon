<!DOCTYPE html>





<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.3.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2">
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.3.0',
    exturl: false,
    sidebar: {"position":"right","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    }
  };
</script>

  <meta name="keywords" content="Optimization, Machine Learning">
<meta property="og:type" content="website">
<meta property="og:title" content="Cheng-Zilong">
<meta property="og:url" content="http://yoursite.com/page/3/index.html">
<meta property="og:site_name" content="Cheng-Zilong">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Cheng-Zilong">
  <link rel="canonical" href="http://yoursite.com/page/3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Cheng-Zilong</title>
  <meta name="generator" content="Hexo 3.9.0">
  








  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Cheng-Zilong</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">Learning Notes</p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            
  <div id="posts" class="posts-expand">
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/12/22/MA6268 Nonlinear Optimization/7.2 Nonlinear conic programming/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Cheng-Zilong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cheng-Zilong">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2020/12/22/MA6268 Nonlinear Optimization/7.2 Nonlinear conic programming/" class="post-title-link" itemprop="url">7. Nonlinear conic programming (2)</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2020-12-22 13:48:40" itemprop="dateCreated datePublished" datetime="2020-12-22T13:48:40+08:00">2020-12-22</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-10-31 22:11:14" itemprop="dateModified" datetime="2019-10-31T22:11:14+08:00">2019-10-31</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/MA6268-Nonlinear-Optimization/" itemprop="url" rel="index"><span itemprop="name">MA6268 Nonlinear Optimization</span></a></span>

                
                
              
            </span>
          

          
            <span id="/2020/12/22/MA6268 Nonlinear Optimization/7.2 Nonlinear conic programming/" class="post-meta-item leancloud_visitors" data-flag-title="7. Nonlinear conic programming (2)" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
        
      
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2020/12/22/MA6268 Nonlinear Optimization/7.2 Nonlinear conic programming/#comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/2020/12/22/MA6268 Nonlinear Optimization/7.2 Nonlinear conic programming/" itemprop="commentCount"></span></a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="robinsons-constraint-qualification">7.1 Robinson’s constraint qualification</h2>
<p>In order for the KKT conditions to be necessary for the local minimizer <span class="math inline">\(\bar x\)</span>, we need to introduce some conditions to ensure the existence of Lagrange multipliers and the boundedness of <span class="math inline">\(\mathcal M(\bar x)\)</span>. This is the generalization of the linear independent constraint qualification (LICQ) in chapter 5.</p>
<p>Note that <span class="math inline">\(G&#39;(\bar x)\)</span> is the Jacobian of <span class="math inline">\(G\)</span>, and we have <span class="math inline">\(\nabla G=(G&#39;)^T\)</span>.</p>
<p><strong>Definition</strong> (Robinson’s constraint qualification)</p>
<p>Let <span class="math inline">\(\bar x\)</span> be a feasible solution to COP. Robinson’s constraint qualification is said to hold at <span class="math inline">\(\bar x\)</span> if <span class="math display">\[
0\in\text{int}\left(G(\bar x)+G&#39;(\bar x)\mathcal X-\mathcal K\right).
\]</span> <strong>Remark</strong></p>
<p>If <span class="math inline">\(A:\mathbb R^n\rightarrow \mathbb R^m\)</span>, then <span class="math inline">\(0\in\text{int }(A\mathbb R^n)\)</span> means <span class="math inline">\(\text{Range}(A)=\mathbb R^m\)</span>.</p>
<p><strong>Example</strong></p>
<p>For the basic nonlinear programming, Robinson's CQ can be written as <span class="math display">\[
0\in \text{int}\left(\begin{bmatrix}g(\bar x)\\h(\bar x)\end{bmatrix}
+\begin{bmatrix}g&#39;(\bar x)\\h&#39;(\bar x)\end{bmatrix}\mathbb R^n
-\begin{bmatrix}\{0^m\}\\\mathbb R^p_+\end{bmatrix}\right).
\]</span> This is the Mangasarian-Fromovitz constraint qualification (MFCQ) given explicitly as <span class="math display">\[
\begin{array}{l}
\exists d\in \mathbb R^n\text{ such that }\\
\langle \nabla g_i(\bar x),d\rangle=0,\quad \forall i=1,2,\dotsm,m\\
\langle \nabla h_j(\bar x),d\rangle&gt;0,\quad \forall j\in J(\bar x).
\end{array}
\]</span> If we define <span class="math display">\[
\begin{array}{rcl}
B_g(\bar x)&amp;=&amp;[\nabla g_1(\bar x),\dotsm,\nabla g_m(\bar x)]\\
B_h(\bar x)&amp;=&amp;\{\nabla h_j(\bar x)\;|\;j\in J(\bar x)\}\\
B(\bar x)&amp;=&amp;[B_g(\bar x),B_h(\bar x)]\in\mathbb R^{n\times (m+|J|)}.
\end{array}
\]</span> The above condition is equivalent to saying that <span class="math inline">\(B_g(\bar x)\)</span> has full column rank and the systems <span class="math display">\[
B_g(\bar x)^Td=0^m,\quad B_h(\bar x)^Td&gt;0
\]</span> have a solution. It is easy to show that LICQ implies MFCQ.</p>
<p><strong>Proposition</strong></p>
<p>Assume that <span class="math inline">\(G(\bar x)\in\mathcal K\)</span>. Then the following conditions are equivalent to each other and to Robinson's CQ.</p>
<ol type="1">
<li><span class="math inline">\(G&#39;(\bar x)\mathcal X+T_{\mathcal K}(G(\bar x))=\mathcal Y\)</span></li>
<li><span class="math inline">\([G&#39;(\bar x)\mathcal X]^\perp\cap N_\mathcal K(G(\bar x))=\{0\}\)</span>.</li>
</ol>
<p>Proof is not trivial and omitted.</p>
<p>For a set <span class="math inline">\(S\)</span> in <span class="math inline">\(\mathcal Y\)</span> and a point <span class="math inline">\(y\in S\)</span>, the <strong>tangent cone</strong> to <span class="math inline">\(S\)</span> at <span class="math inline">\(y\)</span> is defined by <span class="math display">\[
T_S(y)=\{d\in\mathcal Y\;|\; \exists t_k\downarrow0,\text{dist}(y+t_kd,S)=o(t_k)\}.
\]</span> It is saying that <span class="math inline">\(\frac{\text{dist} (y+t_kd,S)}{t_k}\rightarrow 0\)</span> as <span class="math inline">\(t_k\rightarrow 0\)</span>.</p>
<p>Note that if <span class="math inline">\(S\)</span> is a nonempty convex subset of <span class="math inline">\(\mathcal Y\)</span>, then <span class="math display">\[
T_S(y)=\text{closure} (t(x-y)\;|\; x\in S,t\ge 0).
\]</span> <strong>Remark</strong></p>
<ol type="1">
<li><p>For <span class="math inline">\(\mathcal C=\mathbb R^p_+\)</span> and <span class="math inline">\(y\in\mathcal C\)</span>. Let <span class="math inline">\(J(y)=\{j\;|\; y_j=0\}\)</span>. We have <span class="math display">\[
T_\mathcal C(y)=\{d\in\mathbb R^p\;|\;d_j\ge 0,j\in J(y)\}.
\]</span></p></li>
<li><p>For NLP, it follows from the above proposition that Robinson's CQ is equivalent to the following, <span class="math display">\[
\begin{bmatrix}g&#39;(\bar x)\\h&#39;(\bar x)\end{bmatrix}\mathbb R^n
+
\begin{bmatrix}\{0^m\}\\T_{\mathbb R^p_+}(h(\bar x))\end{bmatrix}=
\begin{bmatrix}\mathbb R^m\\ \mathbb R^p\end{bmatrix}.
\]</span></p></li>
</ol>
<p><strong>Proposition</strong></p>
<p>Assume that <span class="math inline">\(G(\bar x)\in\mathcal K\)</span>. If <span class="math inline">\(\mathcal K\)</span> has a nonempty interior, then the Robinson's CQ is equivalent to there exists <span class="math inline">\(d\in\mathcal X\)</span> such that <span class="math display">\[
G(\bar x)+G&#39;(\bar x)d\in\text{int}(\mathcal K).
\]</span> This proposition says that there exists linearization <span class="math inline">\(G(\bar x+d)\approx G(\bar x)+G&#39;(\bar x)d\)</span>, which is in the interior of the set <span class="math inline">\(\mathcal K\)</span>.</p>
<p>Proof.</p>
<p><span class="math inline">\(\implies\)</span></p>
<p>If there exists <span class="math inline">\(d\in\mathcal X\)</span> such that <span class="math inline">\(y= G(\bar x)+G&#39;(\bar x)d\in \text{int}(\mathcal K)\)</span>, then there exists an open ball <span class="math inline">\(B_\epsilon(y)\subset \text{int}(\mathcal K)\)</span>, which means <span class="math inline">\(B_\epsilon(0)\in \text{int}(\mathcal K-y)\)</span>. This means <span class="math inline">\(0\in \text{int}(G(\bar x)+G&#39;(\bar x)d-\mathcal K)\)</span>, which is the Robinson's CQ.</p>
<p><span class="math inline">\(\Longleftarrow\)</span></p>
<p>We will prove the necessity by contradiction. Suppose <span class="math inline">\(\forall d\in\mathcal X\)</span> such that <span class="math inline">\(G(\bar x)+G&#39;(\bar x)d\notin\text{int}(\mathcal K)\)</span>, which means <span class="math display">\[
\left(G(\bar x)+G&#39;(\bar x)\mathcal X\right) \cap \text{int}(\mathcal K)=\emptyset.
\]</span> Then by the proper separation theorem, there exists a nonzero <span class="math inline">\(\lambda\in\mathcal Y\)</span>, such that <span class="math display">\[
\langle \lambda,G(\bar x)+G&#39;(\bar x) d\rangle\ge \langle \lambda ,k\rangle\implies 
\langle \lambda,G(\bar x)+G&#39;(\bar x)d-k\rangle \ge 0,
\]</span> for all <span class="math inline">\(d\in \mathcal X\)</span> and <span class="math inline">\(k\in\mathcal K\)</span>.</p>
<p>Let <span class="math inline">\(y\in\mathcal Y\)</span>, such that <span class="math inline">\(\langle \lambda,y\rangle &lt;0\)</span>. Then for any <span class="math inline">\(t&gt;0\)</span>, we have <span class="math inline">\(\langle \lambda,ty\rangle&lt;0\)</span>, which means <span class="math inline">\(ty\notin G(\bar x)+G&#39;(\bar x)\mathcal X-K\)</span>. This means <span class="math inline">\(G(\bar x)+G&#39;(\bar x)\mathcal X-K\)</span> cannot contain an open ball centered at origin.</p>
<p><strong>Proposition</strong></p>
<p>Suppose that <span class="math inline">\(G(x)=(g(x),h(x))\)</span>, <span class="math inline">\(\mathcal K=\{0^m\}\times \mathcal C\)</span>, and <span class="math inline">\(G(\bar x)\in \mathcal K\)</span>. If <span class="math inline">\(\mathcal C\)</span> has a nonempty interior, then Robinson's CQ is equivalent to</p>
<ol type="1">
<li><span class="math inline">\(g&#39;(\bar x)\)</span> is onto and,</li>
<li><span class="math inline">\(\exists d\in\mathcal X\)</span> such that <span class="math inline">\(g&#39;(\bar x)d=0,h(\bar x)+h&#39;(\bar x)d\in \text{int}(\mathcal C)\)</span>.</li>
</ol>
<p>Proof.</p>
<p><span class="math inline">\(\Longleftarrow\)</span></p>
<p>Robinson’s CQ is saying that there exists <span class="math inline">\(\epsilon_1,\epsilon_2&gt;0\)</span>, for all <span class="math inline">\(y\in\mathbb R^m\)</span> such that <span class="math inline">\(||y||\le \epsilon_1\)</span> and for all <span class="math inline">\(z\in \mathcal V\)</span> such that <span class="math inline">\(||z||\le \epsilon_2\)</span>, such that there exists <span class="math inline">\(d\in\mathcal X\)</span> satisfying <span class="math display">\[
y\in g(\bar x)+g&#39;(\bar x)d-\{0^m\},\\
z\in h(\bar x)+h&#39;(\bar x)d-\mathcal C.
\]</span> From the first equation, it is obvious to show that <span class="math inline">\(g&#39;(\bar x)\)</span> is onto. (Since <span class="math inline">\(g(\bar x)=0\)</span>, <span class="math inline">\(y\in g&#39;(\bar x)\mathcal X\)</span>)</p>
<p>We can take <span class="math inline">\(y=0\)</span>, then we have <span class="math inline">\(d \in \text{null}(g&#39;(\bar x))\)</span>. Therefore, we have <span class="math display">\[
z\in h(\bar x)+h&#39;(\bar x) \text{null}(g&#39;(\bar x))-\mathcal C.
\]</span> Since <span class="math inline">\(\mathcal C\)</span> has nonempty interior, there exists <span class="math inline">\(d\in\mathcal X\)</span>, such that <span class="math inline">\(g&#39;(\bar x) d=0\)</span>, and then we have <span class="math display">\[
h(\bar x)+h&#39;(\bar x)d\in\mathcal C+z\implies h(\bar x)+h&#39;(\bar x)d\in \text{int}(\mathcal C).
\]</span> <span class="math inline">\(\implies\)</span></p>
<p>The proposition is equivalent to <span class="math display">\[
g&#39;(\bar x)\text{ is onto and }0\in \text{int}(h(\bar x)+h&#39;(\bar x)\text{Null}(g&#39;(\bar x))-\mathcal C).
\]</span> Then there exists <span class="math inline">\(\epsilon &gt;0\)</span> such that the open ball <span class="math inline">\(B_\epsilon (0)\subset \text{int}(h(\bar x)+h&#39;(\bar x)\text{Null}(g&#39;(\bar x))-\mathcal C)\)</span>. <span class="math inline">\(g&#39;(\bar x)\)</span> is onto implies there exists <span class="math inline">\(M&gt;0\)</span> such that for each <span class="math inline">\(y\in\mathbb R^m\)</span>, there exists <span class="math inline">\(d_1\in\mathcal X\)</span> such that <span class="math inline">\(g&#39;(\bar x)d_1=y\)</span> and <span class="math inline">\(||d_1||\le M||y||\)</span>.</p>
<p>Assume there exists <span class="math inline">\(\epsilon_1,\epsilon_2&gt;0\)</span>, for all <span class="math inline">\(y\in\mathbb R^m\)</span> such that <span class="math inline">\(||y||\le \epsilon_1\)</span> and for all <span class="math inline">\(z\in \mathcal V\)</span> such that <span class="math inline">\(||z||\le \epsilon_2\)</span>. Then there exists <span class="math inline">\(d\in\mathcal X\)</span> such that <span class="math inline">\(g&#39;(\bar x)d=y\)</span> and <span class="math inline">\(B_\epsilon (0)\subset \text{int}(h(\bar x)+h&#39;(\bar x)d-\mathcal C)\)</span> (This is the Robinson’s CQ) if and only if <span class="math inline">\(d_2=d-d_1\)</span> is such that <span class="math inline">\(g&#39;(\bar x)d_2=0\)</span>, and <span class="math display">\[
z\in h(\bar x)+h&#39;(\bar x)(d_1+d_2)-\mathcal C \iff z-h&#39;(\bar x)d_1\in h(\bar x)+h&#39;(\bar x)d_2-\mathcal C.
\]</span> The above condition can be checked easily by the following. Since we have <span class="math inline">\(||d_1||\le M||y||\)</span>, by choosing sufficient small <span class="math inline">\(\epsilon_1\)</span> and <span class="math inline">\(\epsilon_2\)</span>, we have <span class="math inline">\(B_\epsilon (0)\subset \text{int}(h(\bar x)+h&#39;(\bar x)\mathcal X-\mathcal C)\)</span>. Therefore, there exists <span class="math inline">\(\bar d\in\mathcal X\)</span> such that <span class="math inline">\(g&#39;(\bar x)\bar d=0\)</span> and <span class="math inline">\(z-h&#39;(\bar x)d_1\in h(\bar x)+h&#39;(\bar x)\bar d-\mathcal C\)</span>. Let <span class="math inline">\(d=\bar d+d_1\)</span>. Then Robinson’s CQ holds.</p>
<h2 id="first-order-necessary-conditions">7.2 First order necessary conditions</h2>
<p><strong>Proposition</strong></p>
<p>Let <span class="math inline">\(\bar x\)</span> be a locally optimal solution of (COP). Then the point <span class="math inline">\(d=0\)</span> is an optimal solution of the following problem <span class="math display">\[
\quad \begin{array}{rCl}
\min &amp; f&#39;(\bar x)d\\
\text{subject to}&amp; d\in T_\mathcal F(\bar x),
\end{array}
\]</span> where <span class="math inline">\(\mathcal F=\{x\in\mathcal X\;|\; G(x)\in\mathcal K\}\)</span> is the feasible region of (COP).</p>
<p>Proof.</p>
<p>Let <span class="math inline">\(d\in T_\mathcal K(\bar x)\)</span>. By the definition of the tangent cone, there exists <span class="math inline">\(t_k\downarrow 0\)</span> and <span class="math inline">\(x^k=\bar x+t_kd+o(t_k)\)</span> such that <span class="math inline">\(x^k\in \mathcal F\)</span>. Since <span class="math inline">\(\bar x\)</span> is a locally optimal solution of (COP), it follows that <span class="math display">\[
0\le \lim_{k\rightarrow \infty}\frac{f(x^k)-f(\bar x)}{t_k}=\lim_{k\rightarrow \infty}\frac{f(\bar x+t_kd+o(t_k))-f(\bar x)}{t_k}=f&#39;(\bar x)d.
\]</span> This completes the proof.</p>
<p>This proposition means when the point gets to the suboptimal point, there is no direction to reduce the value of the function. We check the following equation <span class="math display">\[
f(x+d)\approx f(x)+f&#39;(x)d,
\]</span> and we have <span class="math inline">\(\min_d f(x+d)=\min_d f&#39;(x)d\)</span>.</p>
<p><strong>Lemma</strong> (IMPORTANT)</p>
<p>If Robinson's CQ holds at a feasible point <span class="math inline">\(\bar x\)</span>, then there exists a constant <span class="math inline">\(c&gt;0\)</span> such that <span class="math display">\[
\text{dist}(x,G^{-1}(\mathcal K+y))\le c\text{ dist}(G(x)-y,\mathcal K)
\]</span> for all <span class="math inline">\((x,y)\)</span> in an open neighborhood of <span class="math inline">\((\bar x,0)\)</span>.</p>
<ol type="1">
<li>In particular, when <span class="math inline">\(y=0\)</span>, for all <span class="math inline">\(x\)</span> in a neighborhood of <span class="math inline">\(\bar x\)</span>, we have</li>
</ol>
<p><span class="math display">\[
\text{dist}(x,\mathcal F)=O(\text{dist}(G(x),\mathcal K)).
\]</span> 2. One has <span class="math display">\[
   0\in \text{int}(G(x)-\mathcal K).
   \]</span></p>
<p>This lemma is very important because it can be used to measure the distance from the current point to the feasible point. For example, if we have the constraint <span class="math inline">\(Ax=b\)</span>, it is difficult to know the distance <span class="math inline">\(\text{dist}(x^c,\mathcal F)\)</span>, but it is easy to calculate <span class="math inline">\(||b-Ax^c||\)</span>. Since <span class="math inline">\(\text{dist}(x^c,\mathcal F)\)</span> is bounded by <span class="math inline">\(||b-Ax^c||\)</span>, we can use <span class="math inline">\(||b-Ax^c||\)</span> to estimate the distance.</p>
<p><strong>Proposition</strong></p>
<p>Let <span class="math inline">\(\bar x\)</span> be a locally optimal solution of COP. If Robinson's CQ holds at <span class="math inline">\(\bar x\)</span>, then it holds that <span class="math display">\[
T_\mathcal F(\bar x)=\{d\in\mathcal X\;|\; G&#39;(\bar x)d\in T_\mathcal K(G(\bar x))\}.
\]</span> Hence <span class="math inline">\(d=0\)</span> is an optimal solution of the following problem, <span class="math display">\[
\text{(LOCP)}\quad \min_{d\in\mathcal X}\{f&#39;(\bar x)d\;|\; G&#39;(\bar x)d\in T_{\mathcal K}(G(\bar x))\}.
\]</span> Proof.</p>
<p>Let <span class="math inline">\(S(\bar x)=\{d\in\mathcal X\;|\; G&#39;(\bar x)d\in T_\mathcal K(G(\bar x))\}\)</span>. We need to prove <span class="math inline">\(T_\mathcal F(\bar x)= S(\bar x)\)</span>.</p>
<p>$$</p>
<p>For any <span class="math inline">\(d\in T_\mathcal F(\bar x)\)</span>, there exists <span class="math inline">\(t_k\downarrow 0\)</span> and <span class="math inline">\(x^k=\bar x+t_kd+o(t_k)\)</span> such that <span class="math inline">\(x^k \in\mathcal F\)</span> (i.e. <span class="math inline">\(G(x^k)\in\mathcal K\)</span>). Then we have <span class="math inline">\(G(x^k)=G(\bar x+t_kd+o(t_k))=G(\bar x)+t_kG&#39;(\bar x)d+o(t_k)\in\mathcal K\)</span>. By using the definition of the tangent cone, we have <span class="math inline">\(d\in S(\bar x)\)</span>.</p>
<p><span class="math inline">\(\Longleftarrow\)</span></p>
<p>Let <span class="math inline">\(d\in S(\bar x)\)</span>. Then there exists <span class="math inline">\(t_k\downarrow 0\)</span> such that <span class="math inline">\(G(\bar x)+t_kG&#39;(\bar x)d+o(t_k)\in\mathcal K\)</span>. Thus by the previous lemma, there exists a constant <span class="math inline">\(M\)</span> such that <span class="math inline">\(\text{dist}(\bar x+t_kd,\mathcal F)\le M\text{dist}(G(\bar x+t_k d),\mathcal K)=M\text{dist}(G(\bar x)+t_kG&#39;(\bar x)d+o(t_k),\mathcal K)=o(t_k)\)</span>. Therefore <span class="math inline">\(d\in T_\mathcal F(\bar x)\)</span> and hence <span class="math inline">\(S(\bar x)\subset T_{\mathcal F}(\bar x)\)</span>.</p>
<p><strong>Theorem</strong> (Main Theorem)</p>
<p>Suppose that <span class="math inline">\(\bar x\)</span> is a locally optimal solution of COP. Then, <span class="math inline">\(\mathcal M(\bar x)\)</span> is a nonempty (which means you have a KKT point), convex compact subset of <span class="math inline">\(\mathcal Y\)</span> <strong>if and only if</strong> Robinson's CQ holds at <span class="math inline">\(\bar x\)</span>.</p>
<p><span class="math inline">\(\implies\)</span></p>
<p>Suppose that <span class="math inline">\(\bar x\)</span> is a locally optimal solution of COP. Suppose Robinson's CQ holds at <span class="math inline">\(\bar x\)</span>. We need to prove <span class="math inline">\(\mathcal M(\bar x)\)</span> is a nonempty (which means you have a KKT point), convex compact subset of <span class="math inline">\(\mathcal Y\)</span>.</p>
<p>Firstly, we define the set (which is actually derived from the KKT condition) <span class="math display">\[
\bar N=\{s\in\mathcal X\;|\; s=\nabla G(\bar x)\mu,-\mu\in N_\mathcal K(G(\bar x))\}.
\]</span> <span class="math inline">\(\bar N\)</span> is obvious a convex cone since the normal cone is always convex.</p>
<p>Then we will show <span class="math inline">\(\bar N\)</span> is always closed. That is to show that for any <span class="math inline">\(z\in \text{cl}(\bar N)\)</span>, there exists <span class="math inline">\(\{z^k\}\subset \bar N\)</span>, such that <span class="math inline">\(z^k\rightarrow z\)</span>. For any sequence <span class="math inline">\(\{-\mu^k\}\subset N_\mathcal K(G(\bar x))\)</span>, we have <span class="math inline">\(\mu^k\rightarrow \mu\)</span> (converge) or <span class="math inline">\(\sigma^k\mu^k\rightarrow \mu\neq 0\)</span> (not converge), where <span class="math inline">\(\sigma^k = 1/||\mu_k||\rightarrow 0\)</span>. In both cases we have <span class="math inline">\(-\mu\in N_\mathcal K(G(\bar x))\)</span> since normal cone is closed. For the first case, <span class="math inline">\(\mu^k\rightarrow \mu\)</span>, we have <span class="math inline">\(z\in \bar N\)</span> since <span class="math inline">\(-\mu \in N_\mathcal K(G(\bar x))\)</span>. For the second case, we have <span class="math inline">\(\sigma ^k\mu^k\rightarrow\mu\neq 0\)</span>. We obtain from <span class="math inline">\(\sigma^k z^k=\nabla G(\bar x)\sigma^k \mu^k\)</span>. The left hand side is zero since <span class="math inline">\(\sigma^k\rightarrow 0\)</span> and <span class="math inline">\(z^k\rightarrow z\)</span>. Then we have <span class="math inline">\(0=\nabla G(\bar x)\mu\)</span>. We also have <span class="math inline">\(0\neq -\mu\in N_\mathcal K(G(\bar x))\)</span>, which contradicts that <span class="math inline">\([G&#39;(\bar x)\mathcal X]^\perp\cap N_\mathcal K(G(\bar x))=\{0\}\)</span>. Therefore, we only have the first case, which means <span class="math inline">\(\bar N\)</span> is closed.</p>
<p>Then we will show that <span class="math inline">\(\nabla f(\bar x)\in \bar N\)</span> by contradiction. Suppose <span class="math inline">\(\nabla f(\bar x)\notin \bar N\)</span>.Then we have <span class="math inline">\(\bar d=\Pi_\bar N(\nabla f(\bar x))-\nabla f(\bar x)\neq 0\)</span>. Then we have <span class="math inline">\(\bar d = \Pi_{\bar N^*}(\nabla f(\bar x))\)</span>. <span class="math display">\[
0\le||\bar d||^2=\langle d,d\rangle=\langle\Pi_\bar N(\nabla f(\bar x))-\nabla f(\bar x),\Pi_{\bar N^*}(\nabla f(\bar x))\rangle=-f&#39;(\bar x)\bar d.
\]</span> By the property of projection, we also have <span class="math display">\[
\langle \bar d,s-\Pi_\bar N(\nabla f(\bar x))\rangle \ge 0,\forall s\in\bar N.
\]</span> It follows that <span class="math display">\[
\langle \bar d,\nabla G(\bar x)\mu-\Pi_\bar N(\nabla f(\bar x))\rangle \ge 0,\forall -\mu\in N_\mathcal K(G(\bar x))\iff\\
\langle \bar d,\nabla G(\bar x)\mu-\bar d+\nabla f(\bar x)\rangle \ge 0,\forall -\mu\in N_\mathcal K(G(\bar x))\iff\\
\langle \bar d,\nabla G(\bar x)\mu\rangle \ge ||\bar d||^2-\langle \bar d,\nabla f(\bar x)\rangle\ge 0,\forall -\mu\in N_\mathcal K(G(\bar x)).
\]</span> Then <span class="math display">\[
\langle G&#39;(\bar x)\bar d,-\mu\rangle \le 0\quad \forall -\mu\in N_\mathcal K(G(\bar x)),
\]</span> which means <span class="math display">\[
G&#39;(\bar x)\bar d\in (N_\mathcal K(G(\bar x)))^o = T_\mathcal K(G(\bar x)).
\]</span> This yields a contradiction to the proposition.</p>
<p>Similar method can be used to prove the closeness and boundedness of <span class="math inline">\(\mathcal M(\bar x)\)</span>.</p>
<p><span class="math inline">\(\Longleftarrow\)</span></p>
<p>We will prove necessity by contradiction.</p>
<p>Suppose that <span class="math inline">\(\bar x\)</span> is a locally optimal solution of COP. Suppose Robinson's CQ <strong>does not</strong> hold at <span class="math inline">\(\bar x\)</span>. Suppose <span class="math inline">\(\mathcal M(\bar x)\)</span> is a nonempty (which means you have a KKT point), convex compact subset of <span class="math inline">\(\mathcal Y\)</span>. We need to find contradiction.</p>
<p>By the proposition, we know that Robinson’s CQ holds if and only if <span class="math inline">\([G&#39;(\bar x)\mathcal X]^\perp\cap N_\mathcal K(G(\bar x))=\{0\}\)</span>. If Robinson’s CQ does not hold, which means <span class="math inline">\([G&#39;(\bar x)\mathcal X]^\perp\cap N_\mathcal K(G(\bar x))\neq\{0\}\)</span>. Then we have <span class="math inline">\((-\mu_0\neq0)\in N_\mathcal K(G(\bar x))\)</span> such that <span class="math inline">\(\nabla G(\bar x)\mu_0=0\)</span>. Since <span class="math inline">\(\mathcal M(\bar x)\)</span> is nonempty, let <span class="math inline">\(\mu\in\mathcal M(\bar x)\)</span>.</p>
<p>Then for any <span class="math inline">\(t&gt;0\)</span>, we hope to prove <span class="math inline">\(\mu+t\mu_0\in \mathcal M(\bar x)\)</span>, which will cause the contradiction that <span class="math inline">\(\mathcal M(\bar x)\)</span> is bounded.</p>
<p>It is easy to show that <span class="math display">\[
\nabla f(\bar x)-\nabla G(\bar x)(\mu+t\mu_0)=0.
\]</span> The only thing we need to show is <span class="math inline">\(-(\mu+t\mu_0)\in N_\mathcal K(G(\bar x))\)</span>. Since <span class="math inline">\(-(\mu+t\mu_0)=-(1+t)(\frac{1}{1+t}\mu+\frac{t}{1+t}\mu_0)\)</span> and <span class="math inline">\(N_\mathcal K(G(\bar x))\)</span> is a closed convex cone, we have <span class="math display">\[
-(\mu+t\mu_0)\in N_\mathcal K(G(\bar x)).
\]</span> which means <span class="math inline">\(\mu+t\mu_0\in \mathcal M(\bar x)\)</span>.</p>
<p>We get contradiction and therefore, Robinson’s CQ holds at <span class="math inline">\(\bar x\)</span>. This completes the proof.</p>
<p>这个证明好精彩啊！！！</p>
<p><strong>Proposition</strong> (Uniqueness of Lagrange Multipliers)</p>
<p>Suppose that <span class="math inline">\(\bar x\)</span> is a locally optimal solution to COP and <span class="math inline">\(\mathcal M(\bar x)\neq \emptyset\)</span>. Let <span class="math inline">\(\mu_0\in\mathcal M(\bar x)\)</span>.</p>
<ol type="1">
<li><p><span class="math inline">\(\mathcal M(\bar x)\)</span> is a singleton if and only if <span class="math display">\[
[G&#39;(\bar x)\mathcal X]^\perp\cap R_D(-\mu_0)=\{0\}
\]</span> where <span class="math inline">\(D=N_\mathcal K(G(\bar x))\)</span>.</p></li>
<li><p>Then the following condition is sufficient for the uniqueness of <span class="math inline">\(\mu_0\)</span>, <span class="math display">\[
[G&#39;(\bar x)\mathcal X]+(T_\mathcal K(G(\bar x))\cap[-\mu_0]^\perp)=\mathcal Y.
\]</span></p></li>
</ol>
<h2 id="first-order-sufficient-conditions">7.3 First order sufficient conditions</h2>
<p><strong>Definition</strong> (Critical cone)</p>
<p>Let <span class="math inline">\(\bar x\in \mathcal F\)</span>. The critical cone of (COP) at <span class="math inline">\(\bar x\)</span> is defined by <span class="math display">\[
\mathcal C(\bar x)=\{d\in\mathcal X\;|\; G&#39;(\bar x)d\in T_\mathcal K(G(\bar x)),f&#39;(\bar x)d\le 0\}.
\]</span> Critical cone is the cone in which the direction is feasible (first condition) and can reduce the value of the target function (second condition).</p>
<p><strong>Proposition</strong></p>
<p>Suppose that <span class="math inline">\(\bar x\)</span> is a locally optimal solution of (COP). If <span class="math inline">\(\mathcal M(\bar x)\)</span> is nonempty, then <span class="math display">\[
\mathcal C(\bar x)=\{d\in\mathcal X\;|\; G&#39;(\bar x)d\in T_\mathcal K(G(\bar x)),f&#39;(\bar x)d=0\},
\]</span> and for any <span class="math inline">\(\mu\in\mathcal M(\bar x)\)</span>, it holds that <span class="math display">\[
\mathcal C(\bar x)=\{d\in\mathcal X\;|\; G&#39;(\bar x)d\in T_{\mathcal K}(G(\bar x)),\langle \mu,G&#39;(\bar x)d\rangle=0 \}.
\]</span> Proof.</p>
<p>Let <span class="math inline">\(\mu \in \mathcal M(\bar x)\)</span>. Then <span class="math inline">\(\nabla f(\bar x)-\nabla G(\bar x)\mu=0\)</span> and <span class="math inline">\(-\mu\in N_\mathcal K (G(\bar x))\)</span>. It follows that <span class="math display">\[
0=\langle \nabla f(\bar x)-\nabla G(\bar x)\mu,d\rangle =f&#39;(\bar x)d-\langle \mu,G&#39;(\bar x)d\rangle\;\forall d\in \mathcal X.
\]</span> Let <span class="math inline">\(d\in\mathcal C(\bar x)\)</span>, i.e., <span class="math inline">\(f&#39;(\bar x)d\le 0\)</span> and <span class="math inline">\(G&#39;(\bar x)d\in T_\mathcal K(G(\bar x))\)</span>. Then we have <span class="math inline">\(\langle -\mu,G&#39;(\bar x)d\rangle\le 0\)</span> from the fact that <span class="math inline">\(N_\mathcal K(G(\bar x))=[T_\mathcal K(G(\bar x))]^o\)</span>.Therefore, we have <span class="math inline">\(f&#39;(\bar x)d = \langle \mu,G&#39;(\bar x)d\rangle= 0\)</span>.</p>
<p><strong>Definition</strong></p>
<p>For <span class="math inline">\(\bar x\in\mathcal F\)</span> and <span class="math inline">\(\mu\ge 0\)</span>, define <span class="math display">\[
S_\eta(\bar x)=\{d\in\mathcal X\;|\; \text{dist} (G&#39;(\bar x)d,T_\mathcal K(G(\bar x)))\le \eta||d||\}.
\]</span> In particular, for <span class="math inline">\(\eta = 0\)</span>, it coincides with the feasible set of (LCOP). <span class="math display">\[
S_0(\bar x)=\{d\in\mathcal X\;|\; G&#39;(\bar x)d\in T_\mathcal K(G(\bar x))\}.
\]</span> <strong>Definition</strong></p>
<p>We say that <span class="math inline">\(\beta\)</span>-order growth condition holds at <span class="math inline">\(\bar x\)</span>, if there exist a neighborhood <span class="math inline">\(U\)</span> of <span class="math inline">\(\bar x\)</span> and a constant <span class="math inline">\(c&gt;0\)</span> such that, for all <span class="math inline">\(x\in\mathcal F\cap U\)</span>, the following inequality holds, <span class="math display">\[
f(x)\ge f(\bar x)+c||x-\bar x||^\beta.
\]</span> <strong>Proposition</strong></p>
<p>Suppose <span class="math inline">\(\bar x\in\mathcal F\)</span>. If there exist constants <span class="math inline">\(\alpha &gt;0\)</span> and <span class="math inline">\(\beta &gt;0\)</span> such that <span class="math display">\[
f&#39;(x)d\ge \alpha ||d||,\quad \forall d\in S_\eta(\bar x),
\]</span> then the first order growth condition holds at <span class="math inline">\(\bar x\)</span>.</p>
<p><strong>Theorem</strong></p>
<p>Let <span class="math inline">\(\bar x\in \mathcal F\)</span>. Suppose that Robinson’s CQ holds at <span class="math inline">\(\bar x\)</span>. Then, there exists <span class="math inline">\(\alpha &gt;0\)</span> such that <span class="math display">\[
f&#39;(x)d\ge \alpha ||d||,\quad \forall d\in S_\eta(\bar x)
\]</span> holds for <span class="math inline">\(\eta=0\)</span> if and only if the first order growth condition <span class="math display">\[
f(x)\ge f(\bar x)+c||x-\bar x||^\beta
\]</span> holds.</p>
<h2 id="second-order-necessary-conditions">7.4 Second order necessary conditions</h2>
<p><strong>Definition</strong> (Second Oder Tangent Set)</p>
<p>The (outer) second order tangent set to the set <span class="math inline">\(\mathcal D\subset \mathcal Y\)</span> at the point <span class="math inline">\(y\in \mathcal Y\)</span> and in the direction of <span class="math inline">\(d\in\mathcal D\)</span> is defined by <span class="math display">\[
\mathcal T_\mathcal D^2(y,d)=\left\{w\in\mathcal Y\;\Bigg|\; \exists t_k\downarrow 0,\text{dist}\left(y+t_kd+\frac{1}{2}t_k^2 w,\mathcal D\right)=o(t_k^2)\right\}.
\]</span> Note that <span class="math inline">\(\mathcal T_\mathcal D^2 (y,d)\)</span> may not be convex even if <span class="math inline">\(\mathcal D\)</span> is convex.</p>
<p><strong>Proposition</strong></p>
<p>Let <span class="math inline">\(\bar x\in\mathcal F\)</span>. Suppose that Robinson’s CQ holds at <span class="math inline">\(\bar x\)</span>. Then, for <span class="math inline">\(d\in\mathcal X\)</span>, one has <span class="math display">\[
\mathcal T_\mathcal F^2(\bar x,d)=G&#39;(\bar x)^{-1} \left(\mathcal T_\mathcal K^2 (G(\bar x),G&#39;(\bar x)d)-G&#39;&#39;(\bar x)(d,d)\right).
\]</span> Note that the above expression is equivalent to <span class="math display">\[
\mathcal T_\mathcal F^2(\bar x,d)=\left\{w\in\mathcal X\;|\; G&#39;(\bar x)w+G&#39;&#39;(\bar x)(d,d)\in\mathcal T_\mathcal K^2(G(\bar x),G&#39;(\bar x)d)\right\}.
\]</span></p>
<p><strong>Proposition</strong></p>
<p>Suppose that <span class="math inline">\(\bar x\)</span> is a locally optimal solution of (COP). If <span class="math inline">\(f&#39;(x)d=0\)</span>, then we have <span class="math display">\[
f&#39;(\bar x)w+\langle d,\nabla ^2f(\bar x)d\rangle \ge 0,\quad \forall w\in\mathcal T_{\mathcal F}^2(\bar x,d).
\]</span> Consider the following optimization problem, <span class="math display">\[
\text{(SLCOP)}\quad \begin{array}{rCl}
\min &amp; f&#39;(\bar x)w+\langle d,\nabla ^2f(\bar x)d\rangle\\
\text{subject to}&amp; G&#39;(\bar x)w+G&#39;&#39;(\bar x)(d,d)\in\mathcal T_\mathcal K^2(G(\bar x),G&#39;(\bar x)).
\end{array}
\]</span> This is considered as the strong linearized problem. This problem is generalized not convex.</p>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/12/22/MA6268 Nonlinear Optimization/7.1 Nonlinear conic programming/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Cheng-Zilong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cheng-Zilong">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2020/12/22/MA6268 Nonlinear Optimization/7.1 Nonlinear conic programming/" class="post-title-link" itemprop="url">7. Nonlinear conic programming (1)</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2020-12-22 13:48:40" itemprop="dateCreated datePublished" datetime="2020-12-22T13:48:40+08:00">2020-12-22</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2019-11-13 10:18:24" itemprop="dateModified" datetime="2019-11-13T10:18:24+08:00">2019-11-13</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/MA6268-Nonlinear-Optimization/" itemprop="url" rel="index"><span itemprop="name">MA6268 Nonlinear Optimization</span></a></span>

                
                
              
            </span>
          

          
            <span id="/2020/12/22/MA6268 Nonlinear Optimization/7.1 Nonlinear conic programming/" class="post-meta-item leancloud_visitors" data-flag-title="7. Nonlinear conic programming (1)" title="Views">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span class="leancloud-visitors-count"></span>
            </span>
          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
        
      
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2020/12/22/MA6268 Nonlinear Optimization/7.1 Nonlinear conic programming/#comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/2020/12/22/MA6268 Nonlinear Optimization/7.1 Nonlinear conic programming/" itemprop="commentCount"></span></a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="nonlinear-conic-programming">7. Nonlinear Conic Programming</h1>
<p>We consider the following optimization problem, <span class="math display">\[
\text{(OP)}\quad \begin{array}{rCl}
\min &amp; f(x)\\
\text{subject to}&amp; g(x)=0\\
&amp;h(x)\in \mathcal C,
\end{array}
\]</span> where <span class="math inline">\(f:\mathcal X\rightarrow \mathbb R,g:\mathcal X\rightarrow \mathcal U\)</span>, and <span class="math inline">\(h:\mathcal X\rightarrow \mathcal V\)</span> are continuously differentiable, <span class="math inline">\(\mathcal X,\mathcal U\)</span> and <span class="math inline">\(\mathcal V\)</span> are finite dimensional Euclidean spaces each equipped with a scalar product <span class="math inline">\(\langle \cdot,\cdot\rangle\)</span> and its induced norm <span class="math inline">\(||\cdot||\)</span>, and <span class="math inline">\(\mathcal C\subseteq \mathcal V\)</span> is a closed convex set in <span class="math inline">\(\mathcal V\)</span>.</p>
<p>Let <span class="math inline">\(\mathcal Y=\mathcal U\times \mathcal V\)</span>, <span class="math inline">\(\mathcal K=\{0^\mathcal U\}\times \mathcal C\subset \mathcal Y\)</span>. Define <span class="math inline">\(G:\mathcal X\rightarrow \mathcal Y\)</span> by <span class="math display">\[
G(X)=(g(X),h(X)),\quad X\in\mathcal X.
\]</span> The problem can be written as the following compact form, <span class="math display">\[
\text{(COP)}\quad \begin{array}{rCl}
\min &amp; f(X)\\
\text{subject to}&amp; G(X)\in\mathcal K.
\end{array}
\]</span> Define the Lagrangian function <span class="math inline">\(L:\mathcal X\times \mathcal Y\rightarrow \mathbb R\)</span> for (COP) by <span class="math display">\[
L(X,\mu)=f(X)-\langle \mu, G(X)\rangle,\quad X\in\mathcal X,\mu\in\mathcal Y.
\]</span> There is no constraint on <span class="math inline">\(\mu\)</span> for the general Lagrangian function. Therefore, here is <span class="math inline">\(y\in\mathcal Y\)</span>. We will give further explanation in the later.</p>
<p>The <strong>Lagrangian dual function</strong> is defined by <span class="math display">\[
\theta(\mu)=\inf\left\{L(X,\mu )\;|\; X\in\mathcal X\right\},
\]</span> which is an unconstrained function.</p>
<p>The dual problem is <span class="math display">\[
\max \{\theta(\mu)\;|\; \mu \in\mathcal K^*\},
\]</span> where <span class="math inline">\(\mathcal K^* =\mathcal U\times \mathcal C^*\)</span> is the dual cone of <span class="math inline">\(\mathcal K\)</span>. Note that <span class="math inline">\((\{0^\mathcal U\})^*=\mathcal U\)</span> and <span class="math inline">\(\mathbb S_+^n\)</span> is <strong>self-dual</strong>.</p>
<p>We can see in the conic programming, we only consider <span class="math inline">\(\mu\in \mathcal K^*\)</span> in the dual problem. However, if needed, we can also put this constraint to the Lagrangian dual function and Lagrangian function like what we usually do in the basic nonlinear programming.</p>
<p>We also define the Lagrangian function in the conic programming as <span class="math inline">\(L(x,\mu)=f(x)\textbf{ minus } \langle \mu,G(x)\rangle\)</span> <strong>instead of plus</strong>. This is for convenience because the cone is usually defined as “positive”, which means <span class="math inline">\(h(x)\succeq 0\)</span> in the conic programming <strong>instead of</strong> <span class="math inline">\(h(x)\le 0\)</span> in the basic nonlinear programming is the common case.</p>
<p><strong>Example</strong></p>
<p>If we have <span class="math inline">\(\mathcal X=\mathbb R^n\)</span>, <span class="math inline">\(\mathcal U=\mathbb R^m\)</span>, <span class="math inline">\(\mathcal V=\mathbb R^q\)</span> and <span class="math inline">\(\mathcal C=\mathbb R^q_+\)</span>. In this case, the problem reduces to the following, <span class="math display">\[
\text{(NLP)}\quad \begin{array}{rCl}
\min &amp; f(x)\\
\text{subject to}&amp; g(x)=0\\
&amp;h(x)\ge 0.
\end{array}
\]</span> If we denote <span class="math inline">\(G(x)=(g(x),h(x))\)</span>, <span class="math inline">\(\mathcal K=\{0^m\}\times \mathbb R^n_+\)</span>, there exists <span class="math inline">\(\mu\in\mathbb R^m\times \mathbb R^n\)</span>, such that the Lagrange function is defined as <span class="math display">\[
L(x,\mu)=f(x)-\langle \mu,G(x)\rangle.
\]</span> The Lagrange dual function is defined as <span class="math display">\[
\theta(\mu)=\min_x L(x,\mu)=\min_x\left(f(x)-\langle\mu,G(x)\rangle\right),\quad \mu\in\mathbb R^m\times \mathbb R^n.
\]</span> Since <span class="math inline">\(\left(\mathbb R^n_+\right)^*=\mathbb R^n_+\)</span>, the Lagrange dual problem is defined as <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\min &amp; \theta (\mu)\\
\text{subject to}&amp; \mu\in\mathcal K^*=\mathbb R^n\times \mathbb R^n_+.
\end{array}
\]</span> <strong>Example</strong> (semidefinite linear programming)</p>
<p>If <span class="math inline">\(\mathcal X=\mathbb S^n\)</span>, <span class="math inline">\(\mathcal U=\mathbb R^m\)</span>, <span class="math inline">\(\mathcal V=\mathbb S^n\)</span>, and <span class="math inline">\(f(X)=\langle C,X\rangle,\)</span> <span class="math inline">\(g(X)=\mathcal A(X)-b\)</span>, <span class="math inline">\(h(X)=X\)</span> and <span class="math inline">\(\mathcal C=\mathbb S_+^n\)</span>, then the problem (OP) reduces to the following linear semidefinite programming problem, <span class="math display">\[
\text{(SDP)}\quad \begin{array}{rCl}
\min &amp; \langle C,X\rangle\\
\text{subject to}&amp; \mathcal A(X)-b=0\\
&amp;X\succeq 0(X\in\mathbb S^n_+),
\end{array}
\]</span> where <span class="math inline">\(C\in \mathbb S^n\)</span>, <span class="math inline">\(\mathcal A:\mathbb S^n\rightarrow \mathbb R^m\)</span> is a linear mapping defined by <span class="math display">\[
\mathcal A(X)=
\begin{bmatrix}
\langle A_1,X\rangle \\ \vdots \\
\langle A_m,X\rangle
\end{bmatrix},\quad 
X\in\mathbb S^n,
\]</span> where <span class="math inline">\(A_k\in \mathbb S^n,k=1,\dotsm,m\)</span>, are the constraints matrices. Let <span class="math inline">\(\mathcal A^*:\mathbb R^m\rightarrow \mathbb S^n\)</span> be the adjoint of <span class="math inline">\(\mathcal A\)</span> defined by <span class="math display">\[
\mathcal A^*y=\sum_{k=1}^m y_kA_k,\quad y\in \mathbb R^m.
\]</span> This can be shown by the definition of the adjoint of operator. <span class="math display">\[
\begin{array}{rcl}
\langle \mathcal A^* y,X\rangle &amp;=&amp;\langle y,\mathcal A X\rangle\\
&amp;=&amp;\displaystyle\sum_{i=1}^m y_i\langle A_i,X\rangle \\
&amp;=&amp;\displaystyle\sum_{i=1}^m y_i\sum_{j=1}^ne_j^TA_iXe_j, \\
\mathbf 1^T\mathcal A^*yX \mathbf 1 &amp;=&amp; \displaystyle\sum_{i=1}^m y_i \mathbf 1^TA_iX\mathbf 1\\
&amp;=&amp; \mathbf 1^T\displaystyle\sum_{i=1}^m y_i A_iX\mathbf 1,
\end{array}
\]</span> Therefore, we have <span class="math inline">\(\mathcal A^*y=\sum_{i=1}^m y_iA_i\)</span>.</p>
<p>We have the Lagrange function, <span class="math display">\[
\begin{array}{rcl}
L(X,y,Z)&amp;=&amp;\langle C,X\rangle +\langle y,b-\mathcal A(X) \rangle+\langle Z,-X\rangle\\
&amp;=&amp;\langle y,b\rangle+\langle C-\mathcal A^*y-Z,X\rangle\quad X\in\mathbb S^n,y\in\mathbb R^n,Z\in\mathbb S^n.
\end{array}
\]</span> Then <span class="math display">\[
\begin{array}{rcl}
\theta(y,Z)&amp;=&amp;\displaystyle \inf_{X\in\mathbb S^n} \left\{\langle y,b\rangle+\langle C-\mathcal A^*y-Z,X\rangle\right\}\\
&amp;=&amp;\displaystyle\inf_{X\in\mathbb S^n} \left\{\langle y,b\rangle+\langle C-\mathcal A^*y-Z,X\rangle\right\}\\
&amp;=&amp; 
\begin{cases}
\langle y,b\rangle&amp;\text{if }C-\mathcal A^*y-Z=0\\
-\infty &amp; \text{otherwise.}
\end{cases}
\end{array}
\]</span> Therefore, the dual problem is given by, <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\max &amp; \langle y,b\rangle\\
\text{subject to}&amp; C-\mathcal A^*y-Z=0\\
&amp;Z\succeq 0.
\end{array}
\]</span> Also, we can consider the compact form. If we define <span class="math inline">\(G(X)=(\mathcal A(X)-b, X)\)</span>, <span class="math inline">\(\mathcal K=\{0^m\}\times \mathbb S^n_+\)</span>, then we have <span class="math display">\[
\text{(SDP)}\quad \begin{array}{rCl}
\min &amp; f(X)=\langle C,X\rangle\\
\text{subject to}&amp; G(X)\in\mathcal K.
\end{array}
\]</span> Then there exists <span class="math inline">\(\mu=(y,Z)\in\mathbb R^n\times \mathbb S^n\)</span>, such that the Lagrange function is defined as <span class="math display">\[
\begin{array}{rcl}
L(X,\mu)=L(X,y,Z)&amp;=&amp;f(X)-\langle \mu, G(X)\rangle\\
&amp;=&amp;\langle C,X\rangle-\langle y,\mathcal A(X)-b\rangle-\langle  Z,X\rangle\\
&amp;=&amp;\langle C,X\rangle-\langle \mathcal A^*(y), X\rangle+\langle y,b\rangle-\langle  Z,X\rangle\\
&amp;=&amp;\langle C-\mathcal A^*(y)-Z,X\rangle+\langle y,b\rangle.
\end{array}
\]</span> The we have the Lagrange dual function, <span class="math display">\[
\begin{array}{rcl}
\theta(y,Z)
&amp;=&amp; 
\begin{cases}
\langle y,b\rangle&amp;\text{if }C-\mathcal A^*y-Z=0\\
-\infty &amp; \text{otherwise.}
\end{cases}
\end{array}
\]</span> Then the Lagrange dual problem is <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\max &amp; \theta(y,Z)\\
\text{subject to}&amp; (y,Z)\in\mathcal K^*=\mathbb R^n\times \mathbb S^n_+,
\end{array}
\]</span> that is <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\max &amp; \langle y,b\rangle\\
\text{subject to}&amp; Z\in\mathbb S^n_+\\
&amp;C-\mathcal A^*y-Z=0.
\end{array}
\]</span> <strong>Example</strong></p>
<p>Let <span class="math inline">\(G\in\mathbb R^{p\times n}\)</span> and <span class="math inline">\(H\in\mathbb R^{q\times n}\)</span> for the linear map <span class="math inline">\(\mathcal A:\mathbb S^n\rightarrow \mathbb R^{p\times q}\)</span> defined by <span class="math inline">\(\mathcal A(X)=GXH^T\)</span>. Show that the adjoint map <span class="math inline">\(\mathcal A^*:\mathbb R^{p\times q} \rightarrow \mathbb S^n\)</span> is given by <span class="math inline">\(\mathcal A^*(Y)=\frac{1}{2}\left(G^TYH+H^TY^TG\right)\)</span>.</p>
<p>Proof. <span class="math display">\[
\begin{array}{rcl}
\langle \mathcal A(X),Y\rangle&amp;=&amp; \langle GXH^T,Y\rangle\\
&amp;=&amp; \text{tr}(HXG^TY)\\
&amp;=&amp; \text{tr}(XG^TYH)\\
&amp;=&amp; \frac{1}{2}\text{tr}\left(X(G^TYH+H^TY^TG)\right)\\
&amp;=&amp;\langle X,\frac{1}{2}(G^TYH+H^TY^TG)\rangle.
\end{array}
\]</span> Therefore, we have <span class="math inline">\(\mathcal A^*(Y)=\frac{1}{2}\left(G^TYH+H^TY^TG\right)\)</span>. (<strong>ATTENTION</strong>: <span class="math inline">\(\mathcal A^*:\mathbb R^{p\times q}\rightarrow \mathbb S^n\)</span>)</p>
<p><strong>Example</strong> (semidefinite programming least squares problem)</p>
<p>If <span class="math inline">\(f(x)=\frac{1}{2}||X-B||^2\)</span> where <span class="math inline">\(B\in \mathbb S^n\)</span> is a given matrix. <span class="math display">\[
\text{(SDPLS)}\quad \begin{array}{rCl}
\min &amp; \frac{1}{2}||X-B||^2\\
\text{subject to}&amp; \mathcal A(X)=b\\
&amp;X\succeq 0.
\end{array}
\]</span> In particular, when <span class="math inline">\(\mathcal A(X)=\text{diag} (X)\)</span> and <span class="math inline">\(b=e\)</span>, we get the nearest correlation matrix problem.</p>
<p>The problem can be denoted as <span class="math display">\[
\text{(SDPLS)}\quad \begin{array}{rCl}
\min &amp; \frac{1}{2}||X-B||^2\\
\text{subject to}&amp; G(X)\in \mathcal K,
\end{array}
\]</span> where <span class="math inline">\(G(X)=(\mathcal A(X)-b,X)\)</span> and <span class="math inline">\(\mathcal K=\{0^m\}\times \mathbb S_+^n\)</span>.</p>
<p>For <span class="math inline">\(X\in \mathbb S^n\)</span>, <span class="math inline">\(\mu = (y,Z)\in\mathcal Y=\mathbb R^m\times \mathbb S^n\)</span>, <span class="math display">\[
\begin{array}{rcl}
L(X,y,Z)&amp;=&amp;\frac{1}{2}||X-B||^2-\langle y,b-\mathcal A(X)\rangle -\langle Z,X\rangle\\
&amp;=&amp; \langle y,b\rangle +\frac{1}{2}||B||^2+\frac{1}{2}||X||^2-\langle \mathcal A^*(y)+Z+B,X\rangle,
\end{array}
\]</span> Thus <span class="math inline">\(\min\{L(X,y,Z)\;|\; X\in\mathbb S^n\}\)</span> can be found by setting, <span class="math display">\[
\nabla _XL(X,y,Z)=X-(B+Z+\mathcal A^*(y))=0\implies X=B+Z+\mathcal A^*(y).
\]</span> Then we have <span class="math display">\[
\begin{array}{rcl}
\theta (y,Z)&amp;=&amp;\min\{L(X,y,Z)\;|\; X\in\mathbb S^n\}\\
&amp;=&amp; \langle y,b\rangle +\frac{1}{2}||B||^2-\frac{1}{2}||B+Z+\mathcal A^*(y)||^2.
\end{array}
\]</span> The dual problem is given by <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\max &amp; \langle y,b\rangle +\frac{1}{2}||B||^2-\frac{1}{2}||B+Z+\mathcal A^*(y)||^2\\
\text{subject to}&amp; (y,Z)\in\mathcal K^*.
\end{array}
\]</span> Then we have <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\min &amp; -\langle y,b\rangle+\frac{1}{2}||B+Z+\mathcal A^*(y)||^2\\
\text{subject to}&amp; y\in\mathbb R^n\\
&amp; Z\in \mathbb S_+^n.
\end{array}
\]</span> We claim <strong>(This claim is very useful)</strong> <span class="math display">\[
G=\Pi_{\mathbb S_+^n} (G)-\Pi_{\mathbb S_+^n} (-G).
\]</span></p>
<p>This property can be easily checked by the property of proximal operator. Since we have <span class="math inline">\(\delta_K^*(x)=\delta_{K^*}(-x)\)</span>, let us check the proximal. <span class="math display">\[
\begin{array}{rcl}
P_{\delta_K^*}(y)&amp;=&amp;\arg\min_x\{\delta_K^*(x)+\frac{1}{2}||x-y||^2\}\\
&amp;=&amp;\arg\min_x\{\delta_{K^*}(-x)+\frac{1}{2}||x-y||^2\}\\
&amp;=&amp;-\arg\min_x\{\delta_{K^*}(x)+\frac{1}{2}||x-(-y)||^2\}\\
&amp;=&amp; -\Pi_{\delta_{K^*}}(-y).
\end{array}
\]</span> Therefore <span class="math display">\[
\begin{array}{rcl}
G&amp;=&amp;P_{\delta_{\mathbb S^n_+}}(G)+P_{(\delta_{\mathbb S^n_+})^*}(G)\\
&amp;=&amp; \Pi_{\mathbb S^n_+}(G)-\Pi_{(\mathbb S^n_+)^*}(-G)\\
&amp;=&amp; \Pi_{\mathbb S^n_+}(G)-\Pi_{\mathbb S^n_+}(-G).
\end{array}
\]</span></p>
<p>Then by using this claim, we have <span class="math display">\[
\begin{array}{l}
\min\left\{||B+Z+\mathcal A^*(y)||\;|\; Z\in\ \mathbb S_+^n\right\}
\\\quad =||B+\mathcal A^*(y)+\Pi_{\mathcal S_+^n}(-(B+\mathcal A^*(y)))||
\\\quad=||\Pi_{\mathbb S_+^n}(B+\mathcal A^*(y))||.
\end{array}
\]</span> Therefore, <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\min &amp; \phi(y)=-\langle y,b\rangle+\frac{1}{2}||\Pi_{\mathbb S_+^n}(B+\mathcal A^*(y))||^2\\
\text{subject to}&amp; y\in\mathbb R^n.
\end{array}
\]</span> In this case, the dual problem is unconstrained problem. Therefore, we can solve it by finding the root of the gradient, <span class="math display">\[
0=\nabla \phi(y)=-b+\mathcal A \Pi_{\mathbb S_+^n}(B+\mathcal A^* (y)).
\]</span> <strong>Example</strong> (Sparse regression problem) <span class="math display">\[
\min\{\frac{1}{2}||Ax-b||^2+\lambda ||x||_1\;|\; x\in\mathbb R^n\},
\]</span> where <span class="math inline">\(A\in\mathbb R^{m\times n}\)</span> and <span class="math inline">\(b\in\mathbb R^m\)</span> are given data. Let <span class="math inline">\(u=b-Ax\)</span>, then we have <span class="math display">\[
\text{(P)}\quad \begin{array}{rCl}
\min &amp; f(u)+g(x)\\
\text{subject to}&amp; u+Ax=b,
\end{array}
\]</span> where <span class="math inline">\(f(u)=\frac{1}{2}||u||^2\)</span> and <span class="math inline">\(g(x)=\lambda ||x||_1\)</span>.</p>
<p>The Lagrangian function is given as <span class="math display">\[
\begin{array}{rcl}
L(u,x,\xi)&amp;=&amp;f(u)+g(x)+\langle \xi,b-u-Ax\rangle\\
&amp;=&amp; f(u)-\langle \xi,u\rangle +g(x)-\langle A^T\xi,x\rangle +\langle \xi,b\rangle.
\end{array}
\]</span> The Lagrangian dual function is given as <span class="math display">\[
\theta(\xi)=\langle \xi,b\rangle+\min_u(f(u)-\langle \xi,u\rangle)+\min_x(g(x)-\langle A^T\xi,x\rangle)\\
=\langle \xi,b\rangle-\max_u(\langle \xi,u\rangle-f(u))-\max_x(\langle A^T\xi,x\rangle-g(x)).
\]</span> Both of the last two terms are conjugate functions. Therefore we have <span class="math display">\[
\theta(\xi)=\langle \xi,b\rangle-\frac{1}{2}||\xi||^2-\delta_{B_\lambda}(A^T\xi).
\]</span> Therefore, the dual problem is <span class="math display">\[
-\min -\langle\xi,b\rangle +\frac{1}{2}||\xi||^2+\delta_{B_\lambda}(A^T\xi).
\]</span> <strong>Definition</strong> (Lagrange Multipliers) <span class="math display">\[
L(x,\mu)=f(x)-\langle \mu, G(x)\rangle,\quad x\in\mathcal X,\mu\in\mathcal Y,
\]</span> where <span class="math inline">\(L\)</span> be the Lagrangian function for (COP). Assume that <span class="math inline">\(f\)</span> and <span class="math inline">\(G\)</span> are continuously differentiable. We say that <span class="math inline">\(\bar \mu \in\mathcal Y\)</span> is a Lagrange multiplier of (COP) at a feasible point <span class="math inline">\(\bar x\)</span>, if it satisfies the KKT condition, <span class="math display">\[
0=\nabla _xL(\bar x,\bar \mu)=\nabla f(\bar x)-\nabla G(\bar x)\bar \mu,\quad 0\in \bar \mu+N_\mathcal K(G(\bar x)),
\]</span> where <span class="math inline">\(N_\mathcal K (G(\bar x))\)</span> is the normal cone of <span class="math inline">\(\mathcal K\)</span> at <span class="math inline">\(G(\bar x)\in \mathcal Y\)</span>. We denote the set of all Lagrange multipliers at <span class="math inline">\(\bar x\)</span> as <span class="math inline">\(\mathcal M(\bar x)\)</span>. We call the pair <span class="math inline">\((\bar x,\bar \mu)\)</span> a KKT point.</p>
<p><strong>Remark</strong></p>
<ol type="1">
<li><p>If <span class="math inline">\(\mathcal C\)</span> is a closed convex cone, then <span class="math inline">\(\mathcal K = 0^{\mathcal U}\times \mathcal C\)</span> is a closed convex cone. <span class="math display">\[
\begin{array}{rcl}
-\bar \mu \in\mathcal N_\mathcal K(G(\bar x))&amp;\iff&amp; G(\bar x)\in\mathcal K,&amp;\langle -\bar \mu,d-G(\bar x)\rangle \le 0,&amp;&amp;\forall d\in\mathcal K
\end{array}
\]</span> We choose <span class="math inline">\(d=0\)</span> and <span class="math inline">\(d=G(\bar x)\)</span>. Then we have <span class="math display">\[
\begin{array}{rcl}
-\bar \mu \in\mathcal N_\mathcal K(G(\bar x))&amp;\iff&amp; G(\bar x)\in\mathcal K,&amp;\langle \bar \mu,G(\bar x)\rangle = 0,&amp;\langle \bar \mu,d\rangle\ge 0,&amp;\forall d\in\mathcal K\\
&amp;\iff&amp; G(\bar x)\in\mathcal K,&amp;\langle \bar \mu,G(\bar x)\rangle = 0,&amp;\bar \mu\in \mathcal K^*.
\end{array}
\]</span> In this case, the KKT conditions can be written as <span class="math display">\[
(G(\bar x)\in\mathcal K)\perp (\bar \mu \in\mathcal K^*).
\]</span></p></li>
<li><p>The set of multipliers <span class="math inline">\(\mathcal M(\bar x)\)</span> may be <strong>empty</strong> or <strong>unbounded</strong>.</p></li>
</ol>
<p><strong>Example</strong></p>
<p>For basic NLP, let <span class="math inline">\(\bar \mu=(\lambda,\rho)\)</span>, and <span class="math inline">\(G(x)=(g(x),h(x))\)</span>, <span class="math inline">\(\mathcal C=\mathbb R^p_+\)</span>, and <span class="math inline">\(\mathcal K=\{0^m\}\times \mathcal C\)</span>, we have KKT conditions, <span class="math display">\[
\begin{array}{rcl}
\nabla f(\bar x)-\nabla g(\bar x)\lambda -\nabla h(\bar x)\rho&amp;=&amp;0\\
G(\bar x)=(g(\bar x),h(\bar x))&amp;\in&amp; \mathcal K\\
\langle h(\bar x),\rho\rangle &amp;=&amp;0\\
\rho \in \mathcal C^*&amp;=&amp;\mathbb R_+^p.
\end{array}
\]</span> <strong>Example</strong></p>
<p>Given <span class="math inline">\(B\in\mathbb S^n\)</span>, consider the doubly nonnegative projection problem, <span class="math display">\[
\min \left\{\frac{1}{2}||X-B||^2\;|\; X\in\mathbb S_+^n\cap \mathcal N^n\right\}.
\]</span> The above problem can be rewritten as <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\min &amp; f(X)=\frac{1}{2}||X-B||^2\\
\text{subject to}&amp; G(X)=(X,X)\in\mathcal K=\mathbb S_+^n\times \mathcal N^n.
\end{array}
\]</span> The Lagrange function is for <span class="math inline">\(\mu=(Y,Z) \in \mathcal Y=\mathbb S^n\times \mathbb S^n\)</span>, <span class="math display">\[
\begin{array}{rcl}
L(X,\mu)=L(X,Y,Z)&amp;=&amp;\frac{1}{2}||X-B||^2-\langle \mu,G(X)\rangle\\
&amp;=&amp;\frac{1}{2}||X-B||^2-\langle Y,X\rangle-\langle Z,X\rangle.
\end{array}
\]</span> The Lagrange dual function is <span class="math display">\[
\begin{array}{rcl}
\theta(\mu)=\theta(Y,Z)&amp;=&amp;\min_{X\in\mathbb S^n} L(X,\mu)\\
&amp;=&amp;\min_{X\in\mathbb S^n}\left(\frac{1}{2}||X-B||^2-\langle Y,X\rangle-\langle Z,X\rangle\right)\\
&amp;=&amp;\min_{X\in\mathbb S^n}\left(\frac{1}{2}||X||^2-\langle B+Y+Z,X\rangle+\frac{1}{2}||B||^2\right)\\
&amp;=&amp;\frac{1}{2}\left(-||B+Y+Z||^2+||B||^2\right).
\end{array}
\]</span></p>
<p>Therefore the dual problem is <span class="math display">\[
\text{(D)}\quad \begin{array}{rCl}
\max &amp; \frac{1}{2}\left(-||B+Y+Z||^2+||B||^2\right)\\
\text{subject to}&amp; (Y,Z)\in\mathcal K^*=\mathbb S^n_+\times  \mathcal N^n.
\end{array}
\]</span> Therefore, the KKT conditions are given as <span class="math display">\[
0=\nabla _xL(\bar X,\bar Y,\bar Z)=\nabla f(\bar X)-\langle\nabla G(\bar X),(\bar Y,\bar Z)\rangle\\
\mathcal K\ni G(\bar X)\perp (\bar Y,\bar Z) \in \mathcal K^*.
\]</span> That is <span class="math display">\[
\bar X- B-\bar Y-\bar Z=0\\
\langle \bar X,\bar Y\rangle+\langle \bar X,\bar Z\rangle=0\\ 
\bar X\in \mathbb S^n_+\cap \mathcal N^n\\
(\bar Y,\bar Z)\in\mathbb S^n_+\times\mathcal N^n.
\]</span></p>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/35/">35</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>


          </div>
          

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc" data-target="post-toc-wrap">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview" data-target="site-overview-wrap">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Cheng-Zilong</p>
  <div class="site-description" itemprop="description"></div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">70</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">categories</span>
        </a>
      </div>
    
  </nav>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:zilongcheng@u.nus.edu" title="E-Mail &rarr; mailto:zilongcheng@u.nus.edu" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
    
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Cheng-Zilong</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.3.0</div>

        












        
      </div>
    </footer>
  </div>

  
    
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/jquery/index.js?v=3.4.1"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.3.0"></script><script src="/js/motion.js?v=7.3.0"></script>
<script src="/js/schemes/pisces.js?v=7.3.0"></script>

<script src="/js/next-boot.js?v=7.3.0"></script>



  





















  

  
    
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    
  

  

  


<script>
NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail,link';
  guest = guest.split(',').filter(item => {
    return GUEST.indexOf(item) > -1;
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'k1NFV6E2jjtcuFpWbPUwvs04-MdYXbMMI',
    appKey: 'oCso3hdINWUXi0EtP7BsCUoY',
    placeholder: 'Just go go',
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: true,
    lang: '' || 'zh-cn',
    path: location.pathname
  });
}, window.Valine);
</script>

</body>
</html>
