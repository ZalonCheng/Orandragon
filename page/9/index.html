<!DOCTYPE html>





<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.3.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.3.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.3.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.3.0">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css?v=1.0.2">
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.3.0',
    exturl: false,
    sidebar: {"position":"right","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: 'Copy',
      copy_success: 'Copied',
      copy_failure: 'Copy failed'
    }
  };
</script>

  <meta name="keywords" content="Optimization, Machine Learning">
<meta property="og:type" content="website">
<meta property="og:title" content="Cheng-Zilong">
<meta property="og:url" content="http://yoursite.com/page/9/index.html">
<meta property="og:site_name" content="Cheng-Zilong">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Cheng-Zilong">
  <link rel="canonical" href="http://yoursite.com/page/9/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: true,
    isPost: false,
    isPage: false,
    isArchive: false
  };
</script>

  <title>Cheng-Zilong</title>
  <meta name="generator" content="Hexo 3.9.0">
  








  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Cheng-Zilong</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">Learning Notes</p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>About</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            
  <div id="posts" class="posts-expand">
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/12/22/MA6268 Nonlinear Optimization/3.1 Basic Convex Analysis/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Cheng-Zilong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cheng-Zilong">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2020/12/22/MA6268 Nonlinear Optimization/3.1 Basic Convex Analysis/" class="post-title-link" itemprop="url">3. Basic Convex Analysis (1)</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2020-12-22 13:48:40" itemprop="dateCreated datePublished" datetime="2020-12-22T13:48:40+08:00">2020-12-22</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-03-04 19:32:03" itemprop="dateModified" datetime="2020-03-04T19:32:03+08:00">2020-03-04</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/MA6268-Nonlinear-Optimization/" itemprop="url" rel="index"><span itemprop="name">MA6268 Nonlinear Optimization</span></a></span>

                
                
              
            </span>
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="basic-convex-analysis-1">3. Basic Convex Analysis (1)</h1>
<h2 id="convex-sets">3.1 Convex sets</h2>
<p><strong>Definition</strong> (Convex set)</p>
<p>A set <span class="math inline">\(D\subseteq \mathbb R^n\)</span> is said to be convex if for any two points <span class="math inline">\(x,y\in D\)</span>, the linear segment joining <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> also lies in <span class="math inline">\(D\)</span>. That is, <span class="math display">\[
\lambda x+(1-\lambda )y \in D \quad\forall \lambda \in[0,1],\forall x,y\in D.
\]</span> <strong>Notation</strong></p>
<p>To prove a given set <span class="math inline">\(C\)</span> is convex, we use the following procedures,</p>
<ol type="1">
<li>Choose two arbitrary points <span class="math inline">\(x,y\in C\)</span> and any <span class="math inline">\(\lambda \in [0,1]\)</span>.</li>
<li>Argue that <span class="math inline">\(\lambda x+(1-\lambda )y\in C\)</span>.</li>
</ol>
<p><strong>Example</strong> (Half space)</p>
<p>Given <span class="math inline">\(a\in \mathbb R^n\)</span>, the half space <span class="math inline">\(H=\{x\in \mathbb R^n\;|\;a^Tx\le \alpha\}\)</span> is a convex set.</p>
<p>Proof.</p>
<p>Consider <span class="math inline">\(x,y\in H\)</span>, and choose <span class="math inline">\(\lambda \in [0,1]\)</span>, we have <span class="math display">\[
a^T(\lambda x+(1-\lambda )y)=\lambda a^Tx+(1-\lambda)a^Ty\le \lambda \alpha+(1-\lambda)\alpha=\alpha.
\]</span> <strong>Example</strong> (n-ball)</p>
<p>Given <span class="math inline">\(a\in \mathbb R^n\)</span>, <span class="math inline">\(\alpha &gt;0\)</span>. The n-ball <span class="math display">\[
\bar B(a,\alpha)=\{x\in \mathbb R^n\,|\,||x-a||\le \alpha\}
\]</span> is a convex set.</p>
<p>Proof.</p>
<p>Consider <span class="math inline">\(x,y\in \bar B\)</span>, and choose <span class="math inline">\(\lambda \in [0,1]\)</span>, we have <span class="math display">\[
\begin{array}{rCl}
||\lambda x+(1-\lambda )y-a||&amp;=&amp;||\lambda x+(1-\lambda)y-\lambda a-(1-\lambda)a||\\
&amp;=&amp;||\lambda(x-a)+(1-\lambda)(y-a)||\\
&amp;\le&amp; \lambda ||x-a||+(1-\lambda )||y-a||\\
&amp;\le&amp; \lambda \alpha +(1-\lambda)\alpha\\ 
&amp;=&amp;\alpha.
\end{array}
\]</span> It is not very easy to prove the convexity by definition.</p>
<p><strong>Proposition</strong></p>
<p>(Finite or Infinite) intersection of convex sets is a convex set, i.e. if <span class="math inline">\(C_1,C_2,\dots,C_m\)</span> are convex sets in <span class="math inline">\(\mathbb R^n\)</span>, then <span class="math inline">\(C=\bigcap_{i=1}^m C_i\)</span> is also convex.</p>
<p>Proof.</p>
<p>Choose <span class="math inline">\(x,y \in \bigcap_{i=1}^k C_i\)</span> and <span class="math inline">\(\lambda\in [0,1]\)</span>. Since <span class="math inline">\(x,y \in C_i\)</span> and <span class="math inline">\(C_i\)</span> is a convex set. We have <span class="math inline">\(\lambda x+(1-\lambda)y\in C_i\;\forall i=1,\dotsm k\)</span>. That means <span class="math inline">\(\lambda x+(1-\lambda)y\in \bigcap_{i=1}^k C_i\)</span>. Q.E.D.</p>
<p><strong>Example</strong> (Polyhedron or polyhedral set)</p>
<p>The polyhedron or polyhedral sets <span class="math inline">\(\{x\in\mathbb R^n\;|\;Ax\le b\}\)</span> are convex.</p>
<h2 id="convex-and-concave-functions">3.2 Convex and concave functions</h2>
<p><strong>Definition</strong> (Convex function and strictly convex function)</p>
<p>Let <span class="math inline">\(D\subseteq \mathbb R^n\)</span> be a <strong>convex set</strong>. Consider a function <span class="math inline">\(f:D\rightarrow \mathbb R\)</span>.</p>
<ol type="a">
<li>The function is said to be convex if <span class="math display">\[
f(\lambda x+(1-\lambda )y)\le \lambda f(x)+(1-\lambda )f(y)\quad \forall x,y\in D,\lambda\in[0,1].
\]</span></li>
<li>The function is said to be strictly convex if <span class="math display">\[
f(\lambda x+(1-\lambda )y)&lt; \lambda f(x)+(1-\lambda )f(y)\quad \forall x,y\in D,\lambda\in[0,1].
\]</span> <strong>Notation</strong></li>
</ol>
<p><span class="math inline">\(-f\)</span> is convex $$ <span class="math inline">\(f\)</span> is concave.</p>
<p>To prove that a given function <span class="math inline">\(f:D\rightarrow \mathbb R\)</span> is convex, we use the following procedures,</p>
<ol type="1">
<li>Choose two arbitrary points <span class="math inline">\(x,y\in D\)</span> and any <span class="math inline">\(\lambda \in [0,1]\)</span></li>
<li>Argue that <span class="math inline">\(f(\lambda x+(1-\lambda )y)\le \lambda f(x)+(1-\lambda)f(y)\)</span>.</li>
</ol>
<p><strong>Example</strong></p>
<p>Let <span class="math inline">\(f:\mathbb R^2\rightarrow \mathbb R\)</span> where <span class="math inline">\(f(x)=||x||=(x_1^2+x_2^2)^\frac{1}{2}\)</span>, show that <span class="math inline">\(f\)</span> is convex in <span class="math inline">\(\mathbb R^2\)</span>.</p>
<p>Proof.</p>
<p>Choose <span class="math inline">\(x,y\in \mathbb R^2\)</span>, and <span class="math inline">\(\lambda \in [0,1]\)</span>, then we have <span class="math display">\[
f(\lambda x+(1-\lambda)y)=||\lambda x+(1-\lambda )y||\le \lambda ||x||+(1-\lambda)||y||.
\]</span> <strong>Example</strong></p>
<p>Let <span class="math inline">\(a\in \mathbb R^n\)</span> and <span class="math inline">\(\alpha \in \mathbb R\)</span>. Consider <span class="math inline">\(f:\mathbb R^n\rightarrow \mathbb R,f(x)=a^Tx+\alpha\)</span>. Prove that <span class="math inline">\(f\)</span> is convex.</p>
<p>Proof.</p>
<p>Choose <span class="math inline">\(x,y\in \mathbb R^2\)</span>, and <span class="math inline">\(\lambda \in [0,1]\)</span>, then we have <span class="math display">\[
f(\lambda x+(1-\lambda)y)=a^T(\lambda x+(1-\lambda)y)+\alpha =\lambda f(x)+(1-\lambda)f(y).
\]</span> <strong>Example</strong></p>
<p>Show that <span class="math inline">\(f:\mathbb R^2\rightarrow \mathbb R\)</span> defined by <span class="math inline">\(f(x)=x_1^2-4x_2\)</span> is convex.</p>
<p>Proof.</p>
<p>Choose <span class="math inline">\(x,y\in \mathbb R^2\)</span> and <span class="math inline">\(\lambda \in [0,1]\)</span>, then we have <span class="math display">\[
\begin{array}{rCl}
f(\lambda x+(1-\lambda)y)&amp;=&amp;(\lambda x_1+(1-\lambda)y_1)^2-4(\lambda x_2+(1-\lambda)y_2)\\
&amp;=&amp;\lambda^2x_1^2+2\lambda x_1(1-\lambda)y_1+(1-\lambda)^2y_1^2-4\lambda x_2-4(1-\lambda)y_2\\
&amp;\le&amp; \lambda^2x_1^2+\lambda (1-\lambda)(x_1^2+y_1^2)+(1-\lambda)^2y_1^2-4\lambda x_2-4(1-\lambda)y_2\\
&amp;=&amp;\lambda f(x)+(1-\lambda)f(y).
\end{array}
\]</span> <strong>Proposition</strong></p>
<p>If <span class="math inline">\(f_1,f_2:D\rightarrow \mathbb R\)</span> are convex function on a convex set <span class="math inline">\(D\subseteq \mathbb R^n\)</span>, then</p>
<ol type="1">
<li><span class="math inline">\(f_1+f_2\)</span> is a convex function on <span class="math inline">\(D\)</span>.</li>
<li><span class="math inline">\(\alpha f_1\)</span> is a convex function on D for <span class="math inline">\(\alpha \ge 0\)</span>.</li>
</ol>
<p>Proof.</p>
<p>Let <span class="math inline">\(g=f_1+f_2\)</span>. For <span class="math inline">\(x,y\in D\)</span> and <span class="math inline">\(\lambda \in [0,1]\)</span>, we have <span class="math display">\[
\begin{array}{rCl}
g(\lambda x+(1-\lambda)y)&amp;=&amp;f_1(\lambda x+(1-\lambda)y)+f_2(\lambda x+(1-\lambda)y)\\
&amp;\le&amp; \lambda g+(1-\lambda)g.
\end{array}
\]</span> Proof of 2. is straightforward.</p>
<p><strong>Corollary</strong></p>
<p>Let <span class="math inline">\(f_1,f_2,\dotsm,f_k:D\rightarrow \mathbb R\)</span> are convex functions on a convex set <span class="math inline">\(D\subseteq \mathbb R^n\)</span>. Then <span class="math display">\[
f(x)=\sum_{j=1}^k\alpha_jf_j(x),
\]</span> where <span class="math inline">\(\alpha_j\ge 0\)</span>, is also a convex function. If one of the functions is strictly convex, then <span class="math inline">\(f(x)\)</span> is strictly convex.</p>
<p>Proof.</p>
<p>It is straightforward to use the previous proposition.</p>
<p><strong>Example</strong></p>
<p>The objective function <span class="math inline">\(f(x)=\frac{1}{2}||Ax-b||^2+\lambda ||x||_1\)</span>, where <span class="math inline">\(x\in\mathbb R^n\)</span> for the sparse regression problem is a convex function.</p>
<p><strong>Proposition</strong></p>
<p>Let <span class="math inline">\(h:D\rightarrow \mathbb R\)</span> be convex function and <span class="math inline">\(g:\mathcal X\rightarrow \mathbb R\)</span> be a <strong>nondecreasing convex</strong> function with <span class="math inline">\(h(D)\subset \mathcal X\)</span>. Then the composition function <span class="math inline">\(f=g\circ h:D\rightarrow \mathbb R\)</span> is a convex function.</p>
<p>Proof. <span class="math display">\[
\begin{array}{rCl}
f(\lambda x+(1-\lambda )y)&amp;=&amp;g(h(\lambda x+(1-\lambda)y))\\
&amp;\le&amp; g(\lambda h(x)+(1-\lambda)h(y))\text{ (Since $h$ is convex and $g$ is non-decreasing)}\\
&amp;\le&amp; \lambda g(h(x))+(1-\lambda)g(h(y)) \text{ (Since $g$ is convex)}.
\end{array}
\]</span> <strong>Proposition</strong></p>
<p>Let <span class="math inline">\(h:D\rightarrow \mathbb R\)</span> be convex function and <span class="math inline">\(g:\mathcal X\rightarrow \mathbb R\)</span> be a <strong>nonincreasing concave</strong> function with <span class="math inline">\(h(D)\subset \mathcal X\)</span>. Then the composition function <span class="math inline">\(f=g\circ h:D\rightarrow \mathbb R\)</span> is a concave function.</p>
<p>Proof. Same as the previous proposition.</p>
<p>The next result depicts a useful relationship between convex function and convex set.</p>
<p><strong>Proposition</strong></p>
<p>Suppose <span class="math inline">\(D\subset \mathbb R^n\)</span> is convex. If <span class="math inline">\(f:D\rightarrow \mathbb R\)</span> is convex, then for any <span class="math inline">\(\alpha \in \mathbb R\)</span>, the set <span class="math display">\[
S_\alpha=\{x\in D\;|\;f(x)\le \alpha\},
\]</span> is convex.</p>
<p>Proof.</p>
<p>Assume any <span class="math inline">\(x,y\in S_\alpha\)</span>, and any <span class="math inline">\(\lambda \in [0,1]\)</span>. Then we have <span class="math display">\[
f(\lambda x+(1-\lambda)y)\le \lambda f(x)+(1-\lambda )f(y)\le \lambda \alpha +(1-\lambda )\alpha = \alpha.
\]</span> That means the point <span class="math inline">\(\lambda x+(1-\lambda)y\)</span> is also in the set. Q.E.D.</p>
<p><strong>Proposition</strong> (Epigraph theorem)</p>
<p>Suppose <span class="math inline">\(f:D\rightarrow \mathbb R\)</span> is a function defined on a convex set <span class="math inline">\(D\subset \mathbb R^n\)</span>. The <strong>epigraph</strong> of <span class="math inline">\(f\)</span> is the following subset of <span class="math inline">\(\mathbb R^{n+1}\)</span>, <span class="math display">\[
E_f=\{[x;\alpha]\;|\; x\in D,\alpha\in \mathbb R,f(x)\le \alpha\}.
\]</span> The epigraph <span class="math inline">\(E_f\)</span> is a convex set if and only if <span class="math inline">\(f\)</span> is convex function.</p>
<p>Proof.</p>
<p><span class="math inline">\(\implies\)</span></p>
<p>If the epigraph <span class="math inline">\(E_f\)</span> is a convex set, then for any <span class="math inline">\([x,f(x)],[y,f(y)]\in E_f\)</span>, and for any <span class="math inline">\(\lambda \in [0,1]\)</span>, we have <span class="math display">\[
\lambda [x;f(x)]+(1-\lambda)[y;f(y)]\in E_f\\
\lambda [x;f(x)]+(1-\lambda)[y;f(y)]=[\lambda x+(1-\lambda )y;\lambda f(x)+(1-\lambda )f(y)].
\]</span> Then by definition, we have <span class="math inline">\(f(\lambda x+(1-\lambda )y)\le \lambda f(x)+(1-\lambda )f(y)\)</span>.</p>
<p><span class="math inline">\(\Longleftarrow\)</span></p>
<p>If the function <span class="math inline">\(f\)</span> is a convex function, then for every <span class="math inline">\([x;\alpha],[y;\beta]\in E_f\)</span>, which means <span class="math inline">\(f(x)\le \alpha\)</span> and <span class="math inline">\(f(y)\le \beta\)</span>, we choose <span class="math inline">\(\lambda \in [0,1]\)</span>. We have <span class="math display">\[
\lambda [x;\alpha]+(1-\lambda )[y;\beta]=[\lambda x+(1-\lambda)y;\lambda \alpha+(1-\lambda)\beta].
\]</span> We need to prove <span class="math inline">\(f(\lambda x+(1-\lambda )y)\le \lambda \alpha +(1-\lambda)\beta\)</span>.</p>
<p>Then we find <span class="math display">\[
f(\lambda x+(1-\lambda)y)\le \lambda f(x)+(1-\lambda)f(y)\le \lambda \alpha+(1-\lambda)\beta,
\]</span> which means <span class="math display">\[
[\lambda x+(1-\lambda)y;\lambda \alpha+(1-\lambda)\beta]\in E_f.
\]</span> Q.E.D.</p>
<p><strong>Proposition</strong> (Jensen's inequality)</p>
<p>Suppose <span class="math inline">\(f:S\rightarrow \mathbb R\)</span> is a convex function on a convex set <span class="math inline">\(S\subseteq \mathbb R^n\)</span>, and <span class="math inline">\(x_1,x_2,\dotsm,x_n\in S\)</span>. Let <span class="math display">\[
x=\sum_{j=1}^k \lambda_j x_j,\quad \sum_{j=1}^k\lambda_j=1,\quad \lambda_j\ge 0.
\]</span> Then <span class="math display">\[
f(x)\le \sum_{j=1}^k\lambda_k f(x_k).
\]</span></p>
<p><strong>Example</strong></p>
<p>Use the Jensen’s inequality and the convex function <span class="math inline">\(f(x)=-\log x\)</span> to prove <span class="math display">\[
(a_1\dotsm a_k)^{1/k} \le \frac{1}{k}\sum_{j=1}^k a_j.
\]</span> Proof.</p>
<p>Choose <span class="math inline">\(\lambda_1=\lambda_2=\dotsm =\lambda_k=\frac{1}{k}\)</span>. It follows, <span class="math inline">\(x=\frac{1}{k}\sum_{j=1}^k x_j\)</span>. Then we have <span class="math display">\[
-\log x\le -\frac{1}{k}\sum_{j=1}^k \log (x_j)=-\log [(x_1\dotsm x_k)^{\frac{1}{k}}]\\
\log x\ge\log [(x_1\dotsm x_k)^{\frac{1}{k}}]\\
(x_1\dotsm x_k)^{\frac{1}{k}}\le \frac{1}{k}\sum_{j=1}^k x_j.
\]</span></p>
<h2 id="differentiable-convex-functions">3.3 Differentiable convex functions</h2>
<p>If the function is twice differentiable, we can check the convexity of the function much more easily.</p>
<p><strong>Theorem</strong> (Tangent plane characterization)</p>
<p>Suppose that <span class="math inline">\(f(x)\)</span> has continuous first partial derivatives on an open convex set <span class="math inline">\(S\)</span> in <span class="math inline">\(\mathbb R^n\)</span>. Then,</p>
<ol type="1">
<li>the function is convex if and only if</li>
</ol>
<p><span class="math display">\[
f(x)+\nabla f(x)(y-x)\le f(y)\quad \forall x,y\in S.
\]</span></p>
<ol start="2" type="1">
<li>the function is strictly convex if and only if</li>
</ol>
<p><span class="math display">\[
f(x)+\nabla f(x)(y-x)&lt; f(y)\quad \forall x,y\in S.
\]</span></p>
<p>Proof of 1.</p>
<p><span class="math inline">\(\implies\)</span></p>
<p>Suppose <span class="math inline">\(f:D\rightarrow \mathbb R\)</span> is convex, then we have <span class="math display">\[
f(\lambda y+(1-\lambda )x)\le \lambda f(y)+(1-\lambda )f(x)\quad \forall x,y\in D,\lambda \in [0,1]
\]</span> Then we have <span class="math display">\[
\frac{f(x +\lambda (y-x))-f(x)}{\lambda}\le f(y)-f(x)
\]</span> When <span class="math inline">\(\lambda \rightarrow 0\)</span>, the left hand side is <span class="math inline">\(\nabla f(x) ^T(y-x)\)</span>.</p>
<p><span class="math inline">\(\Longleftarrow\)</span></p>
<p>Assume <span class="math inline">\(f(x)+\nabla f(x)(y-x)\le f(y)\)</span>. Let <span class="math inline">\(u,v\in S\)</span> and <span class="math inline">\(\lambda \in [0,1]\)</span>, and define <span class="math inline">\(w=u+(1-\lambda )v\)</span>. Then we have</p>
<p><span class="math display">\[
f(w)+\nabla f(w)(u-w)\le f(u)\\
f(w)+\nabla f(w)(v-w)\le f(v).
\]</span> Since we have <span class="math inline">\(v-w=-\frac{\lambda}{1-\lambda}(u-w)\)</span>, we can cancel <span class="math inline">\(\nabla f(\cdot)\)</span>. Q.E.D.</p>
<p><strong>Remark</strong></p>
<p>The equation <span class="math inline">\(z=f(x)+\nabla f(x)^T(y-x)\)</span> define the tangent plane to the surface <span class="math inline">\(z=f(x)\)</span> at <span class="math inline">\(y=x\)</span>. Thus this theorem shows that the tangent plane is below the convex function.</p>
<p><strong>Proposition</strong> (Monotone gradient condition)</p>
<p>Let <span class="math inline">\(f:S\rightarrow \mathbb R\)</span> be differentiable function on the open convex subset <span class="math inline">\(S\)</span> of <span class="math inline">\(\mathbb R^n\)</span>. Then <span class="math inline">\(f\)</span> is convex on <span class="math inline">\(S\)</span> if and only if <span class="math display">\[
\left\langle \nabla f(x)-\nabla f(y),x-y\right\rangle\ge 0\quad \forall x,y\in S
\]</span> Proof.</p>
<p><span class="math inline">\(\implies\)</span> <span class="math display">\[
f(x)+\nabla f(x)^T(y-x)\le f(y)\\
f(y)-\nabla f(y)^T(y-x)\le f(x).
\]</span> By doing the summation, Q.E.D.</p>
<p><span class="math inline">\(\Longleftarrow\)</span></p>
<p>Suppose we have <span class="math inline">\(\left\langle \nabla f(x)-\nabla f(y),x-y\right\rangle\ge 0\quad \forall x,y\in S\)</span>.</p>
<p>Define <span class="math inline">\(g(t)=f(x+t(y-x))\)</span>. Then we have <span class="math display">\[
g&#39;(t)=\langle \nabla f(x+t(y-x)),y-x\rangle.
\]</span> Then we have <span class="math display">\[
g&#39;(t)-g&#39;(0)=\langle \nabla f(x+t(y-x))-\nabla f(x),y-x\rangle\ge 0\quad \forall t\in[0,1].
\]</span> Then we have <span class="math display">\[
g(1)=f(y)=g(0)+\int _0^1 g&#39;(t)dt\ge g(0)+g&#39;(0)=f(x)+\langle \nabla f(x),y-x\rangle.
\]</span> Q.E.D.</p>
<p><strong>Theorem</strong> (Test for convexity of a differentiable function)</p>
<ol type="1">
<li><p>Suppose that <span class="math inline">\(f(x)\)</span> has continuous second partial derivatives on an open convex set <span class="math inline">\(D\subset \mathbb R^n\)</span>, the function is convex on <span class="math inline">\(D\)</span> <strong>if and only if</strong> the Hessian matrix is positive semidefinite.</p></li>
<li><p>If the Hessian matrix is positive definite, then <span class="math inline">\(f\)</span> is strictly convex. (Converse is not true)</p></li>
<li><p>If the Hessian matrix is indefinite, then <span class="math inline">\(f\)</span> is not a convex nor a concave function on <span class="math inline">\(D\)</span>.</p></li>
</ol>
<h2 id="strongly-convex-functions">3.4 Strongly convex functions</h2>
<p><strong>Definition</strong></p>
<p>Let <span class="math inline">\(D\subseteq \mathbb R^n\)</span> be a convex set. A function <span class="math inline">\(f:D\rightarrow \mathbb R\)</span> is said to be strongly convex if there exists a constant <span class="math inline">\(c&gt;0\)</span> such that for all <span class="math inline">\(x,y\in D\)</span>, and <span class="math inline">\(\lambda \in[0,1]\)</span>, <span class="math display">\[
f(\lambda x+(1-\lambda)y)\le \lambda f(x)+(1-\lambda)f(y)-\frac{c}{2}\lambda(1-\lambda)||x-y||^2.
\]</span> <strong>Theorem</strong></p>
<p>Suppose <span class="math inline">\(f:D\rightarrow \mathbb R\)</span> is a differentiable function. Then the following statements are equivalent,</p>
<ol type="1">
<li><p><span class="math inline">\(f(y)\ge f(x)+\langle \nabla f(x),y-x\rangle+(c/2)||y-x||^2\)</span></p></li>
<li><p><span class="math inline">\(g(x)=f(x)-(c/2)||x||^2\)</span> is convex</p></li>
<li><p><span class="math inline">\(\langle\nabla f(x)-\nabla f(y),x-y\rangle\ge c||x-y||^2\)</span></p></li>
<li><p><span class="math inline">\(f\)</span> is strongly convex.</p></li>
</ol>
<p>Proof. (<span class="math inline">\(1\iff 2\)</span>)</p>
<p><span class="math inline">\(\Longleftarrow\)</span></p>
<p>If <span class="math inline">\(g(x)=f(x)-(c/2)||x||^2\)</span> is convex, then we have <span class="math display">\[
\begin{array}{rcl}
g(y)&amp;\ge&amp; g(x)+\nabla g(x)(y-x)\implies\\
f(y)-(c/2)||y||^2&amp;\ge&amp; f(x)-(c/2)||x||^2+\nabla f(x)^T(y-x)-cx^T(y-x)\implies\\
f(y)&amp;\ge&amp; f(x)+\nabla f(x)^T(y-x)+(c/2)\left(||y||^2-2x^Ty+||x||^2\right)\implies\\
f(y)&amp;\ge&amp; f(x)+\nabla f(x)^T(y-x)+(c/2)||y-x||^2
\end{array}
\]</span> <span class="math inline">\(\implies\)</span></p>
<p>By Tangent plane characterization in Section 3.3.</p>
<p>(<span class="math inline">\(2\iff 3\)</span>) Monotone gradient.</p>
<p>(<span class="math inline">\(1\iff 4\)</span>) Straightforward. Q.E.D.</p>
<p>The following conditions are implied by the strong convexity of <span class="math inline">\(f\)</span>. Let <span class="math inline">\(x^*\)</span> be a minimizer of <span class="math inline">\(f\)</span> over <span class="math inline">\(D\)</span>.</p>
<ol type="1">
<li><span class="math inline">\((1/2c)||\nabla f(x)||^2\ge f(x)-f(x^*)\)</span>.</li>
<li><span class="math inline">\(||\nabla f(x)-\nabla f(y)||\ge c||x-y||\)</span>.</li>
<li><span class="math inline">\(f(y)\le f(x)+\langle \nabla f(x),y-x\rangle +(1/2c)||\nabla f(y)-\nabla f(x)||^2\)</span>.</li>
<li><span class="math inline">\(\langle \nabla f(x)-\nabla f(y),x-y\rangle \le (1/c)||\nabla f(x)-\nabla f(y)||^2\)</span>.</li>
</ol>
<p>Proof.</p>
<ol type="1">
<li><p>Since we have <span class="math inline">\(f(y)\ge f(x)+\langle\nabla f(x),y-x\rangle+(c/2)||y-x||^2\)</span>, for any fixed point <span class="math inline">\(x\)</span>, we can derive the minimal value of the right hand side. <span class="math inline">\(f(x)+\langle \nabla f(x),y-x\rangle+(c/2)||y-x||^2\ge f(x)-(1/2c)||\nabla f(x)||^2\)</span>. Then we have <span class="math display">\[
f(y)\ge f(x)-(1/2c)||\nabla f(x)||^2 \quad \forall x,y \in \mathbb R^n.
\]</span> Then we let <span class="math inline">\(y=x^*\)</span>. Q.E.D.</p>
<p>By this condition, we can see that if the gradient is getting smaller, that means the current value of the cost function is getting to the optimal value.</p></li>
<li><p>From the condition 3 in the Theorem 3.3</p></li>
<li><p>We define the function <span class="math inline">\(\phi_x(z)=f(z)-\langle \nabla f(x),z\rangle\)</span>. We can find the analytical minimizer of this function as <span class="math display">\[
\nabla \phi_x(z)=\nabla f(z)-\nabla f(x)=0\implies z^* =x.
\]</span> Then we use the condition 1, <span class="math display">\[
(1/2c)||\nabla f(y)-\nabla f(x)||^2\ge f(y)-\langle \nabla f(x),x-y\rangle-f(x).
\]</span></p></li>
<li><p>By doing summary of the following two inequalities, <span class="math display">\[
f(y)\le f(x)+\langle \nabla f(x),y-x\rangle +(1/2c)||\nabla f(y)-\nabla f(x)||^2\\
f(x)\le f(y)+\langle \nabla f(y),y-x\rangle +(1/2c)||\nabla f(x)-\nabla f(y)||^2.
\]</span></p></li>
</ol>
<p>Q.E.D.</p>
<h2 id="unconstrained-convex-programming-problem">3.5 Unconstrained convex programming problem</h2>
<p>A convex programming problem is a minimization problem whose objective function is convex and the feasible set is convex. In general, a local minimizer is not a global minimizer. However, for a convex minimization problem, a local minimizer is also a global minimizer.</p>
<p>An <strong>unconstrained convex nonlinear programming problem</strong> is the following, <span class="math display">\[
\begin{array}{rl}
\text{minimize}&amp;f(x)\\ 
\text{subject to}&amp;x\in D,
\end{array}
\]</span> where <span class="math inline">\(D\)</span> is an open convex set, and the function <span class="math inline">\(f\)</span> is convex on <span class="math inline">\(D\)</span>.</p>
<p><strong>Theorem</strong></p>
<p>Let <span class="math inline">\(D\)</span> be a nonempty open convex subset of <span class="math inline">\(\mathbb R^n\)</span>, and <span class="math inline">\(f:D\rightarrow \mathbb R\)</span> is a convex function. Consider the convex minimization problem. Suppose <span class="math inline">\(x^* \in D\)</span> is a local minimizer to the problem, then</p>
<ol type="1">
<li><span class="math inline">\(x^*\)</span> is a global minimizer</li>
<li>If <span class="math inline">\(f\)</span> is strictly convex, then <span class="math inline">\(x^*\)</span> is the unique global minimizer.</li>
</ol>
<p>Proof.</p>
<ol type="1">
<li><p>We assume <span class="math inline">\(x^*\in D\)</span> is a local minimizer, which means there exists a ball <span class="math inline">\(B_\epsilon(x^*)\)</span>, such that for all points <span class="math inline">\(x\in B_\epsilon(x^*)\)</span>, <span class="math inline">\(f(x)\ge f(x^*)\)</span>.</p>
<p>Then we need to prove that <span class="math inline">\(x^*\)</span> is a global minimizer, which means for all points <span class="math inline">\(y\in D\)</span>, we have <span class="math inline">\(f(y)\ge f(x^*)\)</span>.</p>
<p>We consider the point <span class="math inline">\(\lambda y+(1-\lambda )x^* \in D\)</span>. If $$ is enough small, then the point is also in the ball. That means we have <span class="math display">\[
\lambda f(y)+(1-\lambda)f(x^*)\ge f(\lambda y+(1-\lambda)x^*)\ge f(x^*).
\]</span> Q.E.D.</p></li>
<li><p>Assume <span class="math inline">\(x^* \in D\)</span> is the global optimizer. If there is another global minimizer <span class="math inline">\(\bar x\)</span>, for which we have <span class="math inline">\(f(\bar x)=f(x^*)\)</span>.</p>
<p>Then we choose <span class="math inline">\(w=(1/2)x^*+(1/2)\bar x\)</span>. <span class="math display">\[
f(w)=f((1/2)x^*+(1/2)\bar x)&lt; (1/2)f(x^*)+(1/2)f(\bar x)=f(x^*),
\]</span> which contradicts that the point <span class="math inline">\(x^*\)</span> is the global optimal point.</p>
<p>Q.E.D.</p></li>
</ol>
<p><strong>Corollary</strong></p>
<p>If <span class="math inline">\(f\)</span> is a convex function with continuous first partial derivatives on some open convex set <span class="math inline">\(D\)</span>, then any stationary point of <span class="math inline">\(f\)</span> is a global minimizer of <span class="math inline">\(f\)</span>.</p>
<p>Proof.</p>
<p>Suppose <span class="math inline">\(x^*\)</span> is the stationary point, i.e., <span class="math inline">\(\nabla f(x^*)=0\)</span>.</p>
<p>We need to prove <span class="math inline">\(x^*\)</span> is a global minimizer of <span class="math inline">\(f\)</span>, i.e., for all <span class="math inline">\(y\in D\)</span>, we have <span class="math inline">\(f(y)\ge f(x^*)\)</span>.</p>
<p>Since <span class="math inline">\(f\)</span> is a convex function, we have <span class="math display">\[
f(y)\ge f(x^*)+\nabla f(x^*)^T(y-x^*)=f(x^*).
\]</span> Q.E.D.</p>
<h2 id="unconstrained-convex-quadratic-programming">3.6 Unconstrained convex quadratic programming</h2>
<p><strong>Definition</strong> (Quadratic function)</p>
<p>A quadratic function <span class="math inline">\(q:\mathbb R^n\rightarrow \mathbb R\)</span> is defined by <span class="math display">\[
q(x)=\frac{1}{2}x^TQx+c^Tx.
\]</span> The quadratic function is a convex function if <span class="math inline">\(Q\)</span> is positive semidefinite.</p>
<p>The point <span class="math inline">\(x^* \in S\)</span> is a global minimizer of the problem if and only if <span class="math inline">\(Qx^* =-c\)</span>.</p>
<h2 id="projection-onto-a-closed-convex-set">3.7 Projection onto a closed convex set</h2>
<p><strong>Theorem</strong></p>
<p>Let <span class="math inline">\(f:C\rightarrow \mathbb R\)</span> be a convex and continuously differentiable function on the convex set <span class="math inline">\(C\subset \mathcal E\)</span>. Consider the constrained minimization problem, <span class="math display">\[
\min\left\{f(x)\;|\;x\in C\right\}.
\]</span> Then <span class="math inline">\(x^*\in C\)</span> is a global minimizer if and only if <span class="math display">\[
\langle \nabla f(x^*),x-x^*\rangle\ge 0,\;\forall x\in C.
\]</span> Proof.</p>
<p><span class="math inline">\(\Longleftarrow\)</span></p>
<p>Suppose there is a <span class="math inline">\(x^*\in C\)</span> satisfying <span class="math inline">\(\langle \nabla f(x^*),x-x^*\rangle\ge 0,\;\forall x\in C\)</span>.</p>
<p>We need to prove <span class="math inline">\(x^*\in C\)</span> is a global minimizer, i.e., for all <span class="math inline">\(y\in C\)</span>, we have <span class="math inline">\(f(y)\ge f(x^*)\)</span>.</p>
<p>Since <span class="math inline">\(f\)</span> is convex, we have <span class="math display">\[
f(y)\ge f(x)+\nabla f(x)^T(y-x),\;\forall x,y\in C.
\]</span> Then we have <span class="math display">\[
f(y)\ge f(x^*)+\nabla f(x^*)^T(y-x^*)\ge f(x^*),\;\forall y\in C.
\]</span> That means <span class="math inline">\(x^*\)</span> is the global minimizer.</p>
<p><span class="math inline">\(\implies\)</span></p>
<p>We will approve the sufficient condition by contradiction.</p>
<p>Suppose <span class="math inline">\(x^*\)</span> is a global minimizer, i.e., for all <span class="math inline">\(y\in C\)</span>, we have <span class="math inline">\(f(y)\ge f(x^*)\)</span>. Suppose that there exists <span class="math inline">\(\bar x\in C\)</span> such that <span class="math inline">\(\langle \nabla f(x^*),\bar x-x^*\rangle&lt; 0\)</span>.</p>
<p>Consider the point <span class="math inline">\(w=t\bar x+(1-t)x^*\)</span>. Note that <span class="math inline">\(f(w)-f(x^*)\le \nabla f(w)^T(w-x^*)\)</span>. Then <span class="math display">\[
\begin{array}{rcl}
0&amp;\le&amp; f(w)-f(x^*)\le \nabla f(w)^T(w-x^*)\\
&amp;=&amp;\langle \nabla f(t\bar x+(1-t)x^*),(t\bar x+(1-t)x^*-x^*)\rangle\\
&amp;=&amp;\langle \nabla f(t\bar x+(1-t)x^*),t(\bar x-x^*)\rangle\\
&amp;=&amp;\langle \nabla f(t(\bar x-x^*)+x^*),t(\bar x-x^*)\rangle.
\end{array}
\]</span> Let <span class="math inline">\(t\downarrow 0\)</span>, we have <span class="math inline">\(\langle \nabla f(x^*),\bar x-x^*\rangle \ge 0\)</span>.</p>
<p>Q.E.D.</p>
<p><strong>Remark</strong></p>
<p>Using the concept of the <strong>normal cone</strong>, we can rephrase the theorem as follows,</p>
<p><span class="math inline">\(x^*\)</span> is a global minimizer of the problem <span class="math inline">\(\min\{f(x)\;|\;x\in C\}\)</span> if and only if <span class="math inline">\(-\nabla f(x^*)\in N_C(x^*)\)</span>.</p>
<p><strong>Theorem</strong> (Projection theorem)</p>
<p>Let <span class="math inline">\(C\)</span> be a closed convex set in <span class="math inline">\(\mathcal E\)</span>,</p>
<ol type="1">
<li><p>For every <span class="math inline">\(z\in \mathcal E\)</span>, there exists a unique minimizer (denoted as <span class="math inline">\(\Pi_C(z)\)</span> and called as the <strong>projection</strong> of <span class="math inline">\(z\)</span> onto <span class="math inline">\(C\)</span>) of <span class="math display">\[
\min\left\{\frac{1}{2}||x-z||^2\;|\; x\in C\right\},
\]</span> where <span class="math inline">\(||\cdot||\)</span> is the Euclidean norm.</p></li>
<li><p><span class="math inline">\(x^*=\Pi_C(z)\)</span> is the projection of <span class="math inline">\(z\)</span> onto <span class="math inline">\(C\)</span> if and only if <span class="math display">\[
\langle z-x^*,x-x^*\rangle\le 0\quad\forall x\in C.
\]</span></p></li>
<li><p>(Firmly non-expansive property) For any <span class="math inline">\(z,w\in \mathcal E\)</span>, <span class="math display">\[
||\Pi_C(z)-\Pi_C(w)||^2\le \langle z-w,\Pi_C(z)-\Pi_C(w)\rangle.
\]</span> Firmly non-expansive property implies non-expansive property, which means <span class="math inline">\(||\Pi_C(z)-\Pi_C(w)||\le ||z-w||\)</span>. That is, <span class="math inline">\(\Pi_C(\cdot)\)</span> is <strong>Lipschitz continuous</strong> with modulus 1.</p></li>
</ol>
<p>Proof.</p>
<ol type="1">
<li><p>Choose <span class="math inline">\(\bar x\in C\)</span>. Define the set <span class="math inline">\(S=\{x\in C\;|\;f(x)\le f(\bar x)\}\)</span>. It can be proved that the set <span class="math inline">\(S\)</span> is closed and bounded. By Weierstrass Theorem, there exists <span class="math inline">\(x^* \in S\)</span> such that <span class="math inline">\(f(x^*)\le f(x)\quad\forall x\in S\)</span>. And we also have <span class="math display">\[
f(x)&gt;f(\bar x)\ge f(x^*)\quad\forall x\in C\backslash S.
\]</span> Thus we have shown for all <span class="math inline">\(x\in C\backslash S\cup S=C\)</span>, <span class="math inline">\(f(x^* )\le f(x)\)</span>.</p>
<p>Since the function <span class="math inline">\(f(x)=\frac{1}{2}||x-z||^2\)</span> is strictly convex on <span class="math inline">\(C\)</span>, the minimizer is unique.</p></li>
<li><p>From the above theorem, we have <span class="math display">\[
\langle \nabla f(x^*),x-x^*\rangle\ge 0.
\]</span> Q.E.D.</p></li>
<li><p>From condition 2, we have <span class="math inline">\(w,z\in \mathcal E\)</span>. Since <span class="math inline">\(\Pi_C(w)\in \mathcal E\)</span> and <span class="math inline">\(\Pi_C(z)\in \mathcal E\)</span>. Then we have <span class="math display">\[
\begin{array}{rcl}
\langle z-\Pi_C(z),\Pi_C(w)-\Pi_C(z)\rangle&amp;\le&amp;  0\quad (1)\\
\langle w-\Pi_C(w),\Pi_C(z)-\Pi_C(w)\rangle&amp;\le&amp;  0\\
\langle\Pi_C(w)-w,\Pi_C(w)-\Pi_C(z)\rangle&amp;\le&amp;  0\quad (2).
\end{array}
\]</span></p>
<ol type="1">
<li><ul>
<li>(2), <span class="math display">\[
\langle z-w-\Pi_C(z)+\Pi_C(w),\Pi_C(w)-\Pi_C(z)\rangle\le 0.
\]</span></li>
</ul></li>
</ol>
<p>Q.E.D.</p></li>
</ol>
<p><strong>Remark</strong></p>
<p>If <span class="math inline">\(C\)</span> is a linear subspace of <span class="math inline">\(\mathbb R^n\)</span>, then <span class="math inline">\(z-x^* \perp C\)</span>. Thus <span class="math inline">\(z\)</span> can be decomposed into two perpendicular components, <span class="math display">\[
z=\Pi_C(z)+(z-\Pi_C(z)),\quad \text{where}\quad \langle\Pi_C(z),z-\Pi_C(z)\rangle=0.
\]</span> <strong>Example</strong></p>
<p>Let <span class="math inline">\(C=\mathbb R_+^n\)</span>. Then for any <span class="math inline">\(z\in \mathbb R^n\)</span>, <span class="math inline">\(\Pi_C(z)=\max\{z,0\}\)</span>.</p>
<p>Proof. <span class="math display">\[
\min\left\{\frac{1}{2}||x-z||^2\;|\; x\in \mathbb R^n_+\right\}
\]</span> Since we have <span class="math display">\[
||x-z||^2=(x^2_1-2z_1x_1+z^2_1)+\dotsm+(x^2_n-2z_nx_1+z^2_n)
\]</span> Every part should be minimized.</p>
<p><strong>Example</strong></p>
<p><span class="math inline">\(C=\{x\in\ \mathbb R^n\;|\; \sum_{i=1}^n x_i=1,x\ge0\}\)</span> is a simplex. Suppose <span class="math inline">\(z\in \mathbb R^n\)</span> satisfies the condition that <span class="math inline">\(z_1\ge z_2\ge \dotsm\ge z_n\)</span>. Let <span class="math inline">\(k\)</span> be the maximum index in the set <span class="math inline">\(\{1\le j\le n\;|\; z_j+(1-\sum_{i=1}^j z_j)&gt;0\}\)</span>. Set <span class="math display">\[
\lambda = \frac{1}{k}\left(1-\sum_{i=1}^k z_i\right).
\]</span> Then the projection onto the simplex <span class="math inline">\(C\)</span> is given by <span class="math display">\[
\Pi_C(z)=\max\{z+\lambda e,0\}.
\]</span> <strong>Example</strong></p>
<p>Let <span class="math inline">\(C=\mathbb S_+^n\)</span> is the positive semidefinite matrices space. For a given <span class="math inline">\(A\in\mathbb S_n\)</span>, let the eigenvalue decomposition of <span class="math inline">\(A\)</span> be <span class="math inline">\(A=U\text{diag}(d)U^T\)</span>, then we have <span class="math inline">\(\Pi_C(A)=U(\text{diag}(\max\{d,0\}))U^T\)</span>.</p>
<p>Not that <span class="math inline">\(U\)</span> is orthogonal. Then we have <span class="math display">\[
\begin{array}{rcl}
\min\{\frac{1}{2}||X-A||^2_F\;|\; X\in\mathbb  S^n_+\}&amp;=&amp;\min\{\frac{1}{2}||U(U^TXU-\text{diag}(d))U^T||^2_F\;|\; X\in\mathbb  S^n_+\}\\
&amp;=&amp;\min\{\frac{1}{2}||U^TXU-\text{diag}(d)||^2_F\;|\; X\in\mathbb  S^n_+\}\text{ (Trace Property)}\\
&amp;=&amp;\min\{\frac{1}{2}||\bar X-\text{diag}(d)||^2_F\;|\; \bar X\in\mathbb  S^n_+\}\\
&amp;=&amp;\min\{\frac{1}{2}||\text{diag}(x)-\text{diag}(d)||^2_F\;|\; x\ge0\}\\
&amp;=&amp;\min\{\frac{1}{2}||x-d||^2\;|\; x\ge0\}.
\end{array}
\]</span> Then we have <span class="math inline">\(x^* =\max\{0,d\}\)</span>.</p>
<p><strong>Definition</strong> (Fréchet differentiable)</p>
<p>Let <span class="math inline">\(\mathcal E_1,\mathcal E_2\)</span> be two differentiable finite-dimensional real Euclidean spaces. A function <span class="math inline">\(f:\mathcal E_1\rightarrow \mathcal E_2\)</span> is said to be Fréchet differentiable at <span class="math inline">\(\mathcal x\in E_1\)</span> if there exists a linear map <span class="math inline">\(f&#39;(x):\mathcal E_1\rightarrow \mathcal E_2\)</span> such that for any <span class="math inline">\(h\rightarrow 0\)</span>, <span class="math display">\[
f(x+h)-f(x)-f&#39;(x)[h]=o(||h||).
\]</span> This can be explained by <span class="math display">\[
\lim_{h\rightarrow 0}\frac{f(x+h)-f(x)}{h}=f&#39;(x)\\ \iff\lim_{h\rightarrow 0}\frac{f(x+h)-f(x)-f&#39;(x)[h]}{h}=0\\ \iff f(x+h)-f(x)-f&#39;(x)[h]=o(||h||).
\]</span> <strong>Proposition</strong></p>
<p>Let <span class="math inline">\(C\)</span> be a nonempty closed convex set in <span class="math inline">\(\mathcal E\)</span>. For any <span class="math inline">\(x\)</span>, let <span class="math display">\[
\theta(x)=\frac{1}{2}||x-\Pi_C(x)||^2.
\]</span> The <span class="math inline">\(\theta(\cdot)\)</span> is a continuously differentiable convex function and <span class="math display">\[
\nabla \theta(x)=x-\Pi_C(x).
\]</span></p>
<h2 id="convex-separation">3.8 Convex Separation</h2>
<p>In this section, some propositions will be given without proof.</p>
<p><strong>Definition</strong></p>
<ol type="1">
<li><p>The <strong>affine hull</strong> <span class="math inline">\(\text{aff(S)}\)</span> of a set S in <span class="math inline">\(\mathcal E\)</span> is the smallest affine set containing <span class="math inline">\(S\)</span>, i.e. in intersection of all affine set containing <span class="math inline">\(S\)</span>. That can be shown by <span class="math display">\[
\text{aff(S)}=\left\{\sum_{i=1}^k\alpha_ix_i\;|\; \sum_{i=1}^k \alpha_i=1,x_i\in S,k&gt;0\right\}.
\]</span></p></li>
<li><p>The <strong>convex hull</strong> <span class="math inline">\(\text{conv(S)}\)</span> or <span class="math inline">\(\text{co(S)}\)</span> of a set <span class="math inline">\(S\)</span> in <span class="math inline">\(\mathcal E\)</span> is the smallest convex set containing <span class="math inline">\(S\)</span>, i.e. the intersection of all convex set containing <span class="math inline">\(S\)</span>, <span class="math display">\[
\text{conv(S)}=\left\{\sum_{i=1}^k\alpha_ix_i\;|\; \sum_{i=1}^k \alpha_i=1,x_i\in S,\alpha_i\ge 0,k&gt;0\right\}.
\]</span></p></li>
<li><p>A point <span class="math inline">\(x\)</span> is a <strong>relative interior point</strong> of <span class="math inline">\(S\)</span> if <span class="math inline">\(x\)</span> is an interior point relative to <span class="math inline">\(\text{aff(S)}\)</span>. The set of all relative interior points of <span class="math inline">\(S\)</span> is denoted as <span class="math inline">\(\text{relint(S)}\)</span> or <span class="math inline">\(\text{ri(S)}\)</span> <span class="math display">\[
\text{ri(S)}=\{x\in \text{aff(S)}\;|\; \exists \varepsilon &gt;0, B_{\varepsilon}(x)\cap \text{aff(S)}\subset S\}.
\]</span></p></li>
</ol>
<p><strong>Examples</strong></p>
<ol type="1">
<li>The affine hull of the singleton (a set made of one single element) is the singleton itself.</li>
<li>The affine hull of a set of two different points is the line through them.</li>
<li>The affine hull of a set of three points not on one line is the plane going through them.</li>
<li>The affine hull of a set of four points not in a plane in <span class="math inline">\(\mathbb R^3\)</span> is the entire space <span class="math inline">\(\mathbb R^3\)</span>.</li>
<li><span class="math inline">\(\text{aff}(\mathbb R_+^n)=\mathbb R^n\)</span>.</li>
</ol>
<p><strong>Proposition</strong> Let <span class="math inline">\(C\)</span> be a subset of a Euclidean space <span class="math inline">\(\mathcal E\)</span>. If <span class="math inline">\(C\)</span> is convex, then <span class="math inline">\(\text{aff(ri C)}=\text{aff(C)}=\text{aff(cl(C))}\)</span></p>
<p>In the next proposition we will prove that any point outside a closed convex set can be separated from that set with a hyperplane.</p>
<p><strong>Proposition</strong></p>
<p>Let <span class="math inline">\(\Omega \in \mathbb R^n\)</span> be a nonempty closed convex set and let <span class="math inline">\(\bar x\notin \Omega\)</span>. Then there exists a nonzero vector <span class="math inline">\(v\in \mathbb R^n\)</span> such that <span class="math display">\[
\sup\{\langle v,x\rangle \;|\;x\in \Omega\}&lt;\langle v,\bar x\rangle
\]</span> Proof.</p>
<p>Denote <span class="math inline">\(\bar w=\Pi_C(\bar x)\)</span>. let <span class="math inline">\(v=\bar x-\bar w\)</span>. For any <span class="math inline">\(x\in \Omega\)</span> we know that <span class="math display">\[
\langle v,x-\bar w\rangle=\langle \bar x-\bar w,x-\bar w\rangle\le 0\\
\langle v,x-\bar x+\bar x-\bar w\rangle\\
\langle v,x-\bar x+v\rangle=\\
\langle v,x\rangle-\langle v,\bar x\rangle+||v||^2\le 0
\]</span> Q.E.D.</p>
<p><strong>Proposition</strong></p>
<p>Let <span class="math inline">\(\Omega_1\)</span> and <span class="math inline">\(\Omega_2\)</span> be nonempty, closed, convex subsets of <span class="math inline">\(\mathbb R^n\)</span> with <span class="math inline">\(\Omega_1\cap \Omega_2=\emptyset\)</span>. If <span class="math inline">\(\Omega_1\)</span> or <span class="math inline">\(\Omega_2\)</span> is bounded, then there is a nonzero element <span class="math inline">\(v\in \mathbb R^n\)</span> such that <span class="math display">\[
\sup\{\langle v,x\rangle\;|\;x\in \Omega_1\}&lt;\inf\{\langle v,y\rangle\;|\;y\in \Omega_2\}.
\]</span> Proof.</p>
<p>Define <span class="math inline">\(\Omega=\Omega_1-\Omega_2\)</span>. Then <span class="math inline">\(\Omega\)</span> is nonempty closed convex set and <span class="math inline">\(0\notin \Omega\)</span>. Then we choose the point <span class="math inline">\(0\)</span> and use the previous proposition. Q.E.D.</p>
<p><strong>Proposition</strong> (Separation in a subspace)</p>
<p>Let <span class="math inline">\(L\)</span> be a subspace of <span class="math inline">\(\mathbb R^n\)</span> and let <span class="math inline">\(\Omega \subset L\)</span> be a nonempty convex set with <span class="math inline">\(\bar x\in L\)</span> and <span class="math inline">\(\bar x\notin \bar \Omega\)</span> (<span class="math inline">\(\bar \Omega\)</span> is the closure of <span class="math inline">\(\Omega\)</span>). Then there exists <span class="math inline">\(w\in L,w\neq 0\)</span> such that <span class="math display">\[
\sup\{\langle w,x\rangle\;|\; x\in \Omega\}&lt;\langle w,\bar x\rangle.
\]</span> <strong>Definition</strong></p>
<p>We say that two empty convex set <span class="math inline">\(\Omega_1\)</span> and <span class="math inline">\(\Omega_2\)</span> can be properly separated if there exists a nonzero vector <span class="math inline">\(v\in \mathbb R^n\)</span> such that <span class="math display">\[
\sup\{\langle v,x\rangle\;|\; x\in\Omega_1\}\le \inf\{\langle v,y\rangle\;|\; y\in\Omega_2\}\\
\inf\{\langle v,x\rangle\;|\; x\in\Omega_1\}&lt; \sup\{\langle v,y\rangle\;|\; y\in\Omega_2\}.
\]</span> <strong>Proposition</strong></p>
<p>The following assertions hold for affine.</p>
<ol type="1">
<li>A set <span class="math inline">\(\Omega\subset \mathbb R\)</span> is affine if and only if <span class="math inline">\(\Omega\)</span> contains all affine combinations of its elements.</li>
<li>If <span class="math inline">\(\Omega_1\)</span> is an affine subset of <span class="math inline">\(\mathbb R^n\)</span> and <span class="math inline">\(\Omega_2\)</span> is an affine subsets of <span class="math inline">\(\mathbb R^m\)</span>, then <span class="math inline">\(\Omega_1\times \Omega_2\)</span> is an affine subset of <span class="math inline">\(\mathbb R^n\times \mathbb R^m\)</span>.</li>
<li>Let <span class="math inline">\(B:\mathbb R^n\rightarrow \mathbb R^m\)</span> be an affine mapping if <span class="math inline">\(\Omega\)</span> is an affine subset of <span class="math inline">\(\mathbb R^n\)</span> and <span class="math inline">\(\Theta\)</span> is an affine subset of <span class="math inline">\(\mathbb R^m\)</span>. Then the image <span class="math inline">\(B(\Omega)\)</span> is an affine subset of <span class="math inline">\(\mathbb R^m\)</span> and the inverse image <span class="math inline">\(B^{-1}(\Theta)\)</span> is an affine subset of <span class="math inline">\(\mathbb R^n\)</span>.</li>
<li>Let <span class="math inline">\(\Omega,\Omega_1,\Omega_2\)</span> are affine subsets of <span class="math inline">\(\mathbb R^n\)</span>. Then the sum <span class="math inline">\(\Omega_1+\Omega_2\)</span> and the scalar product <span class="math inline">\(\lambda \Omega\)</span> for any <span class="math inline">\(\lambda \in \mathbb R\)</span> are also affine subsets of <span class="math inline">\(\mathbb R^n\)</span>.</li>
<li>Given <span class="math inline">\(\Omega\subset \mathbb R^n\)</span>, its affine hull is the smallest affine set containing <span class="math inline">\(\Omega\)</span>.</li>
<li>A set <span class="math inline">\(\Omega\)</span> is a linear subspace of <span class="math inline">\(\mathbb R^n\)</span> if and only if <span class="math inline">\(\Omega\)</span> is an affine set containing the origin.</li>
</ol>
<p><strong>Definition</strong> (Affine independence)</p>
<p>The elements <span class="math inline">\(v_0,\dotsm,v_m\)</span> in <span class="math inline">\(\mathbb R^m\)</span>, <span class="math inline">\(m\ge 1\)</span> are affinely independent if <span class="math display">\[
\sum_{i=1}^m \lambda_i v_i=0,\quad \sum_{i=1}^m \lambda_i=0\implies \lambda_i=0\quad \forall i=0,\dotsm,m.
\]</span> Roughly speaking, affine independence is like linear independence but without the restriction that the subset of lower dimension the points lie in contains the origin. So three points in space are affinely independent if the smallest flat thing containing them is a plane. They're affinely dependent if they lie on a line (or are the same point).</p>
<p><strong>Definition</strong> (Simplex)</p>
<p>Let <span class="math inline">\(v_0,\dotsm,v_m\)</span> be affinely independent in <span class="math inline">\(\mathbb R^n\)</span>. Then the set <span class="math display">\[
\Delta_m:\text{conv}\{v_i\;|\; i=0,\dotsm,m\}
\]</span> is called an m-simplex in <span class="math inline">\(\mathbb R^n\)</span> with the vertices <span class="math inline">\(v_0,\dotsm,v_m\)</span>.</p>
<p><strong>Lemma</strong></p>
<p>Let <span class="math inline">\(\Omega\)</span> be a nonempty, convex set in <span class="math inline">\(\mathbb R^n\)</span> of dimension <span class="math inline">\(m\ge 1\)</span>. Then there exists <span class="math inline">\(m+1\)</span> affinely independent elements <span class="math inline">\(v_0,\dotsm,v_m\)</span> in <span class="math inline">\(\Omega\)</span>.</p>
<p><strong>Theorem</strong></p>
<p>Let <span class="math inline">\(\Omega \subset \mathbb R^n\)</span> be a nonempty, convex set. The following assertions hold</p>
<ol type="1">
<li>We always have <span class="math inline">\(\text{ri } (\Omega)\neq \emptyset\)</span></li>
<li>We have <span class="math inline">\([a,b)\subset \text{ri }(\Omega)\)</span> for any <span class="math inline">\(a\in \text{ri }(\Omega)\)</span> and <span class="math inline">\(b\in\bar \Omega\)</span>.</li>
</ol>
<p><strong>Theorem</strong></p>
<p>Let <span class="math inline">\(\Omega_1, \Omega_2\)</span> be nonempty convex subsets of <span class="math inline">\(\mathbb R^n\)</span>. Then we have <span class="math display">\[
\text{ri }(\Omega_1-\Omega_2)=\text{ri }(\Omega_1)-\text{ri }(\Omega_2).
\]</span> <strong>Lemma</strong></p>
<p>Let <span class="math inline">\(\Omega\)</span> be a nonempty convex subset of <span class="math inline">\(\mathbb R^n\)</span>. Suppose that <span class="math inline">\(0\in \bar \Omega\backslash \text{ri }(\Omega)\)</span>. Then <span class="math inline">\(\text{aff }(\Omega)\)</span> is a subspace of <span class="math inline">\(\mathbb R^n\)</span>.</p>
<p><strong>Lemma</strong></p>
<p>A nonempty subset <span class="math inline">\(\Omega\)</span> of <span class="math inline">\(\mathbb R^n\)</span> is affine if and only if <span class="math inline">\(\Omega-\omega\)</span> is a subspace of <span class="math inline">\(\mathbb R^n\)</span> for any <span class="math inline">\(\omega\in \Omega\)</span>.</p>
<p><strong>Proposition</strong></p>
<p>Let <span class="math inline">\(\Omega\)</span> be a nonempty convex set. Suppose that <span class="math inline">\(\bar x\in \text{ri }(\Omega)\)</span> and <span class="math inline">\(\bar y\in \Omega\)</span>. Then there exists <span class="math inline">\(t&gt;0\)</span> such that <span class="math display">\[
\bar x+t(\bar x-\bar y)\in \Omega.
\]</span> <strong>Proposition</strong></p>
<p>Let <span class="math inline">\(\Omega\)</span> be a nonempty convex set in <span class="math inline">\(\mathbb R^n\)</span>. Then <span class="math inline">\(0\notin \text{ri }(\Omega)\)</span> if and only if the sets <span class="math inline">\(\Omega\)</span> and <span class="math inline">\(\{0\}\)</span> can be properly separated, i.e. there exists <span class="math inline">\(v\in \mathbb R^n\)</span> such that <span class="math display">\[
\sup\{\langle v,x\rangle\;|\;x\in \Omega\}\le 0\\
\inf\{\langle v,x\rangle\;|\;x\in \Omega\}&lt;0.
\]</span> <strong>Theorem</strong></p>
<p>Let <span class="math inline">\(\Omega_1\)</span> and <span class="math inline">\(\Omega_2\)</span> be two nonempty convex subsets of <span class="math inline">\(\mathbb R^n\)</span>. Then <span class="math inline">\(\Omega_1\)</span> and <span class="math inline">\(\Omega_2\)</span> can be properly separated if and only if <span class="math inline">\(\text{ri }(\Omega_1)\cap \text{ri }(\Omega_2)=\emptyset\)</span>.</p>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
        <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block home">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/09/21/Introduction to Hilbert Spaces with Applications/Hilbert Space/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Cheng-Zilong">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Cheng-Zilong">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
            
            <a href="/2019/09/21/Introduction to Hilbert Spaces with Applications/Hilbert Space/" class="post-title-link" itemprop="url">Chapter 5. Summary</a>
          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              
                
              

              <time title="Created: 2019-09-21 13:48:00 / Modified: 15:01:13" itemprop="dateCreated datePublished" datetime="2019-09-21T13:48:00+08:00">2019-09-21</time>
            </span>
          
            

            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Introduction-to-Hilbert-Spaces-with-Applications/" itemprop="url" rel="index"><span itemprop="name">Introduction to Hilbert Spaces with Applications</span></a></span>

                
                
              
            </span>
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h1 id="normed-vector-spaces">Normed Vector Spaces</h1>
<h2 id="introduction">1.1 Introduction</h2>
<p>The basic algebraic concepts in the theory of Hilbert spaces are those of a vector space and an inner product. The inner product defines a norm, and therefore, every Hilbert space is a norm space.</p>
<h2 id="vector-spaces">1.2 Vector spaces</h2>
<p>We will consider real vector spaces and complex vector spaces. The field of real number will be denoted by <span class="math inline">\(\mathbb R\)</span> and the filed of complex number will be denoted as <span class="math inline">\(\mathbb C\)</span>. We will use <span class="math inline">\(\mathbb F\)</span> to denote either <span class="math inline">\(\mathbb R\)</span> or <span class="math inline">\(\mathbb C\)</span>.</p>
<p>==Definition 1.2.1== Vector Space</p>
<p>By a vector space, we mean a nonempty set E with two operations</p>
<p>a mapping <span class="math inline">\((x,y)\mapsto x+y\)</span> from <span class="math inline">\(E\times E\)</span> into <span class="math inline">\(E\)</span> is called addition</p>
<p>a mapping <span class="math inline">\((\lambda,x)\mapsto \lambda x\)</span> from <span class="math inline">\(F\times E\)</span> into <span class="math inline">\(E\)</span> is called multiplication by scalars.</p>
<p>==Example 1.2.2== Function Spaces</p>
<p>Let <span class="math inline">\(X\)</span> be an arbitrary non-empty set and let <span class="math inline">\(E\)</span> be a vector space. Denote by <span class="math inline">\(F\)</span> the space of all functions from <span class="math inline">\(X\)</span> into <span class="math inline">\(E\)</span>. Then <span class="math inline">\(F\)</span> becomes a vector space if addition and multiplication by scalars are defined. The zero vector in <span class="math inline">\(F\)</span> is the function which assigns the zeros vector of <span class="math inline">\(E\)</span> to every element of <span class="math inline">\(X\)</span>. <span class="math display">\[
(f+g)(x)=f(x)+g(x)\\
(\lambda f)(x)=\lambda f(x)
\]</span> A subset <span class="math inline">\(E_1\)</span> of a vector space <span class="math inline">\(E\)</span> is called a ==vector subspace== if for every <span class="math inline">\(\alpha,\beta \in \mathbb F\)</span> and <span class="math inline">\(x,y\in E_1\)</span>, the vector <span class="math inline">\(\alpha x+\beta y\in E_1\)</span>.</p>
<p><span class="math inline">\(E_1\)</span> is a ==proper subspace== of <span class="math inline">\(E\)</span> if <span class="math inline">\(E_1\)</span> is a subspace of <span class="math inline">\(E\)</span> and <span class="math inline">\(E_1\neq E\)</span>.</p>
<p>==Example 1.2.3==</p>
Let <span class="math inline">\(\Omega\)</span> be an open subset of <span class="math inline">\(\mathbb R^N\)</span>. The following are subspaces of the space of all functions from <span class="math inline">\(\Omega\)</span> to C. $$
<span class="math display">\[\begin{array}{rcl}
\mathscr C(\Omega)&amp;=&amp;\text{The space of all continuous complex-valued functions defined on }\Omega\\

\mathscr C^k(\Omega)&amp;=&amp;\text{The space of all complex-valued functions defined on }\Omega \\
&amp;&amp;\text{ with continuous partial derivatives of order k}\\

\mathscr C^\infty(\Omega)&amp;=&amp;\text{The space of all complex-valued 
}\\
&amp;&amp;\text{functions defined on }\Omega \text{ with continuous partial derivatives of order infty}\\

\mathscr P(\Omega)&amp;=&amp;\text{The space of all polynomials of $N$ variables}
\end{array}\]</span>
<p>$$ ==Example1.2.4== Sequence spaces</p>
<p>If the set X in function spaces is the set <span class="math inline">\(\mathbb N\)</span> of all positive integers. Then the corresponding function space is actually a space of sequences. <span class="math display">\[
(x_1,x_2,\dotsm)+(y_1,y_2,\dotsm)=(x_1+y_1,x_2+y_2,\dotsm)\\
\lambda(x_1,x_2,\dotsm)=(\lambda x_1,\lambda x_2,\dotsm)
\]</span> ==Example 1.2.5== <span class="math inline">\(l^p\)</span>-Spaces</p>
<p>Denote by <span class="math inline">\(l^p\)</span>, for <span class="math inline">\(p\ge 1\)</span>, the space of all infinite sequences <span class="math inline">\((z_n)\)</span> of complex numbers such that <span class="math inline">\(\sum_{n=1}^\infty |z_n|^p&lt;\infty\)</span></p>
<p>We are going to show that <span class="math inline">\(l^p\)</span> is a vector space.</p>
<p>if <span class="math inline">\((x_n),(y_n)\in l^p\)</span> and <span class="math inline">\(\lambda \in C\)</span>. <span class="math display">\[
\sum_{n=1}^\infty|x_n+y_n|^p&lt;\infty
\]</span> from Minkowski's inequality <span class="math inline">\((\sum_{n=1}^\infty |x_n+y_n|^p)^{1/p} \le (\sum_{n=1}^\infty |x_n|^p)^{1/p}+(\sum_{n=1}^\infty |y_n|^p)^{1/p}\)</span></p>
<p>And <span class="math display">\[
\sum_{n=1}^\infty |\lambda x_n|^p=|\lambda|^p \sum_{n=1}^\infty |x_n|^p&lt;\infty
\]</span> Cartesian Product of Vector Spaces</p>
<p>Let <span class="math inline">\(E_1,\dotsm,E_n\)</span> be vector spaces over the same scalar field <span class="math inline">\(F\)</span>. <span class="math display">\[
E=\{(x_1,\dotsm,x_n):x_1\in E_1,x_2\in E_2,\dotsm,x_n\in E_n\}=E_1\times\dotsm\times E_n
\]</span></p>
<h2 id="linear-independence-basis-dimension">1.3 Linear Independence, Basis, Dimension</h2>
<p>==Definition 1.3.1== Linear combination</p>
<p>Let <span class="math inline">\(x_1,\dotsm,x_k\)</span> be elements of a vector space E. A vector <span class="math inline">\(x\in E\)</span> is called a linear combination of vectors if there exists scalars <span class="math inline">\(\alpha_1,\dotsm,\alpha_k\)</span> such that <span class="math display">\[
x=\alpha_1x_1+\dotsm+\alpha_kx_k
\]</span> ==Definition 1.3.2== Linear independence</p>
<p>A finite collection of vectors is called linearly independent if <span class="math inline">\(\alpha_1x_1+\dotsm+\alpha_kx_k=0\)</span> implies <span class="math inline">\(\alpha_1,\alpha_2,\dotsm, \alpha_k=0\)</span></p>
<p>==Definition1.3.3== Basis</p>
<p>A set of vectors <span class="math inline">\(\mathscr B\subset E\)</span> is called a basis of E if <span class="math inline">\(\mathscr B\)</span> is linearly independent and <span class="math inline">\(span \space \mathscr B=E\)</span></p>
<p>If there exists a finite basis in E, then E is called finite dimensional vector space.</p>
<p>E has a basis that consists exactly n vectors, then any other basis has exactly n vectors. In such a case n is called the dimension of E. <span class="math inline">\(\text{dim }E=n\)</span>. Spaces <span class="math inline">\(\mathscr C(\Omega), \mathscr C^k(\mathbb R^N), \mathscr C^\infty (\mathbb R^N)\)</span> are infinite dimensional.</p>
<h2 id="normed-spaces">1.4 Normed Spaces</h2>
<p>In general, it does not make sense to ask what is the length or magnitude of a vector in a vector space. The concept of a norm is an abstract generalization of the length of a vector.</p>
<p>==Definition 1.4.1== Norm</p>
<p>A function <span class="math inline">\(x\mapsto ||x||\)</span> from a vector space <span class="math inline">\(E\)</span> into <span class="math inline">\(R\)</span> is called a norm if it satisfies the following conditions</p>
<ol type="a">
<li><p><span class="math inline">\(||x||=0\)</span> if and only if <span class="math inline">\(x=0\)</span></p></li>
<li><p><span class="math inline">\(||\lambda x||=|\lambda|\space ||x||\)</span> for every <span class="math inline">\(x\in E\)</span> and <span class="math inline">\(\lambda \in F\)</span></p></li>
<li><p><span class="math inline">\(||x+y||\le ||x||+||y||\)</span> for every <span class="math inline">\(x,y \in E\)</span></p></li>
</ol>
<p>For nonnegativity, <span class="math inline">\(0=||0||=||x-x||\le ||x||+||-x||=2||x||\)</span></p>
<p>Example</p>
<ol type="1">
<li><p>The function defined by <span class="math inline">\(||x||=\sqrt{x_1^2+\dotsm+x_N^2}\)</span> is a norm in <span class="math inline">\(R^N\)</span>. This norm is often called the Euclidean norm</p>
<p>The following are also norms <span class="math display">\[
||x||=|x_1|+\dotsm+|x_N|\\
||x||=\max\{|x_1|,\dotsm,|x_N|\}
\]</span></p></li>
<li><p>The formula <span class="math inline">\(||z||=\sqrt{|z_1|^2+\dotsm+|z_n|^2}\)</span> defines a norm in <span class="math inline">\(C^N\)</span></p></li>
<li><p>Let <span class="math inline">\(\Omega\)</span> be a closed bounded subset of <span class="math inline">\(R^n\)</span>. The function $||f||=_{x}|f(x)| $ defines a norm in <span class="math inline">\(\mathscr C(\Omega)\)</span></p></li>
<li><p>Let <span class="math inline">\(z=(z_n)\in l^p\)</span>. The function defined by <span class="math inline">\(||z||=(\sum_{n=1}^\infty|z_n|^p)^{1/p}\)</span> is a norm in <span class="math inline">\(l^p\)</span></p></li>
</ol>
<p>==Definition 1.4.2== Normed Space</p>
<p>A vector space with a norm is called a normed space.</p>
<p>It is possible to define different norms on the same vector space. Therefore, to define a normed space, we need to specify both the vector space and the norm.</p>
<p>==Definition 1.4.3== Convergence in a normed space</p>
<p>Let <span class="math inline">\((E,||\cdot||)\)</span> be a normed space. We say that a sequence <span class="math inline">\((x_n)\)</span> of elements of E converges to some <span class="math inline">\(x\in E\)</span> if for every <span class="math inline">\(\varepsilon &gt;0\)</span>, there exists a number M such that for every <span class="math inline">\(n\ge M\)</span> we have <span class="math inline">\(||x_n-x||&lt;\varepsilon\)</span>. In such case, we write <span class="math inline">\(\lim_{n\rightarrow \infty} x_n=x\)</span> or <span class="math inline">\(x_n\rightarrow x\)</span>.</p>
<p>If we have a normed space <span class="math inline">\(E\)</span>, then we automatically have a convergence defined in <span class="math inline">\(E\)</span>. However, not every convergence definition can be defined with norm (pointwise convergence).</p>
<p>Here are some examples.</p>
<p>==Example 1.4.2== Uniform Convergence</p>
<p>Consider the space <span class="math inline">\(\mathscr C(\Omega)\)</span> of all continuous functions defined on a closed bounded set <span class="math inline">\(\Omega \subset R^n\)</span>. Let <span class="math inline">\(f,f_1,f_2,\dotsm\in \mathscr C(\Omega)\)</span></p>
<p>We say that the sequence <span class="math inline">\((f_n)\)</span> converges uniformly to <span class="math inline">\(f\)</span> if for every <span class="math inline">\(\epsilon&gt;0\)</span> there exists a constant M such that for all <span class="math inline">\(x\in \Omega\)</span> and for all indices <span class="math inline">\(n\ge M\)</span> we have <span class="math inline">\(||f(x)-f_n(x)||&lt;\epsilon\)</span>. For the norm defined in the above example, we have <span class="math display">\[
f_1,f_2,\dotsm\text{ converges uniformly to $f$ if and ony if }\max_{x\in\Omega}|f_n(x)-f(x)|\rightarrow 0
\]</span> ==Definition 1.4.4== Equivalence of Norms</p>
<p>Two norms defined on the same vector space is called equivalent if they define the same convergence. More precisely, norms <span class="math inline">\(||\cdot||_1\)</span> and <span class="math inline">\(||\cdot||_2\)</span> in E are equivalent if for any sequence <span class="math inline">\((x_n)\)</span> in E and <span class="math inline">\(x\in E\)</span> <span class="math display">\[
||x_n-x||_1\rightarrow 0\text{ if and only if }||x_n-x||_2\rightarrow0
\]</span> Example</p>
<p>The norms <span class="math display">\[
||(x,y)||_1=\sqrt{x^2+y^2}\\
||(x,y)||_2=|x|+|y|\\
||(x,y)||_3=\max\{|x|,|y|\}
\]</span> are equivalent in <span class="math inline">\(R^2\)</span>.</p>
<p>It can be proved any two norms in a finite dimensional vector space are equivalent.</p>
<p>The following theorem gives another useful criterion for equivalence of norms and often used as a definition of equivalence of norms.</p>
<p>==Theorem 1.4.1== Let <span class="math inline">\(||\cdot||_1\)</span> and <span class="math inline">\(||\cdot||_2\)</span> be norms in a vector space E. Then <span class="math inline">\(||\cdot||_1\)</span> and <span class="math inline">\(||\cdot||_2\)</span> are equivalent if and only if there exists positive numbers <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> such that <span class="math display">\[
\alpha||x||_1\le ||x||_2\le \beta||x||_1 \quad \forall x\in E
\]</span> Proof.</p>
<p><span class="math inline">\(\Longleftarrow\)</span> <span class="math display">\[
\alpha||x_n-x||_1\le ||x_n-x||_2\le \beta||x_n-x||_1
\]</span> Then if $||x_n-x||_1 $ , then <span class="math inline">\(||x_n-x||_2\rightarrow 0\)</span>. If <span class="math inline">\(||x_n-x||_2\rightarrow 0\)</span>, then <span class="math inline">\(||x_n-x||_1\rightarrow 0\)</span></p>
<p><span class="math inline">\(\Longrightarrow\)</span></p>
<p>If now we have <span class="math inline">\(||x_n-x||_1\rightarrow 0\text{ if and only if }||x_n-x||_2\rightarrow0\)</span></p>
<p>Suppose there is no $&gt;0 $ such that <span class="math inline">\(\forall x\in E,\alpha||x||_1\le ||x||_2\)</span></p>
<p>That means <span class="math inline">\(\forall \alpha &gt; 0\)</span> such that <span class="math inline">\(\exists x\in E\)</span>, <span class="math inline">\(\alpha||x||_1 &gt;||x||_2\)</span></p>
<p>For every <span class="math inline">\(n\in \mathbb N\)</span> there exists <span class="math inline">\(x_n \in E\)</span> such that <span class="math display">\[
\frac{1}{n}||x_n||_1&gt;||x_n||_2
\]</span> We define <span class="math display">\[
y_n=\frac{1}{\sqrt n}\frac{x_n}{||x_n||_2} \in E
\]</span> Then we have <span class="math display">\[
||y_n||_1=\frac{1}{\sqrt n}\frac{||x_n||_1}{||x_n||_2}\\
||y_n||_2=\frac{1}{\sqrt n}\\
||y_n||_1\ge n||y_n||_2=\sqrt n\\
\]</span> Then we find that <span class="math inline">\(||y_n||_2\rightarrow 0\)</span> but <span class="math inline">\(||y_n||_1\)</span> does not converge, that contradiction show that number with required property exists.</p>
<p>In the metric space, the metric is defined by <span class="math inline">\(d(x,y)=||x-y||\)</span>. The metric in E defines a topology in E, i.e. open set and closed set and this all notions can be defined in terms of open set and closed sets. It is not necessary to define the topology using metric. Here we define the basic topological notions in terms of the norm.</p>
<p>==Definition 1.4.5== Open balls, closed balls, spheres</p>
<p>Let <span class="math inline">\(x\)</span> be an element of a normed space <span class="math inline">\(E\)</span> and let <span class="math inline">\(r\)</span> be a positive number. We use the following notion:</p>
<p><span class="math inline">\(B(x,r)=\{y\in E:||y-x||&lt;r\}\)</span> (open ball)</p>
<p><span class="math inline">\(\bar B(x,r)=\{y\in E:||y-x||\le r\}\)</span> (closed ball)</p>
<p><span class="math inline">\(S(x,r)=\{y\in E:||y-x||=r\}\)</span> (sphere)</p>
<p>==Definition 1.4.6== Open and closed sets</p>
<p>A subset S of a normed space E is called open if for every <span class="math inline">\(x\in S\)</span> there exists <span class="math inline">\(\varepsilon&gt;0\)</span> such that <span class="math inline">\(B(x,\varepsilon)\subseteq S\)</span>.</p>
<p>A subset is closed if its complement is open. In topology space, a closed set can be defined as a set which contains all its limit points.</p>
<p>==Theorem 1.4.2==</p>
<ol type="a">
<li><p>The union of any number of open sets is open</p></li>
<li><p>The intersection of finite number of open sets is open</p></li>
<li><p>The union of a finite number of closed sets is closed</p></li>
<li><p>The intersection of any number of closed sets is closed.</p></li>
<li><p>The empty set and the whole space are both open and closed.</p></li>
</ol>
<p>==Theorem 1.4.3==</p>
<p>A subset S of a normed space E is closed if and only if every sequence of elements of S convergent in E has its limit in S.</p>
<p><span class="math inline">\(\Longrightarrow\)</span></p>
<p>Assume a subset S of a normed space E is closed. <span class="math inline">\(\exists x_1,x_2,\dotsm \in S\)</span> and <span class="math inline">\(x\in E\backslash S\)</span>. <span class="math inline">\((x_n)\)</span> convergent to <span class="math inline">\(x\)</span> means that <span class="math inline">\(\forall \epsilon&gt;0\)</span>, there exists <span class="math inline">\(M\)</span> such that <span class="math inline">\(\forall m&gt;M\)</span>, <span class="math inline">\(||x_m-x||&lt;\epsilon\)</span> . We will show that is impossible.</p>
<p>S is closed therefore, <span class="math inline">\(E\backslash S\)</span> is open and <span class="math inline">\(x\in E\backslash S\)</span>. That means for every point including <span class="math inline">\(x\)</span>, there exists $_2 &gt;0 $ such that <span class="math inline">\(B(x,\epsilon_2) \subset E\backslash S\)</span>.</p>
<p>Since <span class="math inline">\((x_n)\)</span> convergent to <span class="math inline">\(x\)</span>, For every <span class="math inline">\(\epsilon_2 &gt;0\)</span>, there exist <span class="math inline">\(m&gt;M\)</span>, <span class="math inline">\(||x_m-x||&lt;\epsilon_2\)</span>, that means <span class="math inline">\(x_m\in B(x,\epsilon_2)\)</span> that contradicts <span class="math inline">\(B(x,\epsilon_2)\subset E\backslash S\)</span>.</p>
<p><span class="math inline">\(\Longleftarrow\)</span></p>
<p>Assume every sequence of elements of S convergent in E has its limit in S, then a subset S of a normed space E is closed, that means whenever <span class="math inline">\(x_1,x_2,\dotsm\in S\)</span>, $x_nx $ and <span class="math inline">\(x\in S\)</span>, the subset S of a normed space E is closed.</p>
<p>If S is not closed, then <span class="math inline">\(E\backslash S\)</span> is not open.</p>
<p>A subset Eof a normed space E is not ==open== if there exists <span class="math inline">\(x\in E\backslash S\)</span>, for all <span class="math inline">\(\epsilon &gt;0\)</span>, such that <span class="math inline">\(B(x,\epsilon)\)</span> contains elements of S. Consequently, we can find a sequence <span class="math inline">\(x_1,x_2,\dotsm\in S\)</span> satisfying <span class="math inline">\(x_n \in B(x,\frac{1}{n})\)</span>. But then <span class="math inline">\(x_n\rightarrow x\)</span>. That contradicts every sequence of elements of S convergent in E has its limit in S.</p>
<p>==Definition 1.4.7== Closure</p>
<p>Let S be a subset of a normed space E. By the closure of S, denoted by cl S, we mean the intersection of all closed sets containing S.</p>
<p>The closure of a set is always a closed set. It is the smallest closed set which contains S.</p>
<p>==Theorem 1.4.4==</p>
<p>Let S be a subset of a normed space E. The closure of S is the set of limits of all convergent sequences of elements of S. <span class="math display">\[
\text{cl S}=\{x\in E:\text{there exist }x_1,x_2,\dotsm\in S\text{ such that }x_n\rightarrow x\}
\]</span> Lemma, if $x$ cl S, there exists <span class="math inline">\(\epsilon&gt;0\)</span> and <span class="math inline">\(B(x,\epsilon)\cap S=\empty\)</span>.</p>
<p>Since cl S is intersection of any closed sets, therefore cl S is closed. Then <span class="math inline">\(E\backslash clS\)</span> is open set. For all <span class="math inline">\(x\in E\backslash clS\)</span>, there exists <span class="math inline">\(\epsilon &gt;0\)</span> such that $B(x,)ES $. Therefore, for all <span class="math inline">\(x\notin cl S\)</span>, there exists <span class="math inline">\(\epsilon &gt;0\)</span>, <span class="math inline">\(B(x,\epsilon)\cap S=\empty\)</span>.</p>
<p><span class="math inline">\(\Longleftarrow\)</span></p>
<p>For any convergent sequences <span class="math inline">\(x_1,x_2,\dotsm\in S\)</span> and <span class="math inline">\(x\in E\)</span>, we have <span class="math display">\[
\forall \epsilon &gt;0\quad \exist M\quad \forall m&gt;M\quad ||x_m-x||&lt;\epsilon
\]</span> therefore, for limits of all convergent sequences of elements of S, there is no arbitrarily small <span class="math inline">\(\epsilon\)</span> such that <span class="math inline">\(B(x,\epsilon)\cap S=\empty\)</span>, that means <span class="math inline">\(x\in\)</span> cl S.</p>
<p><span class="math inline">\(\implies\)</span></p>
<p>If <span class="math inline">\(x\in\)</span> cl S, then <span class="math inline">\(\forall \epsilon&gt;0 \quad B(x,\epsilon)\cap S\neq \empty\)</span></p>
<p>we can find a sequence <span class="math inline">\(x_1,x_2,\dotsm\in S\)</span> satisfying <span class="math inline">\(x_n \in B(x,\frac{1}{n})\)</span>. But then <span class="math inline">\(x_n\rightarrow x\)</span> that means every sequence of elements of S convergent in E has its limit in cl S.</p>
<p>The Weierstrass theorem says that every continuous function on an interval [a,b] can be approximated uniformly by polynomials. This can be expressed as follows: The closure of the set of all polynomials on [a,b] is the whole space <span class="math inline">\(\mathscr C([a,b])\)</span>.</p>
<p>==Definition 1.4.8== Dense subsets</p>
<p>A subset S of a normed space E is called dense in E if cl S=E.</p>
<p>The set of all polynomials on [a,b] is dense in <span class="math inline">\(\mathscr C([a,b])\)</span></p>
<p>==Theorem 1.4.5==</p>
<p>Let S be a subset of a normed space E. The following conditions are equivalent.</p>
<ol type="a">
<li><p>S is dense in E</p></li>
<li><p>For every <span class="math inline">\(x\in E\)</span> there exists <span class="math inline">\(x_1,x_2,\dotsm \in S\)</span> such that <span class="math inline">\(x_n\rightarrow x\)</span></p></li>
<li><p>Every non-empty open subset of E contains elements of S.</p></li>
</ol>
<p>Proof.</p>
<ol type="a">
<li><p>— (b) Theorem 1.4.4</p></li>
<li><p>to (c)</p></li>
</ol>
<p>proof method 1.</p>
<p>cl S=E.</p>
<p>For all <span class="math inline">\(x\in E\)</span>, we have <span class="math inline">\(x\in\)</span> cl S. That means <span class="math inline">\(\forall \epsilon&gt;0 \quad B(x,\epsilon)\cap S\neq \empty\)</span></p>
<p>if there exists one non-empty open subsets O of E contains no element of S, we choose <span class="math inline">\(x&#39;\in O\)</span>, then <span class="math inline">\(\exist\epsilon&#39;&gt;0\)</span>, we have <span class="math display">\[
B(x&#39;,\epsilon&#39;)\subseteq O
\]</span> However, <span class="math inline">\(x&#39;\in E\)</span>, that contradicts <span class="math inline">\(\forall \epsilon&gt;0 \quad B(x&#39;,\epsilon)\cap S\neq \empty\)</span>.</p>
<p>Proof method 2</p>
<p>If there exists non-empty open subset O of E contains no element of S.</p>
<p>Then <span class="math inline">\(O \not \subset clS\)</span></p>
<p>However <span class="math inline">\(O\subset E\)</span></p>
<p>That means <span class="math inline">\(clS\neq E\)</span></p>
<ol start="3" type="a">
<li>to (a)</li>
</ol>
<p>Proof method 1,</p>
<p>Every non-empty open subset of E contains an element of S means S is dense in E.</p>
<p>If S is not dense in E, we have $xE$cl S, since cl S is closed set, <span class="math inline">\(E\backslash\)</span>cl S is an open set. There exists <span class="math inline">\(\epsilon\)</span> such that <span class="math inline">\(B(x,\epsilon)\subseteq E\backslash\)</span>cl S. Q.E.D.</p>
<p>==Definition 1.4.9== Compact sets</p>
<p>A subset S of a normed subspace E is called compact if every sequence <span class="math inline">\((x_n)\)</span> in S contains a convergent subsequence whose limit belongs to S.</p>
<p>For <span class="math inline">\(R^N\)</span> and <span class="math inline">\(C^N\)</span>, every bounded closed set is compact.</p>
<p>==Theorem 1.4.6==</p>
<p>Compact sets are closed and bounded.</p>
<p>==Definition 1.4.10== Bounded <span class="math inline">\(\exists x\in E\)</span> and <span class="math inline">\(\exists r&gt;0\)</span> such that <span class="math inline">\(\forall s\in S\)</span>, <span class="math inline">\(||s-x||&lt;r\)</span></p>
<p>A subset S of a normed subspace E is not closed, that means Eis not an open set.</p>
<p>That means <span class="math inline">\(\exists x\in E\backslash S\quad \forall \epsilon&gt;0 \quad B(x,\epsilon)\)</span> contains elements in S.</p>
<p>Then we can choose sequence in S, <span class="math inline">\(x_1,x_2,\dotsm \in S\)</span> satisfying <span class="math inline">\(x_n \in B(x,\frac{1}{n})\)</span>. <span class="math inline">\(x_n\rightarrow x\)</span>. That means this sequence belongs to S but does not have a convergent subsequence whose limit belongs to S (because the limit belongs to E).</p>
<p>Then we prove compact sets are bounded.</p>
<p>If <span class="math inline">\(S\subseteq E\)</span> is compact but not bounded, that means every sequence <span class="math inline">\((x_n)\)</span> in S contains a convergent subsequence whose limit belongs to S but <span class="math inline">\(\forall x\in E\)</span> and <span class="math inline">\(\forall r&gt;0\)</span> such that <span class="math inline">\(\exists s\in S\)</span>, <span class="math inline">\(||x-s||\ge r\)</span></p>
<p>From the definition of not bounded, we can construct a sequence (For all <span class="math inline">\(x\)</span>, we choose <span class="math inline">\(x=0\)</span>. For all <span class="math inline">\(r\)</span> we choose <span class="math inline">\(r=n\)</span>) <span class="math display">\[
||x_n||&gt;n
\]</span> Obviously these sequence does not have a convergent subsequence.</p>
<h2 id="banach-spaces">1.5 Banach Spaces</h2>
<p>Every Cauchy sequence of <strong>numbers</strong> converges. Every absolutely convergent series of <strong>number</strong> converges. Similar properties of a normed space would be of great importance. Not all normed spaces have the above properties. Those which do are called Banach Spaces.</p>
<p>==Definition 1.5.1== Cauchy Sequence</p>
<p>A sequence of vectors <span class="math inline">\((x_n)\)</span> in a normed space is called a Cauchy sequence if for every <span class="math inline">\(\varepsilon&gt;0\)</span> there exists a number M such that <span class="math inline">\(||x_m-x_n||&lt;\varepsilon\)</span> for all <span class="math inline">\(m,n&gt;M\)</span>.</p>
<p>==Theorem 1.5.1==</p>
<p>The following conditions are equivalent:</p>
<ol type="a">
<li><p><span class="math inline">\((x_n)\)</span> is a Cauchy sequence.</p></li>
<li><p><span class="math inline">\(||x_{p_n}-x_{q_n}||\rightarrow 0\)</span> as <span class="math inline">\(n\rightarrow \infty\)</span>, for every pair of increasing sequences of positive integers <span class="math inline">\((p_n)\)</span> and <span class="math inline">\((q_n)\)</span></p></li>
<li><p><span class="math inline">\(||x_{p_{n+1}}-x_{p_n}||\rightarrow 0\)</span> as <span class="math inline">\(n\rightarrow \infty\)</span> for every increasing sequence of positive integers <span class="math inline">\((p_n)\)</span></p></li>
</ol>
<p>Proof. clearly <span class="math inline">\((a)\rightarrow (b)\rightarrow (c)\)</span></p>
<p>we only need to prove <span class="math inline">\((c)\rightarrow (a)\)</span></p>
<p>If <span class="math inline">\((x_n)\)</span> is not a Cauchy sequence, then <span class="math inline">\(\exists \epsilon&gt;0,\forall M&gt;0,\exists m,n&gt;M\)</span> such that <span class="math inline">\(||x_m-x_n||\ge \epsilon\)</span>.</p>
<p>That means <span class="math inline">\(\exists \epsilon&gt;0\)</span>, there are infinitely many <span class="math inline">\(m,n\)</span> such that <span class="math inline">\(||x_m-x_n||\ge \epsilon\)</span></p>
<p>Then there exists increasing sequence of positive integers <span class="math inline">\((p_n)\)</span> such that <span class="math inline">\(||x_{p_{n+1}}-x_{p_n}||\not \rightarrow 0\)</span> as <span class="math inline">\(n\rightarrow \infty\)</span></p>
<p>We can easily find such sequence. Q.E.D.</p>
<p>Observe that every <strong>convergent sequence</strong> is a <strong>Cauchy sequence</strong>.</p>
<p>If we have <span class="math inline">\(||x_n-x||\rightarrow 0\)</span>, then <span class="math inline">\(||x_{p_n}-x_{q_n}||\le||x_{p_n}-x||+||x_{q_{n}}-x||\rightarrow 0\)</span></p>
<p>The converse is not true. A sequence of the rational number may converge to an irrational number.</p>
<p>==Lemma 1.5.1==</p>
<p>If <span class="math inline">\((x_n)\)</span> is a Cauchy sequence in a normed space, then the sequence of norms <span class="math inline">\((||x_n||)\)</span> converges.</p>
<p>Proof.</p>
<p><span class="math inline">\(x_1,x_2,\dotsm \in E\)</span> and for every <span class="math inline">\(\varepsilon&gt;0\)</span> there exists a number M such that <span class="math inline">\(||x_m-x_n||&lt;\varepsilon\)</span> for all <span class="math inline">\(m,n&gt;M\)</span>. <span class="math display">\[
|\space||x_m||-||x_n||\space|\le||x_m-x_n||\rightarrow 0
\]</span> ==Definition 1.5.2== Banach Space</p>
<p>A normed space E is called complete if every Cauchy sequence in E converges to an element of E. A complete normed space is called a Banach Space.</p>
<p>==Example 1.5.1== The space <span class="math inline">\(l^2\)</span> is complete.</p>
<p>To prove the completeness, we need to prove for any Cauchy sequence <span class="math inline">\(z_1,z_2,\dotsm \in E\)</span> satisfying that</p>
<p><span class="math inline">\(\forall \epsilon &gt;0\)</span>, there exists a number <span class="math inline">\(n_0\)</span> such that for all <span class="math inline">\(m,n\ge n_0\)</span> <span class="math display">\[
||z_m-z_n||^2=\sum_{k=1}^\infty |z_{m,k}-z_{n,k}|^2&lt;\epsilon^2
\]</span> that implies <span class="math inline">\(\forall k\in \mathbb N,\forall\epsilon&gt;0,\exists n_0&gt;0\)</span> <span class="math display">\[
|z_{m,k}-z_{n,k}|&lt;\epsilon\quad \forall m,n&gt;n_0
\]</span> that mean for every k, the sequence <span class="math inline">\((z_{n,k})\)</span> is Cauchy sequence and convergent. Then we denote <span class="math display">\[
z_k=\lim_{n\rightarrow \infty} z_{n,k}\quad k=1,2,\dotsm\quad z=(z_k)
\]</span> We need to prove that there exists an element <span class="math inline">\(z\in E\)</span> such that <span class="math inline">\(\forall \varepsilon&gt;0,\exists M&gt;0,\forall m&gt;M\)</span> such that <span class="math display">\[
||z_m-z||=\sum_{k=1}^\infty |z_{m,k}-z_k|^2&lt;\varepsilon^2
\]</span> By letting $n$, we can prove the second equation by the first equation.</p>
<p>Then we need to prove that <span class="math inline">\(z\in E\)</span> <span class="math display">\[
\sqrt{\sum_{k=1}^\infty|z_k|^2}=\sqrt{\sum_{k=1}^\infty|z_{k}-z_{m,k}+z_{m,k}|^2}\\
\le \sqrt{\sum_{k=1}^\infty|z_{k}-z_{m,k}|^2}+\sqrt{\sum_{k=1}^\infty |z_{m,k}|^2}
&lt; \infty
\]</span> That means <span class="math inline">\(z_m \rightarrow z\)</span></p>
<p>Q.E.D.</p>
<p>==Example 1.5.2== Another important example of a Banach space is the space <span class="math inline">\(\mathscr C([a,b])\)</span> of continuous functions on an interval [a,b].</p>
<p>To prove the completeness, we need to prove for any Cauchy sequence <span class="math inline">\(f_1,f_2,\dotsm \in E\)</span> satisfying that</p>
<p><span class="math inline">\(\forall \epsilon &gt;0\)</span>, there exists a number <span class="math inline">\(n_0\)</span> such that for all <span class="math inline">\(m,n\ge n_0\)</span> <span class="math display">\[
||f_m-f_n||&lt;\epsilon\\
\max_{x\in[a,b]} |f_m(x)-f_n(x)|&lt;\epsilon
\]</span> that implies <span class="math display">\[
|f_m(x)-f_n(x)|&lt;\epsilon \quad \forall n,m\ge n_0,\forall x\in[a,b]
\]</span> that means <span class="math inline">\((f_n(x))\)</span> is Cauchy sequence <span class="math inline">\(\forall x\in[a,b]\)</span>.</p>
<p>We denote <span class="math display">\[
f(x)=\lim_{n\rightarrow \infty } f_n(x),\forall x\in[a,b]
\]</span> Let $n$ , we have <span class="math display">\[
|f_m(x)-f(x)|&lt;\epsilon,\forall m\ge n_0 ,\forall x\in[a,b]\\
\max_{x\in[a,b]}|f_m(x)-f(x)|&lt;\epsilon \\
||f_m-f|&lt;\epsilon
\]</span> Then we prove <span class="math inline">\(f\in E\)</span></p>
<p>Let <span class="math inline">\(\forall x_0\in[a,b]\)</span>. Since <span class="math inline">\(f_{n_0}\)</span> is continuous on <span class="math inline">\([a,b]\)</span>, there exists <span class="math inline">\(\delta &gt;0\)</span> such that <span class="math inline">\(|f_{n_0}(x_0)-f_{n_0}(y)|&lt;\epsilon\)</span> for every <span class="math inline">\(y\in[a,b]\)</span> and <span class="math inline">\(|x_0-y|&lt;\delta\)</span> <span class="math display">\[
|f(x_0)-f(y)|= |f(x_0)-f_{n_0}(x_0)+f_{n_0}(x_0)-f_{n_0}(y)+f_{n_0}(y)-f(y)|\\
\le |f(x_0)-f_{n_0}(x_0)|+|f_{n_0}(x_0)-f_{n_0}(y)|+|f_{n_0}(y)-f(y)|\\
&lt; 3\epsilon
\]</span> whenever <span class="math inline">\(|x_0-y|&lt;\delta\)</span>, that means <span class="math inline">\(f\)</span> is continuous.</p>
<p>Q.E.D.</p>
<p>==Definition 1.5.3== Convergent and Absolutely convergent series</p>
<p>A series <span class="math inline">\(\sum_{n=1}^\infty x_n\)</span> converges in a normed space E if the sequence of partial sums converges in E.</p>
<p>i.e. there exists <span class="math inline">\(x\in E\)</span> such that <span class="math inline">\(||x_1+x_2+\dotsm+x_n-x||\rightarrow 0\)</span> as $n$ .</p>
<p>In that case, we write <span class="math inline">\(\sum_{n=1}^\infty x_n=x\)</span>. If <span class="math inline">\(\sum_{n=1}^\infty ||x_n||&lt;\infty\)</span>, then the series is called absolute convergent.</p>
<p>Theorem 1.5.2</p>
<p>A normed space is complete if and only if every absolutely convergent series converges.</p>
<p><span class="math inline">\(\implies\)</span></p>
<p>We will prove this by proving absolutely convergent series is a Cauchy series.</p>
<p>We define a absolutely convergent series. Suppose <span class="math inline">\(x_n\in E\)</span> and <span class="math inline">\(\sum_{n=1}^\infty||x_n||&lt;\infty\)</span> and denote <span class="math display">\[
s_n=\sum_{k=1}^nx_k
\]</span> Because the sequence of partial sums converges in E, for every $&gt;0 $, there exists <span class="math inline">\(k&gt;0\)</span> such that <span class="math display">\[
\sum_{n=k+1}^\infty ||x_n||&lt;\epsilon
\]</span> To show <span class="math inline">\((s_n)\)</span> is a Cauchy sequence, <span class="math inline">\(\forall \epsilon&gt;0,\exists M,\forall m,n&gt;M\)</span> such that <span class="math display">\[
||s_m-s_n||=||x_{n+1}+x_{n+2}+\dotsm+x_m||\le \sum_{r=n+1}^\infty ||x_r||&lt;\epsilon
\]</span> (without loss of generality, we assume <span class="math inline">\(m&gt;n\)</span>)</p>
<p>Since E is complete, <span class="math inline">\(s_n\)</span> converges.</p>
<p><span class="math inline">\(\Longleftarrow\)</span></p>
<p>We need to prove if every absolutely convergent series in a norm space converges, then the normed space is complete.</p>
<p>Let <span class="math inline">\((x_n)\)</span> be an Cauchy sequence in E and therefore <span class="math inline">\(\forall \epsilon&gt;0,\exists p_k\in N,\forall m,n&gt;p_k\)</span> such that <span class="math display">\[
||x_m-x_n||&lt;2^{-k}
\]</span> without loss of generality, we can assume <span class="math inline">\((p_k)\)</span> is strictly increasing.</p>
<p>Then the series <span class="math inline">\(\sum_{k=1}^\infty (x_{p_{k+1}}-x_{p_k})\)</span> is absolutely convergent and therefore, convergent and therefore, the sequence <span class="math display">\[
x_{p_k}=x_{p_1}+(x_{p_2}-x_{p_1})+(x_{p_3}-x_{p_2})+\dotsm+(x_{p_k}-x_{p_{k-1}})
\]</span> converges to an element <span class="math inline">\(x\in E\)</span></p>
<p>Then <span class="math display">\[
||x_n-x||\le ||x_n-x_{p_n}||+||x_{p_n}-x||\rightarrow 0
\]</span> Q.E.D.</p>
<p>Theorem 1.5.3</p>
<p>A closed vector subspace of a Banach space is a Banach space itself.</p>
<h2 id="linear-mappings">1.6 Linear Mappings</h2>
<p>Let <span class="math inline">\(E_1\)</span> and <span class="math inline">\(E_2\)</span> be vector spaces, and let L be a mapping from <span class="math inline">\(E_1\)</span> into <span class="math inline">\(E_2\)</span></p>
<p>If <span class="math inline">\(y=L(x)\)</span>, then y is called the ==image== of x. If A is subset of <span class="math inline">\(E_1\)</span>, then <span class="math inline">\(L(A)\)</span> denotes the image of the set <span class="math inline">\(A\)</span>.</p>
<p>If B is a subset of <span class="math inline">\(E_2\)</span>, then <span class="math inline">\(L^{-1}(B)\)</span> denote the ==inverse image== of B. i.e. <span class="math inline">\(L^{-1}(B)\)</span> is the set of all vectors in <span class="math inline">\(E_1\)</span> whose images are elements of B.</p>
<p>We consider the mapping which are defined on a proper subset of a vector space. Then the ==domain== of <span class="math inline">\(L\)</span> will be denoted as <span class="math inline">\(\mathscr D(L)\)</span>. The set <span class="math inline">\(L(\mathscr D(L))\)</span> is called the ==range== of the L and denoted by <span class="math inline">\(\mathscr R (L)\)</span></p>
<p>By the ==null space== of L, denoted by <span class="math inline">\(\mathscr N(L)\)</span>, we mean the set of all vectors <span class="math inline">\(x\in \mathscr D(L)\)</span> such that <span class="math inline">\(L(x)=0\)</span></p>
<p>By the ==graph== if L, denoted by <span class="math inline">\(\mathscr G(L)\)</span>, we mean the subset of <span class="math inline">\(E_1\times E_2\)</span> defined as follows: <span class="math display">\[
\mathscr G(L)=\{(x,y):x\in\mathscr D(L),y=L(x)\}
\]</span> ==Definition 1.6.1== Linear Mappings</p>
<p>A mapping <span class="math inline">\(L:E_1\rightarrow E_2\)</span> is called a linear mapping if <span class="math display">\[
L(\alpha x+\beta y)=\alpha L(x)+\beta L(y)
\]</span> for all <span class="math inline">\(x,y\in E_1\)</span> and all scalar <span class="math inline">\(\alpha,\beta\)</span></p>
<p>In the remaining part of this section, we will assume that both spaces <span class="math inline">\(E_1\)</span> and <span class="math inline">\(E_2\)</span> are normed spaces.</p>
<p>==Definition 1.6.2== Continuous Mappings</p>
<p>Let <span class="math inline">\(E_1\)</span> and <span class="math inline">\(E_2\)</span> be normed spaces. A mapping <span class="math inline">\(F\)</span> from <span class="math inline">\(E_1\)</span> to <span class="math inline">\(E_2\)</span> is called continuous at <span class="math inline">\(x_0\in E_1\)</span> if for any sequence <span class="math inline">\((x_n)\)</span> of elements of <span class="math inline">\(E_1\)</span> convergent to <span class="math inline">\(x_0\)</span>, the sequence <span class="math inline">\((F(x_n))\)</span> converges to <span class="math inline">\(F(x_0)\)</span>. i.e. F is continuous at <span class="math inline">\(x_0\)</span> if <span class="math inline">\(||x_n-x_0||\rightarrow 0\)</span> implies <span class="math inline">\(||F(x_n)-F(x_0)||\rightarrow 0\)</span>. If F is continuous at every <span class="math inline">\(x\in E_1\)</span>, then we simply say that <span class="math inline">\(F\)</span> is continuous.</p>
<p>==Example 1.6.1==</p>
<p>The norm in a normed space E is continuous mapping from E into R. <span class="math display">\[
||x_n-x||\rightarrow 0\implies |\space ||x_n||-||x||\space |\le||x_n-x||\rightarrow 0
\]</span> ==Theorem 1.6.1==</p>
<p>Let <span class="math inline">\(F:E_1\rightarrow E_2\)</span>. The following conditions are equivalent:</p>
<ol type="a">
<li><p><span class="math inline">\(F\)</span> is continuous</p></li>
<li><p>The inverse image <span class="math inline">\(F^{-1}(U)\)</span> of any open set U of <span class="math inline">\(E_2\)</span> is open in <span class="math inline">\(E_1\)</span></p></li>
<li><p>The inverse image <span class="math inline">\(F^{-1}(S)\)</span> of any closed set S of <span class="math inline">\(E_2\)</span> is closed in <span class="math inline">\(E_1\)</span></p></li>
</ol>
<p>Proof.</p>
<p><span class="math inline">\((a)\rightarrow (b)\)</span></p>
<p>If there exists an open set U of <span class="math inline">\(E_2\)</span>, the inverse image <span class="math inline">\(F^{-1}(U)\)</span> is not open in <span class="math inline">\(E_1\)</span></p>
<p>there exists <span class="math inline">\(x\in F^{-1}(U)\)</span>, for all <span class="math inline">\(\varepsilon&gt;0\)</span> such that <span class="math inline">\(B(x,\varepsilon)\)</span> contains elements in <span class="math inline">\(E_1\backslash F^{-1}(U)\)</span></p>
<p>Then we can choose the sequence <span class="math inline">\(x_1,x_2,\dotsm\in E_1\backslash F^{-1}(U)\)</span> satisfying <span class="math inline">\(x_n\in B(x,\frac{1}{n})\)</span> that means <span class="math inline">\(||x_n-x||\rightarrow 0\)</span></p>
<p>However, $y=F(x)U $ that means there exists <span class="math inline">\(\epsilon&gt;0\)</span> such that <span class="math inline">\(B(y,\epsilon) \subseteq U\)</span> . <span class="math inline">\(x_n\notin F^{-1}(U)\)</span> means <span class="math inline">\(F(x_n)\notin U\)</span>.</p>
<p><span class="math inline">\(F(x_n)\)</span> cannot converge to <span class="math inline">\(F(x)\)</span>. Proved.</p>
<p><span class="math inline">\((b)\rightarrow (a)\)</span></p>
<p>If for any open set U of <span class="math inline">\(E_2\)</span>, the inverse image <span class="math inline">\(F^{-1}(U)\)</span> is open in <span class="math inline">\(E_1\)</span>, then F is continuous.</p>
<p>For all <span class="math inline">\(a\in F^{-1}(U)\)</span>, <span class="math inline">\(F(a)\in U\)</span>, <span class="math inline">\(U\)</span> is open and therefore for every <span class="math inline">\(a\)</span>, there exists <span class="math inline">\(\epsilon_1\)</span> such that <span class="math inline">\(B(F(a),\epsilon_1)\subseteq U\)</span> and <span class="math inline">\(a\in F^{-1}(B(F(a),\epsilon_1))\)</span>. There exists <span class="math inline">\(\epsilon_2\)</span> such that <span class="math inline">\(B(a,\epsilon_2) \subset F^{-1}(B(F(a),\epsilon_1))\)</span></p>
<p>That mean <span class="math inline">\(||x-a||&lt;\epsilon_2\)</span> implies <span class="math inline">\(||F(x)-F(a)||&lt;\epsilon_1\)</span>. Q.E.D.</p>
<p>==Theorem 1.6.2==</p>
<p>A linear mapping <span class="math inline">\(L:E_1\rightarrow E_2\)</span> is continuous if and only if it is continuous at a point.</p>
<p>Proof.</p>
<p><span class="math inline">\(\implies\)</span> obviously</p>
<p><span class="math inline">\(\Longleftarrow\)</span></p>
<p>Assume L is continuous at <span class="math inline">\(x_0 \in E\)</span>. We define sequence <span class="math inline">\(x_1,x_2,\dotsm \in E\)</span> and for any point <span class="math inline">\(x\in E\)</span> such that <span class="math inline">\(||x_n-x ||\rightarrow 0\)</span>.</p>
<p>Since L is linear mapping, we have <span class="math display">\[
||L(x_n-x+x_0-x_0)||=||L(x_n-x+x_0)-L(x_0)||
\]</span> Since L is continuous at <span class="math inline">\(x_0\in E\)</span>, for every sequence converging to <span class="math inline">\(x_0\)</span>, the <span class="math inline">\(L\)</span> converges <span class="math inline">\(L(x_0)\)</span>. We have <span class="math display">\[
||L(x_n-x+x_0)-L(x_0)||\rightarrow 0
\]</span> Q.E.D.</p>
<p>==Definition 1.6.3== Bounded linear mapping</p>
<p>A linear mapping <span class="math inline">\(L:E_1\rightarrow E_2\)</span> is called bounded if there exists a number K such that <span class="math display">\[
||L(x)||\le K||x||
\]</span> for all <span class="math inline">\(x\in E_1\)</span>.</p>
<p>==Theorem 1.6.3==</p>
<p>A linear mapping is continuous if and only if it is bounded.</p>
<p>Proof.</p>
<p><span class="math inline">\(\implies\)</span></p>
<p>If the linear mapping is not bounded, that means for every number K, there exists some x such that <span class="math display">\[
||L(x)||&gt;K||x||
\]</span> then for every <span class="math inline">\(n-1\le|k_n|&lt; n\)</span>, there exists <span class="math inline">\(x_n \in E_1\)</span> such that <span class="math display">\[
||L(x_n)||&gt;k_n||x_n||
\]</span> We define the sequence <span class="math display">\[
y_n=\frac{x_n}{k_n||x_n||}
\]</span> when <span class="math inline">\(n\rightarrow \infty\)</span> <span class="math display">\[
||y_n||=\frac{1}{k_n}\rightarrow 0\\
||L(y_n)||&gt;k_n||y_n||=1
\]</span> Therefore, <span class="math inline">\(L\)</span> is not continuous.</p>
<p><span class="math inline">\(\Longleftarrow\)</span></p>
<p>If L is bounded, then there exists a number K, for all <span class="math inline">\(x\in E_1\)</span> such that <span class="math display">\[
||L(x)||\le K||x||
\]</span> Then we define a sequence <span class="math inline">\((x_n)\)</span> converging to zero. When <span class="math inline">\(n\rightarrow \infty\)</span>, <span class="math display">\[
||L(x_n)||\le K||x_n||\rightarrow 0
\]</span> By theorem 1.6.2, The linear mapping L is continuous at zero point, then it is continuous linear mapping.</p>
<p>Q.E.D.</p>
<p>The space of all linear mapping from a vector space <span class="math inline">\(E_1\)</span> into a vector space <span class="math inline">\(E_2\)</span> becomes a vector space if addition and multiplication by scalars are defined as follows <span class="math display">\[
(L_1+L_2)(x)=L_1(x)+L_2(x)\\
(\lambda L)(x)=\lambda(L(x))
\]</span> If <span class="math inline">\(E_1\)</span> and <span class="math inline">\(E_2\)</span> are normed spaces, then the set of all bounded linear mappings from <span class="math inline">\(E_1\)</span> into <span class="math inline">\(E_2\)</span>, denoted by <span class="math inline">\(\mathscr B(E_1,E_2)\)</span>, is a vector subspace of the space defined above.</p>
<p>==Theorem 1.6.4==</p>
<p>If <span class="math inline">\(E_1\)</span> and <span class="math inline">\(E_2\)</span> are normed space, then <span class="math inline">\(\mathscr B(E_1,E_2)\)</span> is a normed space with norm defined by <span class="math display">\[
||L||=\sup_{||x||=1}||L(x)||\quad \forall L\in \mathscr B(E_1,E_2)
\]</span> Proof.</p>
<p>Only show Triangle Inequality</p>
<p><span class="math inline">\(\forall L_1,L_2\in \mathscr B(E_1,E_2)\)</span> <span class="math display">\[
||L_1+L_2||=\sup_{||x||=1}||L_1(x)+L_2(x)||\le \sup_{||x||=1}||L_1(x)||+\sup_{||x||=1}||L_2(x)||=||L_1||+||L_2||
\]</span> Q.E.D.</p>
<p>It follows Theorem 1.6.4 that <span class="math inline">\(||L(x)||\le ||L||||x||\)</span> for all <span class="math inline">\(x\in E_1\)</span>. In fact, <span class="math inline">\(||L||\)</span> is the least number K such that <span class="math inline">\(||L(x)||\le K||x||\)</span> for all <span class="math inline">\(x\in E_1\)</span>.</p>
<p>The norm defined above is the standard norm in <span class="math inline">\(\mathscr B(E_1,E_2)\)</span>. It is usually called the ==operator norm==. Convergence with respect to this norm is called the uniform convergence of operator.</p>
<p>==Theorem 1.6.5==</p>
<p>If <span class="math inline">\(E_1\)</span> is normed space and <span class="math inline">\(E_2\)</span> is a Banach space, then <span class="math inline">\(\mathscr B(E_1,E_2)\)</span> is a Banach space.</p>
<p>Proof.</p>
<p>We only need to show that <span class="math inline">\(\mathscr B(E_1,E_2)\)</span> is complete.</p>
<p>A normed space <span class="math inline">\(\mathscr B(E_1,E_2)\)</span> is called complete if every Cauchy sequence in <span class="math inline">\(\mathscr B(E_1,E_2)\)</span> converges to an element of <span class="math inline">\(\mathscr B(E_1,E_2)\)</span>.</p>
<p>Let <span class="math inline">\((L_n)\)</span> be Cauchy sequence of <span class="math inline">\(\mathscr B(E_1,E_2)\)</span> and Let <span class="math inline">\(\forall x\in E_1\)</span></p>
<p>We have <span class="math display">\[
||L_m(x)-L_n(x)||\le ||L_m-L_n||||x||\rightarrow 0 \quad as\space n,m \rightarrow \infty
\]</span> That means <span class="math inline">\((L_n(x))\)</span> is Cauchy sequence in <span class="math inline">\(E_2\)</span>. By completeness of <span class="math inline">\(E_2\)</span>, we have <span class="math inline">\(L(x)\in E_2\)</span> such that <span class="math display">\[
L(x)=\lim_{n\rightarrow \infty} L_n(x)
\]</span> Then we only need to prove <span class="math inline">\(||L_n-L||\rightarrow 0\)</span> and <span class="math inline">\(L\in \mathscr B(E_1,E_2)\)</span></p>
<p>First we prove <span class="math inline">\(L\in \mathscr B(E_1,E_2)\)</span>, we only need to prove <span class="math inline">\(\exists K,||L(x)||\le K||x||\)</span> <span class="math display">\[
||L(x)||=||\lim_{n\rightarrow \infty }L_n(x)||=\lim_{n\rightarrow \infty}||L_n(x)||
\]</span> Since <span class="math inline">\(E_2\)</span> is complete and Cauchy sequence <span class="math inline">\((L_n)\)</span> is bounded, that means <span class="math inline">\(||L_n||\le M\)</span> <span class="math display">\[
\lim_{n\rightarrow \infty}||L_n(x)||\le M||x||\\
||L(x)||\le M||x||
\]</span> Then we need to prove <span class="math inline">\(||L_n-L||\rightarrow 0\)</span> <span class="math display">\[
||L_m-L_n||\rightarrow 0\\
m\rightarrow \infty\\
||L_n-L||\rightarrow 0
\]</span> Q.E.D.</p>
<p>==Theorem 1.6.6==</p>
<p>Let L be a continuous linear mapping from a subspace of a normed space <span class="math inline">\(E_1\)</span> into a Banach space <span class="math inline">\(E_2\)</span>. Then L has a unique extension continuous linear mapping defined on the closure of the domain <span class="math inline">\(\mathscr D(L)\)</span>. In particular, if <span class="math inline">\(\mathscr D(L)\)</span> is dense in <span class="math inline">\(E_1\)</span>, then L has a unique extension to a continuous linear mapping defined on the whole space <span class="math inline">\(E_1\)</span>.</p>
<p>==Theorem 1.6.7==</p>
<p>If <span class="math inline">\(L:E_1\rightarrow E_2\)</span> is a continuous linear mapping, then the null space <span class="math inline">\(\mathscr N(L)\)</span> is a closed subspace of E. Moreover, if the domain <span class="math inline">\(\mathscr D(L)\)</span> is closed, then the graph <span class="math inline">\(\mathscr G(L)\)</span> is a closed subspace of <span class="math inline">\(E_1\times E_2\)</span>.</p>
<p>==Theorem 1.6.9==</p>
<p>Let <span class="math inline">\(\mathscr T\)</span> be a family of bounded linear mapping from a Banach space X into a normed space Y. If for every <span class="math inline">\(x\in X\)</span> there exists a constant <span class="math inline">\(M_x\)</span> such that <span class="math inline">\(||T(x)||\le M_x\)</span> for all <span class="math inline">\(T\in \mathscr T\)</span>, then there exists a constant <span class="math inline">\(M&gt;0\)</span> such that <span class="math inline">\(||T||\le M\)</span> for all <span class="math inline">\(T\in \mathscr T\)</span>.</p>
<h2 id="completion-of-normed-spaces">1.7 Completion of Normed Spaces</h2>
<p>Some spaces arising naturally from applications are not complete. We would like to find a way to enlarge such a space to a complete space. It turns out that it is always possible.</p>
<p>Let <span class="math inline">\((E,||\cdot||)\)</span> be a normed space. A normed space <span class="math inline">\((\tilde E,||\cdot||_1)\)</span> is called a completion of <span class="math inline">\((E,||\cdot||)\)</span> if</p>
<ol type="a">
<li><p>there exists a one-to-one linear mapping <span class="math inline">\(\Phi:E\rightarrow \tilde E\)</span></p></li>
<li><p><span class="math inline">\(||x||=||\Phi(x)||_1\)</span> for every <span class="math inline">\(x\in E\)</span></p></li>
<li><p><span class="math inline">\(\Phi(E)\)</span> is dense in <span class="math inline">\(\tilde E\)</span></p></li>
<li><p><span class="math inline">\(\tilde E\)</span> is complete</p></li>
</ol>
<h1 id="the-lebesgue-integral">The Lebesgue Integral</h1>
<h2 id="introduction-1">2.1 Introduction</h2>
<p>The main purpose of this book is a presentation of basic methods and applications of Hilbert spaces. One of the most important applications of the theory is the solution of differential equations. To this aim, we need, for example, a Hilbert space which contains all differentiable functions defined on some intervals [a,b] for which the inner product is defined by <span class="math display">\[
\langle f,g \rangle = \int_a^bf(x)\overline{g(x)}dx
\]</span> The smallest Hilbert space satisfying these conditions is the space of Lebesgue square integrable functions on [a,b]. Thus, the Lebesgue integral is essential for understanding some of the most important applications of Hilbert space theory.</p>
<h2 id="step-functions">2.2 Step Functions</h2>
<p>By a step function on the real line <span class="math inline">\(R\)</span> we mean a finite linear combination of characteristic functions of semi-open intervals <span class="math inline">\([a,b)\subseteq R\)</span>. Thus for every step function <span class="math inline">\(f\)</span>, there are intervals <span class="math inline">\([a_1,b_1),[a_2,b_2),\dotsm,[a_n,b_n)\)</span> and numbers <span class="math inline">\(\lambda_1,\lambda_2,\dotsm,\lambda_n \in R\)</span> such that <span class="math display">\[
f(x)=\lambda_1f_1(x)+\lambda_2f_2(x)+\dotsm+\lambda_nf_n(x)
\]</span> where <span class="math inline">\(f_k\)</span> is the characteristic function of <span class="math inline">\([a_k,b_k)\)</span>. That means for <span class="math inline">\(x\in [a_k,b_k)\)</span>, <span class="math inline">\(f(x)=1\)</span>, and <span class="math inline">\(f(x)=0\)</span>, otherwise.</p>
<p>If we assume that intervals are disjoint and the minimal number of intervals are used, then the representation can be unique. This representation is called basic representation of <span class="math inline">\(f\)</span> and we call <span class="math inline">\(f=0\)</span> the basic representation of the zero function.</p>
<p>The collection of all step function on R is a vector space. The absolute value of a step function is again a step function.</p>
<p>If <span class="math inline">\(f=\alpha_1f_1+\alpha_2f_2+\dotsm+\alpha_nf_n\)</span> is a basic representation of a step function, then <span class="math display">\[
|f|=|\alpha_1|f_1+|\alpha_2|f_2+\dotsm+|\alpha_n|f_n
\]</span> For any real value functions <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> we have <span class="math display">\[
\min(f,g)=\frac{1}{2}(f+g-|f-g|)\quad \max(f,g)=\frac{1}{2}(f+g+|f-g|)
\]</span> That means <span class="math inline">\(\min(f,g)\)</span> and <span class="math inline">\(\max(f,g)\)</span> are step functions.</p>
<p>By the ==support== of a nonzero function <span class="math inline">\(f\)</span>, denoted by supp <span class="math inline">\(f\)</span>, we mean the set of all points <span class="math inline">\(x\in R\)</span> for which <span class="math inline">\(f(x)\neq 0\)</span>. The support of a nonzero step function is always a finite union of semi-open intervals. If <span class="math inline">\(f=0\)</span>, supp <span class="math inline">\(f=\empty\)</span></p>
<p>==Definition 2.2.1== Integral of a step function</p>
<p>The integral <span class="math inline">\(\int f\)</span> of a step function <span class="math inline">\(f(x)=\lambda_1f_1(x)+\lambda_2f_2(x)+\dotsm+\lambda_nf_n(x)\)</span> where <span class="math inline">\(f_k\)</span> is the characteristic function of <span class="math inline">\([a_k,b_k),k=1,\dotsm,n\)</span> is defined by <span class="math display">\[
\int f=\lambda_1(b_1-a_1)+\lambda_2(b_2-a_2)+\dotsm+\lambda_n(b_n-a_n)
\]</span> clearly, the value of <span class="math inline">\(\int f\)</span> is equal to the Riemann Integral of <span class="math inline">\(f\)</span>. From the properties of Riemann integral it follows that the defined integral does not depend on a particular representation.</p>
<p>==Theorem 2.2.1==</p>
<p>For any step functions <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> we have</p>
<ol type="a">
<li><p><span class="math inline">\(\int (f+g)=\int f+\int g\)</span></p></li>
<li><p><span class="math inline">\(\int \lambda f=\lambda \int f\)</span>, <span class="math inline">\(\lambda \in R\)</span></p></li>
<li><p><span class="math inline">\(f\le g\implies \int f\le \int g\)</span></p></li>
<li><p><span class="math inline">\(|\int f|\le \int |f|\)</span></p></li>
</ol>
<p>Proof.</p>
<ol type="a">
<li><ol start="2" type="a">
<li>can be proved directly from definition</li>
</ol></li>
<li>We only need to prove <span class="math inline">\(g-f\ge 0\implies \int (g-f)\ge 0\)</span> i.e. <span class="math inline">\(f\ge 0\implies \int f\ge 0\)</span></li>
</ol>
<p>If <span class="math inline">\(f\ge 0\)</span>, then all parameters are positive and <span class="math inline">\(\int f \ge 0\)</span></p>
<ol start="4" type="a">
<li><span class="math inline">\(|\int f|=|\lambda_1(b_1-a_1)+\lambda_2(b_2-a_2)+\dotsm+\lambda_n(b_n-a_n)|\)</span></li>
</ol>
<p><span class="math inline">\(\int |f|=|\lambda_1|(b_1-a_1)+|\lambda_2|(b_2-a_2)+\dotsm+|\lambda_n|(b_n-a_n)\)</span></p>
<p>==Lemma 2.2.1==</p>
<p>Let <span class="math inline">\(f\)</span> be a step function whose support is contained in the union of semi-open intervals <span class="math inline">\([a_1,b_1),\dotsm,[a_n,b_n)\)</span>. If <span class="math inline">\(|f|&lt;M\)</span> for some constant <span class="math inline">\(M&gt;0\)</span>, then <span class="math display">\[
\int |f|\le M\sum_{k=1}^n(b_k-a_k)
\]</span> Proof.</p>
<p><span class="math inline">\(|f|=|\alpha_1|f_1+|\alpha_2|f_2+\dotsm+|\alpha_n|f_n\)</span>. Then we choose <span class="math inline">\(M &gt; \max\{|\alpha_1|,\dots,|\alpha_n|\}\)</span></p>
<p>Then <span class="math display">\[
\int |f|=|\alpha_1|(b_1-a_1)+|\alpha_2|(b_2-a_2)+\dotsm+|\alpha_n|(b_n-a_n)\\
\le M(b_1-a_1)+M(b_2-a_2)+\dotsm+M(b_n-a_n)\\
=M\sum_{k=1}^n(b_k-a_k)
\]</span> ==Lemma 2.2.2==</p>
<p>Let <span class="math inline">\([a_1,b_1),[a_2,b_2),\dotsm\)</span> be disjoint subintervals of an interval <span class="math inline">\([a,b)\)</span> such that <span class="math display">\[
\bigcup_{n=1}^\infty [a_n,b_n)=[a,b)
\]</span> Then <span class="math display">\[
\sum_{n=1}^\infty (b_n-a_n)=b-a
\]</span> Proof.</p>
<p>Let <span class="math inline">\(S \subset [a,b)\)</span> consist of all points <span class="math inline">\(c\)</span> such that the lemma holds for the interval <span class="math inline">\([a,c)\)</span> and for each of the subintervals <span class="math inline">\([a_n,b_n)\cap [a,c)\)</span> , S is not empty because <span class="math inline">\(a=a_{n_0}\)</span> for some <span class="math inline">\(n_0\in N\)</span> and then <span class="math inline">\(b_{n_0}\in S\)</span>. If <span class="math inline">\(c\in S\)</span>, then <span class="math inline">\(\sum_n(b_{c,n}-a_n)\)</span> where <span class="math inline">\(b_{c,n}=\min \{b_n,c\}\)</span>. It suffices to prove <span class="math inline">\(b\in S\)</span>.</p>
<p>To this end, we first prove lub <span class="math inline">\(S \in S\)</span>. Indeed, if <span class="math inline">\(s=\)</span> lub S and <span class="math inline">\(\{s_n\}\)</span> is a non-decreasing sequence of elements of S convergent to s, then <span class="math display">\[
s_n-a=\sum_m (b_{s_n,m}-a_m)\le \sum_m(b_{s,m}-a_m)\le s-a
\]</span> Then <span class="math inline">\(s_n-a\rightarrow s-a\implies \sum_m(b_{s,m}-a_m)= s-a\)</span>, then <span class="math inline">\(s\in S\)</span>, then easily <span class="math inline">\(s=b\)</span></p>
<p>Q.E.D.</p>
<p>==Theorem 2.2.2==</p>
<p>Let <span class="math inline">\((f_n)\)</span> be a non-increasing sequence of non-negative step functions such that <span class="math inline">\(\lim_{n\rightarrow \infty} f_n(x)=0\)</span> for every <span class="math inline">\(x\in R\)</span>. Then <span class="math inline">\(\lim_{n\rightarrow \infty} \int f_n=0\)</span>.</p>
<p>Proof.</p>
<p><span class="math inline">\((f_n)\)</span> is non-increasing sequence, and therefore $f_{n+1}f_nf_{n+1}f_n $</p>
<p><span class="math inline">\(f_n \ge 0\implies \int f_n \ge 0\)</span></p>
<p>Therefore <span class="math inline">\((\int f_n)\)</span> is non-increasing and bounded from below, it converges.</p>
<p>Let <span class="math display">\[
\lim_{n\rightarrow \infty} \int f_n=\varepsilon&gt;0
\]</span> Let <span class="math inline">\([a,b)\)</span> be an interval containing all the support of <span class="math inline">\(f_1\)</span> (and therefore, <span class="math inline">\(f_n\)</span>). Put <span class="math inline">\(\alpha=\varepsilon /(2(b-a))\)</span> <span class="math display">\[
A_n=\{x\in[a,b):f_n(x)&lt;\alpha\}\\
\begin{array}{rcl}
B_1=A_1 &amp; B_2=A_2\backslash A_1 &amp; B_2=A_3\backslash A_2\dotsm
\end{array}
\]</span> Note that <span class="math inline">\(B_n\)</span> are disjoint and <span class="math inline">\(\bigcup_{n=1}^\infty B_n=[a,b)\)</span></p>
<p>Because <span class="math inline">\(f_n\)</span> are step functions, <span class="math display">\[
B_n=[a_{n,1},b_{n,1})\cup\dotsm \cup[a_{n,k_n},b_{n,k_n})
\]</span> By lemma 2.2.2, <span class="math display">\[
\sum_{n=1}^\infty \sum_{k=1}^{k_n}(b_{n,k}-a_{n,k})=b-a
\]</span> Let <span class="math inline">\(n_0 \in N\)</span> such that <span class="math display">\[
\sum_{n=n_0+1}^\infty \sum_{k=1}^{k_n}(b_{n,k}-a_{n,k})&lt;\delta
\]</span> where <span class="math inline">\(\delta = \varepsilon/(2\max|f_1|)\)</span>.</p>
<p>Define <span class="math display">\[
F=[a_{1,1},b_{1,1})\cup \dotsm\cup [a_{1,k_1},b_{1,k_1})\cup\dotsm\cup[a_{n_0,1},b_{n_0,1})\cup\dotsm\cup[a_{n_0,k_{n_0}},b_{n_0,k_{n_0}})
\]</span> Then, <span class="math display">\[
g(x)=
\begin{cases}
f_{n_0}(x) &amp; x\in F\\
0 &amp; otherwise
\end{cases}\\
h(x)=
\begin{cases}
0 &amp; x\in F\\
f_{n_0}(x) &amp; otherwise
\end{cases}
\]</span> <span class="math inline">\(x\in F\implies x\in A_{n_0}\)</span>, and thus <span class="math inline">\(f_{n_0}(x)&lt;\alpha\)</span> <span class="math display">\[
\int g&lt;\alpha(b-a)=\frac{\varepsilon }{2} 
\]</span> and, <span class="math display">\[
\int h&lt;\delta \max|f_{n_0}|\le \delta\max|f_{1}|=\frac{\varepsilon }{2} 
\]</span> Therefore, <span class="math display">\[
\int f=\int g+\int h &lt;\varepsilon
\]</span> Q.E.D.</p>
<p>==Lemma 2.2.3==</p>
<p>Let <span class="math inline">\((g_n)\)</span> and <span class="math inline">\((h_n)\)</span> be non-decreasing sequences of step functions. If <span class="math inline">\(\lim_{n\rightarrow \infty} h_n(x)\le \lim_{n\rightarrow \infty} g_n(x)\)</span> for every <span class="math inline">\(x\in R\)</span>, then <span class="math inline">\(\lim_{n\rightarrow \infty} \int h_n(x)\le \lim_{n\rightarrow \infty} \int g_n(x)\)</span></p>
<p>Proof.</p>
<p>Fix <span class="math inline">\(k\in N\)</span>. $h_k-(h_k,g_n)(n) $ is non-decreasing sequence converging to zero for every <span class="math inline">\(x\in R\)</span></p>
<p>By theorem 2.2.2 <span class="math display">\[
0=\lim_{n\rightarrow \infty}\int (h_k-\min(h_k,g_n))\\
=\lim_{n\rightarrow \infty}\int h_k-\lim_{n\rightarrow \infty}\int\min(h_k,g_n)\\
\]</span> Q.E.D.</p>
<h2 id="lebesgue-integrable-functions">2.3 Lebesgue Integrable Functions</h2>
<p>==Definition 2.3.1== (Lebesgue Integral)</p>
<p>A real-valued function <span class="math inline">\(f\)</span> defined on <span class="math inline">\(R\)</span> is called Lebesgue integrable if there exists a sequence of step functions <span class="math inline">\((f_n)\)</span> such that the following two conditions are satisfied:</p>
<ol type="a">
<li><p><span class="math inline">\(\sum_{n=1}^\infty \int|f_n|&lt;\infty\)</span></p></li>
<li><p><span class="math inline">\(f(x)=\sum_{n=1}^\infty f_n(x)\)</span> for every <span class="math inline">\(x\in R\)</span> such that <span class="math inline">\(\sum_{n=1}^\infty |f_n(x)|&lt;\infty\)</span></p></li>
</ol>
<p>The integral of <span class="math inline">\(f\)</span> is then defined by <span class="math display">\[
\int f=\sum_{n=1}^\infty \int f_n
\]</span> If a function <span class="math inline">\(f\)</span> and a sequence of step function <span class="math inline">\((f_n)\)</span> satisfy (a) and (b), then we will write <span class="math display">\[
f \simeq \sum_{n=1}^\infty f_n\text{ or } f\simeq f_1+f_2+\dotsm
\]</span> ==Theorem 2.3.1==</p>
<p>If <span class="math inline">\(f\simeq f_1+f_2+\dotsm\)</span> and <span class="math inline">\(f\ge 0\)</span>, then <span class="math inline">\(\int f_1+\int f_2 +\dotsm \ge 0\)</span></p>
<p>Proof <span class="math display">\[
\forall \varepsilon&gt;0,\exists n_0\in N\quad \sum_{n=n_0+1}^\infty \int |f_n|&lt;\varepsilon
\]</span> Then define <span class="math display">\[
g_n = f_1+\dotsm+f_{n_0}+|f_{n_0+1}|+\dotsm+|f_{n_0+n}|\\
h_n=\max (g_n,0)\\
\]</span> and <span class="math inline">\(g_n\)</span> and <span class="math inline">\(h_n\)</span> are non-decreasing sequences</p>
<p>Then <span class="math display">\[
\lim _{n\rightarrow \infty }g_n=\lim_{n \rightarrow \infty} h_n \implies \\
\lim _{n\rightarrow \infty }\int g_n=\lim_{n \rightarrow \infty}\int  h_n\ge0
\]</span> and this <span class="math display">\[
\int f_1+\dotsm+\int f_{n_0}+\int |f_{n_0+1}|+\dotsm\ge 0 \\
\int f_1+\dotsm+2\sum_{n=n_0+1}^\infty\int |f_{n}|\ge 0 \\
\int f_1+\dotsm+2\varepsilon\ge 0 \\
\]</span> because <span class="math inline">\(\varepsilon\)</span> is arbitrary, Q.E.D.</p>
<p>==Corollary 2.3.1==</p>
<p>If <span class="math inline">\(f\simeq \sum_{n=1}^\infty f_n\)</span> and <span class="math inline">\(f\simeq \sum_{n=1}^\infty g_n\)</span>. then <span class="math inline">\(\sum_{n=1}^\infty \int f_n=\sum_{n=1}^\infty \int g_n\)</span></p>
<p>By theorem 2.3.1. Q.E.D.</p>
<p>The space of all ==Lebesgue integrable functions== defined on R will be denoted as <span class="math inline">\(L^1(R)\)</span>. In the sequel, Lebesgue integrable functions will be called simply ==integrable==.</p>
<p>It will be proved that every Riemann integrable function is Lebesgue integrable and both integrals are equal.</p>
<p>==Theorem 2.3.2==</p>
<p><span class="math inline">\(L^1(R)\)</span> is a vector space and <span class="math inline">\(\int\)</span> is a linear functional on <span class="math inline">\(L^1(R)\)</span>.</p>
<p>==Theorem 2.3.3==</p>
<p>If <span class="math inline">\(f,g \in L^1(R)\)</span> and <span class="math inline">\(f&lt;g\)</span>, then <span class="math inline">\(\int f\le \int g\)</span></p>
<p>Definition 2.3.1 is fairly simple although it may be a little disturbing.</p>
<h2 id="the-absolute-value-of-an-integrable-function">2.4 The absolute value of an integrable function</h2>
<p>In the previous section, we mentioned that all Riemann integrable functions are Lebesgue integrable.</p>
<p>For improper integrals it is not so. For instance, the integral <span class="math display">\[
\int_{-\infty}^\infty \frac{\sin x}{x}dx
\]</span> converges, although the function is not Lebesgue integrable. It is clear from the following theorem,</p>
<p>==Theorem 2.4.1==</p>
<p>If <span class="math inline">\(f\in L^1(R)\)</span>, then <span class="math inline">\(|f|\in L^1(R)\)</span> and <span class="math inline">\(|\int f| \le \int |f|\)</span></p>
<p><span class="math inline">\(f\in L^1(R)\)</span> means</p>
<ol type="a">
<li><p><span class="math inline">\(\sum_{n=1}^\infty \int|f_n|&lt;\infty\)</span></p></li>
<li><p><span class="math inline">\(f(x)=\sum_{n=1}^\infty f_n(x)\)</span> for every <span class="math inline">\(x\in R\)</span> such that <span class="math inline">\(\sum_{n=1}^\infty |f_n(x)|&lt;\infty\)</span></p></li>
</ol>
<p>Let <span class="math inline">\(f=f_1+f_2+\dotsm\)</span> and define <span class="math display">\[
Z=\{x\in R:\sum_{n=1}^\infty |f_n(x)|&lt;\infty\}\\
s_n=f_1+f_2+\dotsm+f_n
\]</span> Then <span class="math display">\[
f(x)=\lim_{n\rightarrow \infty} s_n(x)\\
|f(x)|=|\lim_{n\rightarrow \infty} s_n(x)|=\lim_{n\rightarrow \infty} |s_n(x)|\\
=|s_1|+(|s_2|-|s_1|)+(|s_3|-|s_2|)\dotsm
\]</span> define <span class="math inline">\(g_1=|s_1|\)</span>, <span class="math inline">\(g_n=|s_n|-|s_{n-1}|\)</span> <span class="math display">\[
|f(x)|=\sum_{n=1}^\infty g_n(x)
\]</span> Then we have <span class="math display">\[
|g_n|\le |s_n-s_{n-1}|=|f_n|\\
\int |g_n|\le \int |f_n|\\
\sum_{n=1}^\infty \int |g_n|&lt;\infty
\]</span> Q.E.D.</p>
<p>==Corollary 2.4.1==</p>
<p>If <span class="math inline">\(f\simeq f_1+f_2+\dotsm\)</span>, then <span class="math inline">\(\int |f|\le \sum_{n=1}^\infty\int |f_n|\)</span></p>
<p>==Corollary 2.4.2==</p>
<p>If <span class="math inline">\(f,g\in L^1(R)\)</span>, then <span class="math inline">\(\min(f,g),\max(f,g) \in L^1(R)\)</span>.</p>
<p>==Theorem 2.4.2==</p>
<p>If <span class="math inline">\(f\in L^1(R)\)</span>, then <span class="math inline">\(\lim_{t\rightarrow 0}\int |f(x+t)-f(x)|dx=0\)</span></p>
<h2 id="series-of-integrable-functions">2.5 Series of integrable functions</h2>
<p>In the construction described in the preceding sections, we start with an integral of step functions and extend it to a larger class of functions by expanding them in series of step functions <span class="math inline">\(f\simeq f_1+f_2+\dotsm\)</span>. The functions in that class have a well-defined integral. This result is a form of completeness of the space of Lebesgue integrable functions. It is of fundamental importance for the theory of the Lebesgue integral.</p>
<p>==Definition 2.5.1==</p>
<p>Let <span class="math inline">\(f\)</span> be a real-valued function and let <span class="math inline">\((f_n)\)</span> be a sequence of <strong>integrable functions</strong> (Not step functions). If</p>
<ol type="a">
<li><p><span class="math inline">\(\sum_{n=1}^\infty \int |f_n|&lt;\infty\)</span></p></li>
<li><p><span class="math inline">\(f(x)=\sum_{n=1}^\infty f_n(x)\)</span> for every <span class="math inline">\(x\in R\)</span> such that <span class="math inline">\(\sum_{n=1}^\infty |f_n(x)|&lt;\infty\)</span></p></li>
</ol>
<p>then we write <span class="math inline">\(f\simeq f_1+f_2+\dotsm\)</span> or <span class="math inline">\(f\simeq \sum_{n=1}^\infty f_n\)</span></p>
<p>==Lemma 2.5.1==</p>
<p>If <span class="math inline">\(f\in L^1(R)\)</span>, then for every <span class="math inline">\(\epsilon&gt;0\)</span> there exists a sequence of step functions <span class="math inline">\((f_n)\)</span> such that <span class="math inline">\(f\simeq f_1+f_2+\dotsm\)</span> and <span class="math inline">\(\sum_{n=1}^\infty\int |f_n|\le \int |f|+\epsilon\)</span></p>
<p>Proof.</p>
<p>Define, <span class="math inline">\(f\simeq g_1+g_2+\dotsm\)</span>, for every <span class="math inline">\(\varepsilon&gt;0\)</span> there exists <span class="math inline">\(n_0\in N\)</span> such that <span class="math display">\[
\sum_{n=n_0+1}^\infty \int |g_n|&lt;\frac{\varepsilon}{2}
\]</span> Define <span class="math display">\[
f_1=g_1+\dotsm+g_n\\
f_n=g_{n_0+n-1}\\
f\simeq f_1+f_2+\dotsm\\
f-f_1\simeq f_2+f_3+\dotsm\\
\int |f_1|-\int |f|\le\int |f-f_1|\le \sum_{n=2}^\infty |f_n|\\
\sum_{n=1}^\infty \int |f_n|=\int |f_1|+\sum_{n=2}^\infty |f_n|\\
\le \int |f|+2\sum_{n=2}^\infty |f_n|\\
=\int |f|+\varepsilon
\]</span> ==Theorem 2.5.1==</p>
<p>If <span class="math inline">\((f_n)\)</span> is a sequence of integrable functions and <span class="math inline">\(f\simeq f_1+f_2+\dotsm\)</span>, then <span class="math inline">\(f\)</span> is integrable and <span class="math inline">\(\int f=\int f_1+\int f_2+\dotsm\)</span></p>
<p>==Corollary 2.5.1==</p>
<p>Let <span class="math inline">\(f_1,f_2,\dotsm\in L^1(R)\)</span>. If <span class="math inline">\(\sum_{n=1}^\infty \int |f_n|&lt;\infty\)</span>, then there exists an integrable function <span class="math inline">\(f\)</span> such that <span class="math inline">\(f=f_1+f_2+\dotsm\)</span>.</p>
<h2 id="norm-in-l1r">2.6 Norm in <span class="math inline">\(L^1(R)\)</span></h2>
<p>One of the important features of the Lebesgue integral is that the techniques of normed spaces can be used. We will see that, with some precautions, <span class="math inline">\(L^1(R)\)</span> can be treated as a <strong>Banach space</strong>.</p>
<p>==Definition 2.6.1== (<span class="math inline">\(L^1-\)</span>norm)</p>
<p>The functional <span class="math inline">\(||\cdot||:L^1(R)\rightarrow R\)</span> defined by <span class="math inline">\(||f||=\int |f|\)</span> will be called the norm in <span class="math inline">\(L^1(R)\)</span> or the <span class="math inline">\(L^1-\)</span>norm</p>
<p>The functional <span class="math inline">\(||\cdot||\)</span> is well defined in view of Theorem 2.4.1. By Theorem 2.3.2 and Theorem 2.3.3, we have <span class="math display">\[
||\lambda f||=|\lambda|||f||\\
||f+g||\le ||f||+||g||
\]</span> However, we cannot say that the defined functional <span class="math inline">\(||\cdot||\)</span> is a norm. There are non-zero functions <span class="math inline">\(f\)</span> for which <span class="math inline">\(\int |f|=0\)</span>. Consider, for example, the function <span class="math inline">\(f(x)=0\)</span> for every <span class="math inline">\(x\)</span> except 0 and <span class="math inline">\(f(0)=1\)</span>. This is a none zero function but <span class="math inline">\(\int |f|=0\)</span>. This difficulty can be resolved by the following way.</p>
<p>==Definition 2.6.2== (Null Function)</p>
<p>A function is called a null function if <span class="math inline">\(f\)</span> is integrable and <span class="math inline">\(\int |f|=0\)</span></p>
<p>Two functions <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> will be called equivalent if <span class="math inline">\(f-g\)</span> is a null function. It is easy to check the defined relation is an equivalence relation. Now we define the space <span class="math inline">\(\mathscr L^1(R)\)</span> as the space of equivalence classes of Lebesgue integrable functions. The equivalence classes of <span class="math inline">\(f\in L^1(R)\)</span> is denoted by <span class="math inline">\([f]\)</span> <span class="math display">\[
[f]=\{g\in L^1(R):\int |f-g|=0\}
\]</span> With the usual definition <span class="math display">\[
[f]+[g]=[f+g],\lambda[f]=[\lambda f],||[f]||=\int |f|
\]</span> <span class="math inline">\((\mathscr L^1(R),||\cdot||)\)</span> becomes a normed space.</p>
<p>The following theorem describes an important property of null functions.</p>
<p>==Theorem 2.6.1==</p>
<p>If <span class="math inline">\(f\)</span> is a null function and <span class="math inline">\(|g|\le |f|\)</span>, then <span class="math inline">\(g\)</span> is a null function too.</p>
<p>==Definition 2.6.3== Convergence in Norm</p>
<p>We say that a sequence of functions <span class="math inline">\(f_1,f_2,\dotsm \in L^1(R)\)</span> converges to a function <span class="math inline">\(f\in L^1(R)\)</span> in norm, denoted by <span class="math inline">\(f_n\rightarrow f\)</span> i.n., if <span class="math inline">\(||f_n-f||\rightarrow 0\)</span>.</p>
<p>The following theorem is simple but important.</p>
<p>==Theorem 2.6.2==</p>
<p>If <span class="math inline">\(f_n\rightarrow f \space i.n.\)</span>, then <span class="math inline">\(\int f_n\rightarrow \int f\)</span>.</p>
<p>==Theorem 2.6.3==</p>
<p>If <span class="math inline">\(f\simeq f_1+f_2+\dotsm\)</span>, then the series <span class="math inline">\(f_1+f_2 +\dotsm\)</span> converges to <span class="math inline">\(f\)</span> in norm.</p>
<h2 id="convergence-almost-everywhere">2.7 Convergence Almost Everywhere</h2>
<p>If <span class="math inline">\(f\simeq f_1+f_2+\dotsm\)</span>, then the series <span class="math inline">\(f_1(x)+f_2(x)+\dotsm\)</span> need not converge at every <span class="math inline">\(x\in R\)</span>. On the other hand, the set of those points where we do not have convergence is a small set.</p>
<p>==Definition: Null set==</p>
<p>A set <span class="math inline">\(x\in R\)</span> will be called a null set or a set of measure zero if its characteristic function is a null function.</p>
<p>==Theorem 2.7.1==</p>
<p>Every subset of a null set is a null set.</p>
<p>==Definition 2.7.2== (Equality Almost Everywhere)</p>
<p>If for two functions <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> defined on R, the set of all <span class="math inline">\(x\in R\)</span> for which <span class="math inline">\(f(x)\neq g(x)\)</span> is a null set, then we say that <span class="math inline">\(f\)</span> equals <span class="math inline">\(g\)</span> almost everywhere and write <span class="math inline">\(f=g\)</span> a.e.</p>
<p>==Theorem 2.7.2==</p>
<p><span class="math inline">\(\int |f-g|=0\)</span> if and only if <span class="math inline">\(f=g\)</span> a.e. In particular, <span class="math inline">\(\int |f|=0\)</span> if and only if <span class="math inline">\(f=0\)</span> a.e.</p>
<p>That means the equivalence of functions defined in section 2.6 and equality almost everywhere are the same thing.</p>
<p>==Theorem 2.7.3==</p>
<p>Suppose <span class="math inline">\(f_n\rightarrow f\)</span> i.n. Then <span class="math inline">\(f_n\rightarrow g\)</span> i.n. if and only if <span class="math inline">\(f=g\)</span> a.e.</p>
<p>==Definition 2.7.3== Convergence Almost Everywhere</p>
<p>We say a sequence of functions <span class="math inline">\(f_1,f_2,\dotsm\)</span> defined on R converges to a function <span class="math inline">\(f\)</span> almost everywhere, denoted by $f_nf $ a.e., if <span class="math inline">\(f_n(x)\rightarrow f(x)\)</span> for every <span class="math inline">\(x\)</span> except a null set.</p>
<p>==Theorem 2.7.4==</p>
<p>Suppose <span class="math inline">\(f_n\rightarrow f\)</span> a.e. Then <span class="math inline">\(f_n\rightarrow g\)</span> a.e. if and only if <span class="math inline">\(f=g\)</span> a.e.</p>
<p>The following two examples show that convergence in norm and convergence almost everywhere are essentially different.</p>
<p>==Example 2.7.1==</p>
<p>For <span class="math inline">\(n=1,2,\dotsm\)</span>, define <span class="math display">\[
f_n(x)=\begin{cases}1/\sqrt n &amp; \text{for $x\in[-n,n]$}\\0&amp;\text{otherwise}\end{cases}
\]</span> ==Theorem 2.7.5==</p>
<p>Let <span class="math inline">\(f_1,f_2,\dotsm\in L^1(R)\)</span> and <span class="math inline">\(\int |f_1|+\int |f_2|+\dotsm&lt;\infty\)</span> . Then the series <span class="math inline">\(f_1+f_2+\dotsm\)</span> converges almost everywhere.</p>
<p>==Corollary 2.7.1==</p>
<p>If <span class="math inline">\(f\simeq f_1+f_2+\dotsm\)</span>, then <span class="math inline">\(f=f_1+f_2+\dotsm\)</span> a.e.</p>
<p>==Theorem 2.7.6==</p>
<p>Let <span class="math inline">\(f_1,f_2,\dotsm\in L^1(R)\)</span> and <span class="math inline">\(\int |f_1|+\int |f_2|+\dotsm&lt;\infty\)</span>. Then <span class="math inline">\(f=f_1+f_2+\dotsm\)</span> almost everywhere if and only if <span class="math inline">\(f=f_1+f_2+\dotsm\)</span> in norm.</p>
<h2 id="fundamental-theorems">2.8 Fundamental Theorems</h2>
<p>Now we are ready to prove the main theorems of this chapter.</p>
<p>==Theorem 2.8.1==</p>
<p>The space <span class="math inline">\(L^1(R)\)</span> is complete.</p>
<p>In view of the above theorem, the space <span class="math inline">\(L^1(R)\)</span> can be defined as the completion of the space of step functions with respect to the convergence in norm.</p>
<p>We know that convergence in norm and convergence almost everywhere are essentially different. The next theorem connects both convergences in an elegant way.</p>
<p>==Theorem 2.8.2==</p>
<p>If <span class="math inline">\(f_n\rightarrow f\)</span> i.n., then there exists a subsequence <span class="math inline">\((f_{p_n})\)</span> of <span class="math inline">\((f_n)\)</span> such that <span class="math inline">\(f_{p_n} \rightarrow f_n\)</span> a.e.</p>
<p>Convergence in norm has the following important property, <span class="math display">\[
f_n\rightarrow f\text{ i.n. implies } \int f_n\rightarrow \int f
\]</span> In other words, the limit with respect to the convergence in norm can be interchanged with integration: <span class="math display">\[
\int \lim _{n\rightarrow \infty} f_n = \lim_{n\rightarrow \infty} \int f_n
\]</span> Convergence almost everywhere does not share this property.</p>
<p>Theorem 2.8.3 and Theorem 2.8.4 give conditions which are easy to check and at the same time imply the convergence in norm.</p>
<p>==Theorem 2.8.3== Monotone Convergence Theorem</p>
<p>If <span class="math inline">\((f_n)\)</span> is a monotone sequence of integrable functions and <span class="math inline">\(|\int f_n| \le M\)</span> for some constant M and all <span class="math inline">\(n\in N\)</span>, then there exists an integrable function <span class="math inline">\(f\)</span> such that <span class="math inline">\(f_n\rightarrow f\)</span> i.n. and <span class="math inline">\(f_n\rightarrow f\)</span> a.e. Moreover, we have <span class="math inline">\(|\int f|\le M\)</span></p>
<p>==Theorem 2.8.4== The Lebesgue Dominated Convergence Theorem</p>
<p>If a sequence of integrable functions <span class="math inline">\((f_n)\)</span> converges almost everywhere to a function <span class="math inline">\(f\)</span> and there exists an integrable function <span class="math inline">\(h\)</span> such that <span class="math inline">\(|f_n|\le h\)</span> for every <span class="math inline">\(n\in N\)</span>, then <span class="math inline">\(f\)</span> is integrable and <span class="math inline">\(f_n\rightarrow f\)</span> i.n.</p>
<p>==Theorem 2.8.5== Fatou's Lemma</p>
<p>Let <span class="math inline">\((f_n)\)</span> be nonnegative integrable functions such that <span class="math inline">\(|\int f_n| \le M\)</span> for some constant M and every <span class="math inline">\(n\in N\)</span>. if the sequence <span class="math inline">\((f_n)\)</span> converges almost everywhere to a function <span class="math inline">\(f\)</span>, then <span class="math inline">\(f\)</span> is integrable and <span class="math inline">\(\int f \le M\)</span></p>
<h2 id="locally-integrable-functions">2.9 Locally Integrable Functions</h2>
<p>The integral <span class="math inline">\(\int f\)</span> corresponds to the integration over the entire real line, so the symbols <span class="math inline">\(\int ^\infty_{-\infty}\)</span> or <span class="math inline">\(\int _R\)</span> could be used instead. In applications we often need to integrate functions over bounded intervals. This concept can be easily defined using the integral <span class="math inline">\(\int f\)</span></p>
<p>==Definition 2.9.1== Integral over an interval</p>
<p>By the integral of a function <span class="math inline">\(f\)</span> over an interval <span class="math inline">\([a,b]\)</span>, denoted by <span class="math inline">\(\int_a^b f\)</span>, we mean the value of the integral <span class="math inline">\(\int f \mathcal X_{[a,b]}\)</span>, where <span class="math inline">\(\mathcal X_{[a,b]}\)</span> denotes the characteristic function of <span class="math inline">\([a,b]\)</span> and <span class="math inline">\(f\mathcal X_{[a,b]}\)</span> is the product of <span class="math inline">\(f\)</span> and <span class="math inline">\(\mathcal X_{[a,b]}\)</span></p>
<p>In proofs, it is often more convenient to use <span class="math inline">\(\mathcal X_{[a,b)}\)</span> instead of <span class="math inline">\(\mathcal X_{[a,b]}\)</span></p>
<p>==Theorem 2.9.1==</p>
<p>If <span class="math inline">\(f\in L^1(R)\)</span>, then for every interval <span class="math inline">\([a,b]\)</span> the integral <span class="math inline">\(\int _a^b f\)</span> exists.</p>
<p>==Definition 2.9.2== Locally integrable functions</p>
<p>A function <span class="math inline">\(f\)</span> on R is called locally integrable if for <strong>every</strong> <span class="math inline">\(-\infty&lt;a&lt;b&lt;\infty\)</span> the integral <span class="math inline">\(\int _a^b f\)</span> exists.</p>
<p>It is sufficient to check that the integral <span class="math inline">\(\int_{-n}^n f\)</span> exists for every <span class="math inline">\(n\in N\)</span>. The absolute value of a locally integrable functions is locally integrable. However, the product of integrable functions need not be integrable.</p>
<p>==Theorem 2.9.2==</p>
<p>Let <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> be locally integrable functions. If <span class="math inline">\(g\)</span> is bounded on <span class="math inline">\([a,b]\)</span> for every <span class="math inline">\(-\infty&lt;a&lt;b&lt;\infty\)</span>, then the product <span class="math inline">\(fg\)</span> is locally integrable functions.</p>
<p>==Theorem 2.9.3==</p>
<p>If <span class="math inline">\(f\)</span> is locally integrable function such that <span class="math inline">\(|f|\le g\)</span> for some <span class="math inline">\(g\in L^1(R)\)</span>, then <span class="math inline">\(f\in L^1(R)\)</span></p>
<h2 id="the-lebesgue-integral-and-the-riemann-integral">2.10 The Lebesgue Integral and the Riemann Integral</h2>
<p>In this section we are going to prove that Riemann integrable functions are Lebesgue integrable. Then we will prove some theorems which show that useful properties of the Riemann integral are not lost when the more general Lebesgue integral is considered.</p>
<p>==Theorem 2.10.1== A Riemann integrable function is Lebesgue integrable and the integrals are equal.</p>
<p>==Theorem 2.10.2== Let <span class="math inline">\(f\)</span> be a Lebesgue integral function on a bounded or unbounded interval <span class="math inline">\((a,b)\)</span> and Let <span class="math inline">\(a\le c\le b\)</span>. Then the function <span class="math inline">\(F(x)=\int ^x _c f\)</span> is continuous in <span class="math inline">\((a,b)\)</span> and the limits <span class="math display">\[
F(a)=\lim_{x\rightarrow a+} F(x)\quad F(b)=\lim_{x\rightarrow b-} F(x)
\]</span> ==Theorem 2.10.3== Let <span class="math inline">\(f\)</span> be a function integrable over <span class="math inline">\((a,b)\)</span> and let <span class="math inline">\(F(x)=\int _c^x f\)</span> where $c(a,b) $. If <span class="math inline">\(f\)</span> is continuous at a point <span class="math inline">\(x_0 \in (a,b)\)</span>, then F is differentiable at <span class="math inline">\(x_0\)</span> and we have <span class="math inline">\(F&#39;(x_0)=f(x_0)\)</span>.</p>
<p>The following theorem establishes the same change of variables formula for the Lebesgue integral as for the Riemann integral. The theorem is only a special case of a more general theorem on the change of variables for the Lebesgue integral, but it is sufficient for most applications.</p>
<p>==Theorem 2.10.4== Change of variables</p>
<p>Let <span class="math inline">\(g\)</span> be a non-decreasing differentiable function defined on a bounded or unbounded interval <span class="math inline">\((a,b)\)</span> such that <span class="math inline">\(g&#39;\)</span> is integrable over <span class="math inline">\((a,b)\)</span>. Denote by <span class="math inline">\(g(a)\)</span> and <span class="math inline">\(g(b)\)</span> the limits of <span class="math inline">\(g\)</span> at <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> respectively, i.e. <span class="math inline">\(g(a)=\lim_{x\rightarrow a+} g(x)\)</span> and <span class="math inline">\(g(b)=\lim_{x\rightarrow b-} g(x)\)</span>. If <span class="math inline">\(f\)</span> is an integrable function <span class="math inline">\((g(a),g(b))\)</span>, then the product <span class="math inline">\(f(g(t))g&#39;(t)\)</span> is integrable over <span class="math inline">\((a,b)\)</span> and <span class="math display">\[
\int _{g(a)}^{g(b)} f(t)dt=\int_a^b f(g(t))g&#39;(t)dt
\]</span></p>
<h2 id="lebesgue-measure-on-r">2.11 Lebesgue Measure on R</h2>
<p>Our presentation of the Lebesgue integral does not require the concept of measure. On the other hand, once the integral is defined, we can easily define measurable set and Lebesgue measure.</p>
<p>Lebesgue measure is an extension of the concept of length of an interval onto a large class of sets.</p>
<p>==Definition 2.11.1== Measurable sets</p>
<p>A set S is called measurable if the characteristic function of S is locally integrable function.</p>
<p>To every measurable set, we assign a non-negative number or infinity which is called the measure of that set.</p>
<p>==Definition 2.11.2== Measure</p>
<p>Let S be a measurable set. If the characteristic function $X_S $ is an integrable function, then by the measure of S, denoted by <span class="math inline">\(\mu(S)\)</span>, we mean the value of the integral <span class="math inline">\(\mu(S)=\int \mathcal X_S\)</span>. If <span class="math inline">\(\mathcal X_S\)</span> is not integrable, then we define <span class="math inline">\(\mu(S)=\infty\)</span>.</p>
<p>==Null sets== are sets whose measure is 0. The following theorem gives a useful tool for proving that a set is a null set.</p>
<p>==Theorem 2.11.1==</p>
<p>Let <span class="math inline">\(S\subseteq R\)</span> be such that for every <span class="math inline">\(\epsilon &gt;0\)</span> there exist intervals <span class="math inline">\([a_1,b_1),[a_2,b_2),\dotsm\)</span> such that <span class="math display">\[
S\subseteq \bigcup_{n=1}^\infty [a_n,b_n)\\
\sum_{n=1}^\infty (b_n-a_n)&lt;\epsilon
\]</span> Then S is a null set.</p>
<p>The property of the measure proven in the next theorem is called <span class="math inline">\(\sigma-\)</span>additivity of the measure. It is one of the most fundamental properties of the measure.</p>
<p>==Theorem 2.11.2== Let <span class="math inline">\(S_1, S_2,\dotsm\)</span> be a sequence of disjoint measurable sets. Then the union <span class="math inline">\(S=\bigcup_{n=1}^\infty S_n\)</span> is measurable and we have <span class="math display">\[
\mu(S)=\sum_{n=1}^\infty \mu(S_n)
\]</span> In section 2.9, we defined the integral <span class="math inline">\(\int _a^b f\)</span> which corresponds to the integral over interval <span class="math inline">\([a,b]\)</span>. In a similar way we can define the integral over any measurable set <span class="math inline">\(\Omega\)</span>. <span class="math display">\[
\int _{\Omega}=\int f \mathcal X_{\Omega}
\]</span> If <span class="math inline">\(f\)</span> is a measurable function, then <span class="math inline">\(|f|\in L^1(R)\)</span> implies <span class="math inline">\(f\in L^1(R)\)</span></p>
<p>==Definition 2.11.3== Measurable functions</p>
<p>A <span class="math inline">\(f\)</span> is called measurable if there exists a sequence of step functions <span class="math inline">\(f_1,f_2,\dotsm\)</span> such that <span class="math inline">\(f_n\rightarrow f\)</span> a.e.</p>
<p>Obviously, every integrable function is measurable and every locally integrable function is measurable.</p>
<p>==Theorem 2.11.3== The measurable functions form a vector space. The absolute value of a measurable function is a measurable function. The product of measurable functions is a measurable function.</p>
<p>==Theorem 2.11.4==</p>
<p>If <span class="math inline">\(f\)</span> is a measurable function and <span class="math inline">\(|f|\le g\)</span> for some locally integrable function <span class="math inline">\(g\)</span>, then <span class="math inline">\(f\)</span> is locally integrable.</p>
<h2 id="complex-valued-lebesgue-integrable-functions">2.12 Complex-valued Lebesgue Integrable Functions</h2>
<p>In this section, we extend the definition of Lebesgue integrable functions to include also functions with complex values. First we define a complex valued step function: <span class="math inline">\(f\)</span> is a ==complex-valued step function== if there exist complex number <span class="math inline">\(\lambda_1, \dotsm, \lambda_n\)</span> and intervals <span class="math inline">\([a_1,b_1),\dotsm,[a_n,b_n)\)</span> such that <span class="math display">\[
f(x)=\lambda_1 \mathcal X_{[a_1,b_1)}+\dotsm+\lambda_n \mathcal X_{[a_n,b_n)}
\]</span> where <span class="math inline">\(\mathcal X_{[a_k,b_k)}\)</span> is the characteristic function of <span class="math inline">\([a_k,b_k)\)</span>, <span class="math inline">\(k=1,2,\dotsm\)</span>. The integral <span class="math inline">\(\int f\)</span> of the step function is defined by <span class="math display">\[
\int f=\lambda_1(b_1-a_1)+\dotsm+\lambda_n(b_n-a_n)
\]</span> ==Definition 2.12.1== Lebesgue Integral for complex-valued functions</p>
<p>A complex-valued function <span class="math inline">\(f\)</span> is integrable if there exists a sequence of step functions <span class="math inline">\((f_n)\)</span> such that the following two conditions are satisfied,</p>
<ol type="a">
<li><p><span class="math inline">\(\sum_{n=1}^\infty \int |f_n|&lt;\infty\)</span></p></li>
<li><p><span class="math inline">\(f(x)=\sum_{n=1}^\infty f_n(x)\)</span> for every <span class="math inline">\(x \in R\)</span> such that <span class="math inline">\(\sum_{n=1}^\infty |f_n(x)|&lt;\infty\)</span></p></li>
</ol>
<p>The integral of <span class="math inline">\(f\)</span> is defined by <span class="math display">\[
\int f=\sum_{n=1}^\infty \int f_n
\]</span> If a function <span class="math inline">\(f\)</span> and a sequence of step functions <span class="math inline">\((f_n)\)</span> satisfy (a) and (b), then we write as before <span class="math display">\[
f\simeq \sum_{n=1}^\infty f_n\quad or \quad f\simeq f_1+f_2+\dotsm
\]</span> ==Theorem 2.12.1==</p>
<p>A complex-valued function <span class="math inline">\(f\)</span> is integrable if and only if its real part <span class="math inline">\(\real f\)</span> and its imaginary part <span class="math inline">\(\Im f\)</span> are integrable. Moreover, if <span class="math inline">\(f\)</span> is integrable, then <span class="math display">\[
\int f=\int \Re f+i\int \Im f
\]</span> ==Theorem 2.12.2==</p>
<p>If a complex-valued function <span class="math inline">\(f\)</span> is integrable, then the real-valued function <span class="math inline">\(|f|\)</span> is integrable and <span class="math inline">\(|\int f |\le \int |f|\)</span></p>
<p>==Definition 2.12.2== Locally integrable complex-valued functions</p>
<p>A complex-valued function defined on R is called locally integrable if its real part and imaginary part are locally integrable.</p>
<p>==Theorem 2.12.3==</p>
<p>The absolute value <span class="math inline">\(|f|\)</span> of a locally integrable complex-valued function <span class="math inline">\(f\)</span> is locally integrable.</p>
<h2 id="the-space-l2r">2.13 The space <span class="math inline">\(L^2(R)\)</span></h2>
<p>==Definition 2.13.1== Square Integrable Function</p>
<p>The space of all complex-valued locally integrable functions <span class="math inline">\(f\)</span> such that <span class="math inline">\(|f|^2 \in L^1(R)\)</span> will be denoted by <span class="math inline">\(L^2(R)\)</span>. Elements of <span class="math inline">\(L^2(R)\)</span> will be called square integrable functions.</p>
<p>==Theorem 2.13.1== <span class="math inline">\(L^2(R)\)</span> is a vector space</p>
<p>==Corollary 2.13.1== The product of two square integrable functions is an integrable function. i.e. if <span class="math inline">\(f,g \in L^2(R)\)</span>, then <span class="math inline">\(fg \in L^1(R)\)</span></p>
<p>It will be proved in chapter 3 that <span class="math inline">\(L^2(R)\)</span> is a complete normed space with norm defined by <span class="math display">\[
||f||=\sqrt{\int |f|^2}
\]</span></p>
<h2 id="the-space-l1rn-and-l2rn">2.14 The space <span class="math inline">\(L^1(R^N)\)</span> and <span class="math inline">\(L^2(R^N)\)</span></h2>
<p>By a semi-open interval in <span class="math inline">\(R^N\)</span>, we mean a set <span class="math inline">\(I\)</span> which can be represented as <span class="math display">\[
I=[a_1,b_1)\times\dotsm\times[a_N,b_N)
\]</span> define <span class="math inline">\(m(I)=(b_1-a_1)\dotsm(b_N-a_N)\)</span></p>
<p>By a step function we mean a finite linear combination of characteristic functions of semi-open intervals <span class="math display">\[
f=\lambda_1\mathcal X_{I_1}+\dotsm+\lambda_1\mathcal X_{I_N}
\]</span> For a step function, define <span class="math display">\[
\int f = \lambda_1m(I_1)+\dotsm+\lambda_Nm(I_N)
\]</span> ==Definition 2.14.1== Lebesgue Integrable functions on <span class="math inline">\(R^N\)</span></p>
<p>A real- or complex-valued function <span class="math inline">\(f\)</span> defined on <span class="math inline">\(R^N\)</span> is called Lebesgue integrable if there exists a sequence of step functions <span class="math inline">\((f_n)\)</span> such that the following two conditions are satisfied,</p>
<ol type="a">
<li><p><span class="math inline">\(\sum_{n=1}^\infty \int |f_n|&lt;\infty\)</span></p></li>
<li><p><span class="math inline">\(f(x)=\sum_{n=1}^\infty f_n(x)\)</span> for every <span class="math inline">\(x \in R^N\)</span> such that <span class="math inline">\(\sum_{n=1}^\infty |f_n(x)|&lt;\infty\)</span></p></li>
</ol>
<p>The integral of <span class="math inline">\(f\)</span> is then denoted by <span class="math display">\[
\int f=\sum_{n=1}^\infty \int f_n
\]</span> The space of all Lebesgue integrable functions on <span class="math inline">\(R^N\)</span> is denoted by <span class="math inline">\(L^1(R^N)\)</span></p>
<p>==Definition 2.14.2== (Locally integrable functions on <span class="math inline">\(R^N\)</span>)</p>
<p>A function <span class="math inline">\(f\)</span> defined on <span class="math inline">\(R^N\)</span> is called locally integrable if for every bounded interval <span class="math inline">\(I\)</span> the product <span class="math inline">\(f\mathcal X_I\)</span> is an integrable function.</p>
<p>The Lebesgue measure on <span class="math inline">\(R^N\)</span> can be defined as in section 2.11: A set <span class="math inline">\(S\subseteq R^N\)</span> is called measurable if the characteristic function of <span class="math inline">\(S\)</span> is a locally integrable function. If the characteristic function <span class="math inline">\(\mathcal X_S\)</span> is integrable, then by the measure of <span class="math inline">\(S\)</span>, denoted by <span class="math inline">\(\mu(S)\)</span>, we mean the value of the integral <span class="math inline">\(\mu(S)=\int \mathcal X_S\)</span>. If <span class="math inline">\(\mathcal X_S\)</span> is locally integrable but not integrable, then we define <span class="math inline">\(\mu(S)=\infty\)</span>.</p>
<p>==Definition 2.14.3== (Square integrable functions on <span class="math inline">\(R^N\)</span>)</p>
<p>A complex-valued, locally integrable function <span class="math inline">\(f\)</span> defined on <span class="math inline">\(R^N\)</span> such that <span class="math inline">\(|f|^2\)</span> is integrable is called square integrable. The space of square integrable functions on <span class="math inline">\(R^N\)</span> is denoted by <span class="math inline">\(L^2(R^N)\)</span>.</p>
<h2 id="convolution">2.15 Convolution</h2>
<p>If the integral <span class="math inline">\(\int f(x-y) g(y)dy\)</span> exists for all <span class="math inline">\(x\in R\)</span>, or at least almost everywhere, then it defines a function which is called the convolution of <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span>, denoted by <span class="math inline">\(f*g\)</span>.</p>
<p>==Theorem 2.15.1==</p>
<p>If <span class="math inline">\(f,g \in L^1(R)\)</span>, then the function <span class="math inline">\(f(x-y)g(y)\)</span> is integrable for almost all <span class="math inline">\(x\in R\)</span>. Moreover, the convolution <span class="math display">\[
(f*g)(x)=\int f(x-y)g(y)dy
\]</span> is an integrable function and we have <span class="math display">\[
\int |f*g|\le \int |f|\int |g|
\]</span> ==Theorem 2.15.2==</p>
<p>If <span class="math inline">\(f,g \in L^1(R)\)</span>, then <span class="math inline">\(f*g=g*f\)</span></p>
<p>==Theorem 2.15.3==</p>
<p>If <span class="math inline">\(f\)</span> is an integrable function g is bounded, locally integrable function, then the convolution <span class="math inline">\(f*g\)</span> is a continuous function.</p>
<p>Hilbert Spaces and Orthonormal Systems</p>
<h2 id="introduction-2">3.1 Introduction</h2>
<p>This chapter is concerned with inner product space and Hilbert Spaces. The basic ideas and properties will be discussed with special attention given to orthonormal systems.</p>
<h2 id="inner-product-spaces-definition-and-examples">3.2 Inner Product Spaces-Definition and Examples</h2>
<p>==Definition 3.2.1== Inner product space</p>
<p>Let E be a complex vector space. A mapping <span class="math inline">\(\langle \cdot,\cdot\rangle:E\times E\rightarrow C\)</span> is called an inner product in E if for any <span class="math inline">\(x,y,z\in E\)</span> and <span class="math inline">\(\alpha,\beta \in C\)</span> the following conditions are satisfied,</p>
<ol type="a">
<li><p><span class="math inline">\(\langle x,y\rangle=\overline {\langle y,x\rangle}\)</span></p></li>
<li><p><span class="math inline">\(&lt;\alpha x+\beta y,z&gt;=\alpha&lt;x,z&gt;+\beta&lt;y,z&gt;\)</span></p></li>
<li><p><span class="math inline">\(&lt;x,x&gt;\ge 0\)</span> and <span class="math inline">\(&lt;x,x&gt;=0\implies x=0\)</span></p></li>
</ol>
<p>A vector space with an inner product is called a inner product space or pre-Hilbert space.</p>
<p>According to the definition, we know that the inner product of two vectors is a complex number.</p>
<p>An inner product is the generalization of the dot product.</p>
<p>==Example 3.2.1==</p>
<p>The simplest example is an inner product of complex number C. The inner product is defined as <span class="math display">\[
\def \norm &lt;#1,#2&gt;{\langle#1,#2\rangle}
\norm&lt;x,y&gt;=x\bar y
\]</span> ==Example 3.2.2==</p>
<p>The space <span class="math inline">\(C^N\)</span> of ordered N-tuples <span class="math inline">\(x=(x_1,x_2,\dotsm,x_N)\)</span> of complex numbers, with the inner product defined by <span class="math display">\[
\norm&lt;x,y&gt;=\sum_{k=1}^N x_k \bar y_k
\]</span> ==Example 3.2.3==</p>
<p>The space <span class="math inline">\(l^2\)</span> of all sequences <span class="math inline">\((x_1,x_2,\dotsm)\)</span> of complex numbers such that <span class="math inline">\(\sum_{k=1}^\infty |x_k|^2&lt;\infty\)</span> with the inner product defined by <span class="math display">\[
\norm&lt;x,y&gt;=\sum_{k=1}^\infty x_k\bar y_k
\]</span> is an infinite dimensional inner product space.</p>
<p>==Example 3.2.4==</p>
<p>Consider the space of sequences <span class="math inline">\((x_1,x_2,\dotsm)\)</span> of complex number with only finite number of items is non-zero. This is an inner product space with the inner product defined as in Example 3.2.3.</p>
<p>==Example 3.2.5==</p>
<p>The space <span class="math inline">\(\mathscr C([a,b])\)</span> of all continuous complex-valued functions on the interval [a,b], with the inner product <span class="math display">\[
\norm&lt;f,g&gt;=\int _a^b f(x)\overline{g(x)} dx
\]</span> is an inner product space.</p>
<p>==Example 3.2.6==</p>
<p>The space <span class="math inline">\(L^2(R)\)</span> with the inner product defined by <span class="math display">\[
\int _{-\infty} ^\infty f(x)\overline{g(x)} dx
\]</span> and more generally, the space <span class="math inline">\(L^2(R^N)\)</span> with the inner product defined by <span class="math display">\[
\int _{R^N} f(x)\overline{g(x)} dx
\]</span> are inner product space.</p>
<p>==Example 3.2.7==</p>
<p>Let E be the Cartesian product of inner product spaces <span class="math inline">\(E_1\)</span> and <span class="math inline">\(E_2\)</span>, i.e. <span class="math inline">\(E=E_1\times E_2\)</span>.</p>
<p>The space E is an inner product space with the inner product defined by <span class="math display">\[
\norm&lt;(x_1,y_1),(x_2,y_2)&gt; = \norm&lt;x_1,x_2&gt;+\norm&lt;y_1,y_2&gt;
\]</span></p>
<h2 id="norm-in-an-inner-product-space">3.3 Norm in an inner product space</h2>
<p>An inner product space is a vector space with an inner product. It turns out that every inner product space is also a normed space with the norm defined by <span class="math display">\[
||x||=\sqrt{\norm&lt;x,x&gt;}
\]</span> ==Definition 3.3.1== (Norm in an Inner Product Space)</p>
<p>By the norm in an inner product space E, we mean the functional defined by <span class="math inline">\(||x||=\sqrt{\norm&lt;x,x&gt;}\)</span></p>
<p>We have proved that every inner product space is a normed space. But it is <strong>not true</strong> that any normed space is an inner product space. In the following theorem, we prove a property of a norm in an inner product space which is a necessary and sufficient condition for a normed space to be an inner product space.</p>
<p>==Theorem 3.3.2== Parallelogram Law</p>
<p>For any two elements <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> of an inner product space we have <span class="math display">\[
||x+y||^2+||x-y||^2=2(||x||^2+||y||^2)
\]</span> One of the most important consequences of having the inner product is the possibility of defining <strong>orthogonality</strong> of vectors. This makes the theory of Hilbert spaces very different from the general theory of Banach spaces.</p>
<p>==Definition 3.3.2== Orthogonal vectors</p>
<p>Two vectors <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> in an inner product space are called orthogonal, denoted by <span class="math inline">\(x\perp y\)</span> if <span class="math inline">\(\norm&lt;x,y&gt;=0\)</span>.</p>
<p>==Theorem 3.3.3== Pythagorean Formula</p>
<p>For any pair of orthogonal vectors we have <span class="math display">\[
||x+y||^2=||x||^2+||y||^2
\]</span></p>
<h2 id="hilbert-spaces-definition-and-examples">3.4 Hilbert Spaces-Definition and Examples</h2>
<p>==Definition 3.4.1== Hilbert space</p>
<p>A complete inner product space is called a Hilbert space.</p>
<p>By the completeness of an inner product space E, we mean the completeness of E as a ==normed space==.</p>
<p>Now we are going to discuss completeness of the inner product spaces and give some new examples.</p>
<p>==Example 3.4.1==</p>
<p>Since C is complete, it is a Hilbert space.</p>
<p>==Example 3.4.2==</p>
<p><span class="math inline">\(C^N\)</span> is Hilbert space.</p>
<p>==Example 3.4.3==</p>
<p><span class="math inline">\(l^2\)</span> is a Hilbert space.</p>
<p>==Example 3.4.4==</p>
<p>The space described in Example 3.2.4 is ==not== Hilbert space.</p>
<p>==Example 3.4.5==</p>
<p><span class="math inline">\(\mathscr C([a,b])\)</span> is ==not== Hilbert space.</p>
<p>==Example 3.4.6==</p>
<p>The space <span class="math inline">\(L^2([a,b])\)</span> is a Hilbert space.</p>
<p>==Example 3.4.7==</p>
<p>The space <span class="math inline">\(L^2(R)\)</span> is a Hilbert space.</p>
<h2 id="strong-and-weak-convergence">3.5 Strong and Weak Convergence</h2>
<p>Since every inner product is a normed , it is equipped with a convergence, namely the convergence defined by the norm. This convergence is called strong convergence.</p>
<p>==Definition 3.5.1== Strong convergence</p>
<p>A sequence <span class="math inline">\((x_n)\)</span> of vectors in an inner product space <span class="math inline">\(E\)</span> is called strongly convergent to a vector <span class="math inline">\(x\)</span> in E if <span class="math inline">\(||x_n-x||\rightarrow 0\)</span> as <span class="math inline">\(n\rightarrow 0\)</span>.</p>
<p>==Definition 3.5.2== Weak convergence</p>
<p>A sequence <span class="math inline">\((x_n)\)</span> of vectors in an inner product space <span class="math inline">\(E\)</span> is called weakly convergent to a vector <span class="math inline">\(x\)</span> in E if <span class="math inline">\(\norm&lt;x_n,y&gt;\rightarrow \norm&lt;x,y&gt;\)</span> as <span class="math inline">\(n\rightarrow 0\)</span>.</p>
<p>It will be convenient to reserve the notation <span class="math inline">\(x_n\rightarrow x\)</span> for the strong convergent and use <span class="math inline">\(x_n\overset{w}{\rightarrow} x\)</span> for weakly convergent.</p>
<p>==Theorem 3.5.1==</p>
<p>A strongly convergent sequence is weakly convergent.</p>
<p>==Theorem 3.5.2==</p>
<p>If <span class="math inline">\(x_n\overset{w}{\rightarrow} x\)</span> and <span class="math inline">\(||x_n||\rightarrow ||x||\)</span>, then <span class="math inline">\(x_n\rightarrow x\)</span></p>
<p>==Theorem 3.5.3==</p>
<p>Let <span class="math inline">\(S\)</span> be a subset of an inner product space <span class="math inline">\(E\)</span> such that span S is dense in E. If <span class="math inline">\((x_n)\)</span> is a bounded sequence in E and <span class="math display">\[
\norm&lt;x_n,y&gt;\rightarrow \norm&lt;x,y&gt;\quad \forall y\in S
\]</span> then <span class="math inline">\(x_n\overset{w}{\rightarrow} x\)</span>.</p>
<p>==Theorem 3.5.4==</p>
<p>Weakly convergent sequences in a <strong>Hilbert Space</strong> are bounded. i.e. if <span class="math inline">\((x_n)\)</span> is a weakly convergent sequence, then there exists a number M such that <span class="math inline">\(||x_n||\le M\)</span> for all <span class="math inline">\(n\in N\)</span>.</p>
<h2 id="orthogonal-and-orthonormal-system">3.6 Orthogonal and Orthonormal system</h2>
<p>By a basis of a vector space E, we mean a linearly independent family <span class="math inline">\(\mathscr B\)</span> of vectors from E such that any vector <span class="math inline">\(x\in E\)</span> can be written as <span class="math inline">\(x=\sum_{n=1}^m \lambda_nx_n\)</span> where <span class="math inline">\(x_n\in \mathscr B\)</span> and <span class="math inline">\(\lambda_n\)</span>’s are scalars. In the inner product space, orthonormal bases are of much greater importance. Instead of finite combinations <span class="math inline">\(\sum_{n=1}^m \lambda_nx_n\)</span>, infinite sums are allowed and the ==condition of linear independence== is replaced by orthogonality.</p>
<p>==Definition 3.6.1== (Orthogonal and Orthonormal systems)</p>
<p>Let E be an inner product space. A family S of non-zero vectors in E is called an orthogonal system if <span class="math inline">\(x\perp y\)</span> for any two distinct elements of S. If, in addition, <span class="math inline">\(||x||=1\)</span> for all <span class="math inline">\(x\in S\)</span>, then S is called an orthonormal system.</p>
<p>Every orthogonal set of non-zero vectors can be normalized. If S is an orthogonal system, then the family <span class="math display">\[
S_1=\{\frac{x}{||x||}:x\in S\} 
\]</span> is an orthonormal system.</p>
<p>==Theorem 3.6.1==</p>
<p>Orthogonal systems are linearly independent.</p>
<p>==Definition 3.6.2== (Orthonormal sequence)</p>
<p>A sequence of vectors which constitute an orthonormal system is called an orthonormal sequence.</p>
<p>The condition of orthogonality of a sequence <span class="math inline">\((x_n)\)</span> can be expressed in terms of the Kronecker delta symbol <span class="math display">\[
&lt;x_m,x_n&gt;=\delta_{mn}=\begin{cases}0&amp;m\neq n\\1&amp;m=n\end{cases}
\]</span> ==Example 3.6.1==</p>
<h2 id="properties-of-orthonormal-systems">3.7 Properties of Orthonormal systems</h2>
<p>In section 3.3, we proved that Pythagorean formula holds for any pair of orthogonal vectors in an inner product space. It turns out that it can be generalized to any finite number of orthogonal vectors.</p>
<p>==Theorem 3.7.1== (Pythagorean formula)</p>
<p>If <span class="math inline">\(x_1,\dotsm,x_n\)</span> are orthogonal vectors in an inner product space, then <span class="math display">\[
||\sum_{k=1}^nx_k||^2=\sum_{k=1}^n||x_k||^2
\]</span> ==Theorem 3.7.2== Bessel’s equality and inequality</p>
<p>Let <span class="math inline">\(x_1,\dotsm,x_n\)</span> be an orthonormal set of vectors in an inner product space E. Then, for every <span class="math inline">\(x\in E\)</span>, we have <span class="math display">\[
\left|\left|x-\sum_{k=1}^n &lt;x,x_k&gt;x_k\right|\right|^2=||x||^2-\sum_{k=1}^n|&lt;x,x_k&gt;|^2
\]</span> and <span class="math display">\[
\sum_{k=1}^n|&lt;x,x_k&gt;|^2\le ||x||^2
\]</span> Proof.</p>
<p>In view of the Pythagorean Formula, we have <span class="math display">\[
\left|\left|\sum_{k=1}^n\alpha_kx_k\right|\right|^2=\sum_{k=1}^n|\alpha_k|^2
\]</span> Then <span class="math display">\[
\left|\left|x-\sum_{k=1}^n\alpha_kx_k\right|\right|^2\\
=\left\langle x-\sum_{k=1}^n\alpha_kx_k,x-\sum_{k=1}^n\alpha_kx_k \right\rangle\\
=||x||^2
-\sum_{k=1}^n\bar \alpha_k\left\langle x,x_k\right\rangle
-\sum_{k=1}^n\alpha_k\overline{\left\langle x,x_k \right\rangle}
+\sum_{k=1}^n|\alpha_k|^2||x_k||^2\\
=||x||^2-\sum_{k=1}^n|&lt;x,x_k&gt;|^2+\sum_{k=1}^n |&lt;x,x_k&gt;-\alpha_k|^2
\]</span> Then let <span class="math inline">\(\alpha_k=&lt;x,x_k&gt;\)</span>, Q.E.D.</p>
<ol type="1">
<li><p>This choice of <span class="math inline">\(\alpha_k\)</span>’s minimizes <span class="math inline">\(||x-\sum_{k=1}^n\alpha_kx_k||\)</span> and thus it provides the best approximation of <span class="math inline">\(x\)</span> by a linear combination of vectors <span class="math inline">\(x_1,x_2,\dotsm,x_n\)</span>.</p></li>
<li><p>If <span class="math inline">\((x_n)\)</span> is an orthonormal sequence of vectors in an inner product space E, then we have <span class="math display">\[
\sum_{n=1}^\infty |&lt;x,x_k&gt;|^2\le ||x||^2
\]</span> This shows that the series <span class="math inline">\(\sum_{k=1}^\infty |&lt;x,x_k&gt;|^2\)</span> converges for every <span class="math inline">\(x\in E\)</span>.</p>
<p>In another words, the sequence <span class="math inline">\((&lt;x,x_n&gt;)\)</span> is an elements of <span class="math inline">\(l^2\)</span>. We can say that an orthonormal sequence in E induces a mapping from E into <span class="math inline">\(l^2\)</span>. <span class="math display">\[
x\sim \sum_{n=1}^\infty &lt;x,x_n&gt;x_n
\]</span> is called generalized Fourier series of <span class="math inline">\(x\)</span>. In general we do not know whether the series if convergent. However, the next theorem show that the completeness of the space ensures the convergence.</p></li>
</ol>
<p>==Theorem 3.7.3==</p>
<p>Let <span class="math inline">\((x_n)\)</span> be an orthonormal sequence in a Hilbert space H and let <span class="math inline">\((\alpha_n)\)</span> be a sequence of complex numbers. Then the series <span class="math inline">\(\sum_{n=1}^\infty\alpha_n x_n\)</span> converges if and only if $_{n=1}^|_n|^2&lt;$, and in that case <span class="math display">\[
||\sum_{n=1}^\infty \alpha_nx_n||^2=\sum_{n=1}^\infty |\alpha_n|^2
\]</span> The proceeding theorem imply that in a Hilbert space H the series <span class="math inline">\(\sum_{n=1}^\infty &lt;x,x_n&gt;x_n\)</span> converges for every <span class="math inline">\(x\in H\)</span>. However, it can happen that it converges to an element different from <span class="math inline">\(x\)</span>.</p>
<p>==Example 3.7.1==</p>
<p>Let <span class="math inline">\(H=L^2([-\pi,\pi])\)</span> and let <span class="math inline">\(x_n=\frac{1}{\sqrt \pi}\sin nt\)</span> for <span class="math inline">\(n=1,2,\dotsm\)</span>. The sequence <span class="math inline">\((x_n)\)</span> is an orthonormal set in H. On the other hand, for <span class="math inline">\(x(t)=\cos t\)</span>, we have <span class="math display">\[
\sum_{n=1}^\infty &lt;x,x_n&gt;x_n(t)=\sum_{n=1}^\infty [\frac{1}{\sqrt \pi}\int _{-\pi}^\pi \cos t\sin nt dt]\frac{\sin nt}{\sqrt \pi}=0\neq \cos t
\]</span> If <span class="math inline">\((x_n)\)</span> is an orthonormal sequence in an inner product space E, then for every <span class="math inline">\(x\in E\)</span>, we have <span class="math display">\[
\sum_{n=1}^\infty |&lt;x,x_n&gt;|^2&lt;\infty
\]</span> and consequently, <span class="math display">\[
\lim_{n\rightarrow \infty }&lt;x,x_n&gt;=0
\]</span> Therefore, orthonormal sequence are weakly convergent to zero. But <span class="math inline">\(||x_n||=1\)</span>, they are not strongly convergent.</p>
<p>==Definition 3.7.1== (Complete orthonormal sequence)</p>
<p>An orthonormal sequence <span class="math inline">\((x_n)\)</span> in an inner product space E is said to be complete if for every <span class="math inline">\(x\in E\)</span> we have <span class="math display">\[
x=\sum_{n=1}^\infty &lt;x,x_n&gt;x_n
\]</span> ==Definition 3.7.2== (Orthonormal basis)</p>
<p>An orthonormal system B in an inner product space E is called an orthonormal basis if every <span class="math inline">\(x\in E\)</span> has a unique representation <span class="math display">\[
x=\sum_{n=1}^\infty \alpha_nx_n
\]</span> where <span class="math inline">\(\alpha_n \in C\)</span> and <span class="math inline">\(x_n\)</span>’s are distinct elements of B.</p>
<p>==Theorem 3.7.4==</p>
<p>An orthonormal sequence <span class="math inline">\((x_n)\)</span> in a Hilbert space is complete if and only if <span class="math inline">\(&lt;x,x_n&gt;=0\)</span> for all <span class="math inline">\(n\in N\)</span> implies <span class="math inline">\(x=0\)</span></p>
<p>==Theorem 3.7.5== (Parseval’s Formula)</p>
<p>An orthonormal sequence <span class="math inline">\((x_n)\)</span> in a Hilbert space is complete if and only if <span class="math display">\[
||x||^2=\sum_{n=1}^\infty |&lt;x,x_n&gt;|^2
\]</span> for every <span class="math inline">\(x\in H\)</span>.</p>
<h2 id="orthogonal-complements-and-projection-theorem">3.9 Orthogonal Complements and projection theorem</h2>
<p>By a subspace of a Hilbert space, we mean a vector subspace of H. A subspace of a Hilbert space is an inner product space. If we additionally assume that S is a closed subspace of H, then S is a Hilbert space itself, because a closed subspace of complete normed space is complete.</p>
<p>==Definition 3.9.1== Orthogonal Complement</p>
<p>Let S be a non-empty subset of a Hilbert space H. An element <span class="math inline">\(x\in H\)</span> is said to be orthogonal to S, denoted by <span class="math inline">\(x\perp S\)</span>, if <span class="math inline">\(&lt;x,y&gt;=0\)</span> for every <span class="math inline">\(y\in S\)</span>. The set of all elements of H orthogonal to S, denoted by <span class="math inline">\(S^\perp\)</span> is called the orthogonal complement of S. In symbols, <span class="math display">\[
S^\perp =\{x\in H,x\perp S\}
\]</span> The orthogonal complement of <span class="math inline">\(S^\perp\)</span> is denoted by <span class="math inline">\(S^{\perp\perp}\)</span></p>
<p>Two subsets of A and B is said to be orthogonal if <span class="math inline">\(x\perp y\)</span> for every <span class="math inline">\(x\in A\)</span> and <span class="math inline">\(y\in B\)</span>. This is denoted by <span class="math inline">\(A\perp B\)</span>. Note that if <span class="math inline">\(A\perp B\)</span>, then <span class="math inline">\(A\bigcap B=\empty\)</span></p>
<p>==Theorem 3.9.1==</p>
<p>For any subset S of a Hilbert space H, the set <span class="math inline">\(S^\perp\)</span> is a closed subspace of H.</p>
<p>==Definition 3.9.2== (Convex sets)</p>
<p>A set <span class="math inline">\(U\)</span> in a vector space is called convex if for any <span class="math inline">\(x,y \in U\)</span> and <span class="math inline">\(\alpha\in(0,1)\)</span>, we have <span class="math inline">\(\alpha x+(1-\alpha)y \in U\)</span></p>
<p>The following theorem, concerning the minimization of the norm, is of fundamental importance in approximation theory.</p>
<p>==Theorem 3.9.2== (The closet point property)</p>
<p>Let S be a closed convex subset of a Hilbert space H. For every point <span class="math inline">\(x\in H\)</span> there exists a unique point <span class="math inline">\(y\in S\)</span> such that <span class="math display">\[
||x-y||=\inf_{z\in S}||x-z||
\]</span> ==Theorem 3.9.3==</p>
<p>Let S be a closed convex subset of a real Hilbert space H, <span class="math inline">\(y\in S\)</span> and <span class="math inline">\(x\in H\)</span>. Then the following conditions are equivalent.</p>
<ol type="a">
<li><p><span class="math inline">\(||x-y||=\inf_{z\in S}||x-z||\)</span></p></li>
<li><p><span class="math inline">\(&lt;x-y,z-y&gt;\le 0\)</span> for all <span class="math inline">\(z\in S\)</span></p></li>
</ol>
<p>==Theorem 3.9.4== (Orthogonal projection)</p>
<p>If S is a closed subspace of a Hilbert space H, then every element <span class="math inline">\(x\in H\)</span> has a unique decomposition in the form <span class="math inline">\(x=y+z\)</span> where <span class="math inline">\(y\in S\)</span> and <span class="math inline">\(z\in S^\perp\)</span></p>
<p>==Theorem 3.9.5==</p>
<p>If S is a closed subspace of a Hilbert space H, then <span class="math inline">\(S^{\perp\perp}=S\)</span>.</p>
<h2 id="linear-functionals-and-riesz-representation-theorem">3.10 Linear Functionals and Riesz Representation Theorem</h2>
<p>In section 3.5 we have remarked that for any fixed vector <span class="math inline">\(x_0\)</span> in an inner product space E, the formula <span class="math inline">\(f(x)=&lt;x,x_0&gt;\)</span> defines a bounded linear functional on E. It turns out E is a Hilbert space, then every bounded linear functional is of this form.</p>
<p>==Example 3.10.1==</p>
<p>Let <span class="math inline">\(H=L^2((a,b)),-\infty&lt;a&lt;b&lt;\infty\)</span>. Define a linear functional <span class="math inline">\(f\)</span> on <span class="math inline">\(H\)</span> by the formula <span class="math display">\[
f(x)=\int _a^bx(t)dt
\]</span> If <span class="math inline">\(x_0\)</span> denote the constant function 1 on <span class="math inline">\((a,b)\)</span>, then clearly <span class="math inline">\(f(x)=&lt;x,x_0&gt;\)</span> and thus <span class="math inline">\(f\)</span> is a bounded functional.</p>
<p>==Example 3.10.2==</p>
<p>Let <span class="math inline">\(H=L^2((a,b))\)</span> and let <span class="math inline">\(t_0\)</span> to be a fixed point in <span class="math inline">\((a,b)\)</span>. Let <span class="math inline">\(f\)</span> be a functional on H defined by <span class="math inline">\(f(x)=x(t_0)\)</span>. This function is linear but not bounded.</p>
<p>==Lemma 3.10.1==</p>
<p>Let <span class="math inline">\(f\)</span> be a bounded linear functional on an inner product space <span class="math inline">\(E\)</span>. Then dim <span class="math inline">\(\mathcal N(f)^\perp\le 1\)</span>.</p>
<p>==Theorem 3.10.1== (Riesz Representation Theorem)</p>
<p>Let <span class="math inline">\(f\)</span> be a bounded linear functional on a Hilbert space H. There exists one <span class="math inline">\(x_0\in H\)</span> such that <span class="math inline">\(f(x)=&lt;x,x_0&gt;\)</span> for all <span class="math inline">\(x\in H\)</span>. Moreover, we have <span class="math inline">\(||f||=||x_0||\)</span>.</p>
<h2 id="separable-hilbert-space">3.11 Separable Hilbert Space</h2>
<p>==Definition 3.11.1== (Separable Spaces)</p>
<p>A Hilbert space is called separable if it contains a complete orthonormal sequence. Finite dimensional Hilbert space are considered separable.</p>
<p>==Theorem 3.11.1==</p>
<p>Every separable Hilbert Space contains a countable dense subset.</p>
<p>==Theorem 3.11.2==</p>
<p>Every orthogonal set in a separable Hilbert Space is countable.</p>
<p>==Definition 3.11.2== (Hilbert Space Isomorphism)</p>
<p>A Hilbert space <span class="math inline">\(H_1\)</span> is said to be isomorphic to a Hilbert space <span class="math inline">\(H_2\)</span> if there exists a one-to-one linear mapping T from <span class="math inline">\(H_1\)</span> onto <span class="math inline">\(H_2\)</span> such that <span class="math display">\[
&lt;T(x),T(y)&gt;=&lt;x,y&gt;
\]</span> for every <span class="math inline">\(x,y\in H_1\)</span>. Such a mapping is called a Hilbert Space isomorphism of <span class="math inline">\(H_1\)</span> onto <span class="math inline">\(H_2\)</span>.</p>
<p>==Theorem 3.11.3==</p>
<p>Let H be a separable Hilbert space.</p>
<ol type="a">
<li><p>if H is infinite dimensional, then it is isomorphic to <span class="math inline">\(l^2\)</span>.</p></li>
<li><p>If H has a dimension N, then it is isomorphic to <span class="math inline">\(C^N\)</span>.</p></li>
</ol>
<h1 id="linear-operator-on-hilbert-spaces">Linear Operator on Hilbert Spaces</h1>
<h2 id="introduction-3">4.1 Introduction</h2>
<p>The conception of an operator (or transformation) on a normed vector space is a natural generalization of the idea of a function of a real variable. Linear operators on a normed vector space are widely used to represent physical quantities, and hence their importance is further enhanced in applied mathematics and mathematical physics.</p>
<p>The most important operators include <strong>differential, integral, and matrix operators</strong>.</p>
<h2 id="examples-of-operators">4.2 Examples of Operators</h2>
<p>In section 4.1, we discussed some basic properties of linear mappings from a vector space <span class="math inline">\(E_1\)</span> into a vector space <span class="math inline">\(E_2\)</span>. In this chapter, we are interested in the cases when <span class="math inline">\(E_1=E_2=E\)</span> or <span class="math inline">\(E_1\subset E_2=E\)</span>, where <span class="math inline">\(E\)</span> is normed space or inner product space. Here we will not consider nonlinear operator so operator just means the linear operator.</p>
<p>Recall that an operator A is called bounded if there is a number <span class="math inline">\(K\)</span> such that <span class="math inline">\(||Ax||\le K||x\|\)</span> for every <span class="math inline">\(x\)</span> in the domain of A. The norm of A is defined as the least of all numbers K, or equivalently, by <span class="math display">\[
||A||=\sup_{||x||=1}||Ax||
\]</span> In section 1.6, we proved that an operator A is bounded if and only if it is continuous. It is often much more difficult to find the norm of an operator than just prove it is bounded.</p>
<p>==Example 4.2.1== (Identity Operator and Null operator)</p>
<p>The simplest example of an operator is the identity operator <span class="math inline">\(\mathscr I\)</span>, which leaves every element unchanged: <span class="math inline">\(\mathscr Ix=x\quad \forall x\in E\)</span>. The null operator, which assigns the zero vector to every element of E, will be denoted by 0. The two operators are both bounded and we have <span class="math inline">\(||\mathscr I||=1\)</span> and <span class="math inline">\(||0||=0\)</span>. A scalar multiple <span class="math inline">\(\alpha\mathscr I\)</span> of the identity operator is the operator which multiplies every element by the scalar <span class="math inline">\(\alpha\)</span>: <span class="math inline">\((\alpha\mathscr I)x=\alpha x\)</span>.</p>
<p>==Example 4.2.2==</p>
<p>Let A be an operator on <span class="math inline">\(C^N\)</span> and let <span class="math inline">\(\{e_1,\dotsm,e_n\}\)</span> be the standard orthonormal base in <span class="math inline">\(C^N\)</span>, i.e. <span class="math display">\[
e_1=(1,0,\dotsm,0)\\
e_2=(0,1,\dotsm,0)\\
\dotsm\\
e_n=(0,0,\dotsm,1)
\]</span> Define <span class="math inline">\(i,j=\{1,2,\dotsm,N\}\)</span>, <span class="math display">\[
a_{ij}=&lt;Ae_j,e_i&gt;
\]</span> Then for <span class="math inline">\(x=\sum_{j=1}^N \lambda_je_j\in C^N\)</span>, we have <span class="math inline">\(Ax=\sum_{j=1}^N\lambda_jAe_j\)</span>. <span class="math display">\[
&lt;Ax,e_i&gt;=\sum_{j=1}^N\lambda_j&lt;Ae_j,e_i&gt;=\sum_{j=1}^N\lambda_j\alpha_{ij}\\
\]</span> Hence, every operator on the space <span class="math inline">\(C^N\)</span> is defined by a <span class="math inline">\(N\times N\)</span> matrix. Conversely, for every <span class="math inline">\(N\times N\)</span> matrix <span class="math inline">\((\alpha_{ij})\)</span>, it defines an operator on <span class="math inline">\(C^N\)</span>. <span class="math display">\[
||A||\le \sqrt{\sum_{i=1}^N\sum_{j=1}^N |\alpha_{ij}|^2}
\]</span> ==Example 4.2.3== (Differential Operator)</p>
<p>One of the most important operator is the differential operator <span class="math display">\[
(Df)(x)=\frac{df}{dx}(x)=f&#39;(x)
\]</span> defined on a space of differentiable functions.</p>
<p>==Example 4.2.4== (Integral Operator)</p>
<p>Another important kind of operator is an integral operator defined by <span class="math display">\[
(Tx)(s)=\int _a^b K(s,t)x(t)dt
\]</span> where a and b are finite or infinite, <span class="math inline">\(a&lt;b\)</span> and K is a function defined on <span class="math inline">\((a,b)\times (a,b)\)</span>. The function K is called the kernel of the operator. The domain of an integral operator depends on K. If <span class="math display">\[
\int _a^b\int _a^b|K(s,t)|^2dtds&lt;\infty
\]</span> Then T is bounded operator on <span class="math inline">\(L^2([a,b])\)</span> and <span class="math display">\[
||T||\le \sqrt{\int _a^b\int _a^b|K(s,t)|dtds}
\]</span> ==Example 4.2.5== (Multiplication Operator)</p>
<p>Let <span class="math inline">\(z\in \mathscr C([a,b])\)</span>. An operator A on <span class="math inline">\(L^2([a,b])\)</span> defined by <span class="math inline">\((Ax)(t)=z(t)x(t)\)</span> is clearly linear. The function z is called the multiplier.</p>
<p>We have <span class="math display">\[
||Ax||\le \max_{|a,b|}|z(t)|||x||
\]</span> and thus A is bounded.</p>
<p>Two operator on a vector space E is said to be ==equal==, A=B if <span class="math inline">\(Ax=Bx\)</span> for every <span class="math inline">\(x\in E\)</span>.</p>
<p>The set of all operator constitutes a ==vector space== with the addition and multiplication defined by <span class="math display">\[
(A+B)x=Ax+Bx\quad and\quad (\alpha A)x=\alpha(Ax)
\]</span> The product of operator A and B is defined by <span class="math display">\[
(AB)x=A(Bx)
\]</span> Thus, AB denotes the composition of A and B.</p>
<p>The defined operators have the following obvious properties. <span class="math display">\[
A+B=B+A\\
(A+B)+C=A+(B+C)\\
A+0=A\\
\alpha(A+B)=\alpha A+\alpha B\\
(\alpha+\beta) A=\alpha A+\beta A\\
A0=0\\
A(BC)=(AB)C\\
(A+B)C=AC+BC\\
A\mathscr J=\mathscr JA
\]</span> In general, <span class="math inline">\(AB\)</span> need not equal BA. Operators A and B for which <span class="math inline">\(AB=BA\)</span> are called commuting operators.</p>
<p>==Example 4.2.6== (Noncommuting Operators)</p>
<p>Consider the space of differential functions on R and the operators <span class="math display">\[
Af(x)=xf(x)\quad D=\frac{d}{dx}\\
AD\neq DA
\]</span> The ==square== of an operator A is defined as <span class="math inline">\(A^2x=A(Ax)\)</span>. By induction, we can define <span class="math display">\[
A^nx=A(A^{n-1}x)
\]</span> for any positive integer n. As usual <span class="math inline">\(A^1=A\)</span> and <span class="math inline">\(A^0=\mathscr I\)</span>.</p>
<p>==Theorem 4.2.1==</p>
<p>The product AB of bounded operators A and B is bounded and <span class="math inline">\(||AB||\le ||A||||B||\)</span></p>
<p>==Theorem 4.2.2==</p>
<p>A bounded operator on a separable infinite dimensional Hilbert Space can be represented by an infinite matrix.</p>
<h2 id="bilinear-functionals-and-quadratic-forms">4.3 Bilinear Functionals and Quadratic Forms</h2>
<p>The concept of Bilinear functional and quadratic form do not require the structure of an inner product space. They can be defined in any vector space. This discussion is presented in this chapter because of important applications to the theory of operators in Hilbert Space.</p>
<p>==Definition 4.3.1== (Bilinear Functional)</p>
<p>By a bilinear functional <span class="math inline">\(\phi\)</span> on a complex vector space E, we mean a mapping <span class="math inline">\(E\times E \rightarrow C\)</span> satisfying the following two conditions,</p>
<ol type="a">
<li><p><span class="math inline">\(\phi(\alpha x_1+\beta x_2,y)=\alpha \phi(x_1,y)+\beta \phi(x_2,y)\)</span></p></li>
<li><p><span class="math inline">\(\phi(x,\alpha y_1+\beta y_2)=\bar \alpha \phi(x,y_1)+\bar \beta \phi(x,y_2)\)</span></p></li>
</ol>
<p>for any scalar <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> and any <span class="math inline">\(x,x_1,x_2,y,y_1,y_2\in E\)</span>.</p>
<p>Bilinear functionals are often called ==sesquilinear==. Note that bilinear functional is linear with respect to the first variable and antilinear with respect to the second variable, all bilinear functionals on E constitute a vector space.</p>
<p>==Example 4.2.1== Inner product is a bilinear functional</p>
<p>==Example 4.2.2== Let A and B be operators on an inner product space E. Then <span class="math inline">\(\phi_1(x,y)=&lt;Ax,y&gt;\)</span>, <span class="math inline">\(\phi_2(x,y)=&lt;x,By&gt;\)</span>, and <span class="math inline">\(\phi_3(x,y)=&lt;Ax,By&gt;\)</span> are bilinear functionals.</p>
<p>==Example 4.2.3== Let <span class="math inline">\(f\)</span> and <span class="math inline">\(g\)</span> be linear functionals on a vector space E. Then <span class="math inline">\(\phi(x,y)=f(x)\overline{g(y)}\)</span> is a bilinear functional on E.</p>
<p>==Definition 4.3.2== Let <span class="math inline">\(\phi\)</span> be a bilinear functional on E.</p>
<ol type="a">
<li><p><span class="math inline">\(\phi\)</span> is called symmetric if <span class="math inline">\(\phi(x,y)=\overline{\phi(y,x)}\)</span> for all <span class="math inline">\(x,y\in E\)</span>.</p></li>
<li><p><span class="math inline">\(\phi\)</span> is called positive if <span class="math inline">\(\phi(x,x)\ge 0\)</span> for every <span class="math inline">\(x\in E\)</span>.</p></li>
<li><p><span class="math inline">\(\phi\)</span> is called strictly positive if it is positive and <span class="math inline">\(\phi(x,x)&gt;0\)</span> for every <span class="math inline">\(x\neq 0\)</span>.</p></li>
<li><p>If E is a normed space, then <span class="math inline">\(\phi\)</span> is called bounded if <span class="math inline">\(|\phi(x,y)|\le K||x|||y||\)</span> for some <span class="math inline">\(K&gt;0\)</span> and all <span class="math inline">\(x,y\in E\)</span>. The norm of a bounded bilinear functional is defined by <span class="math display">\[
||\phi||=\sup_{||x||=1,||y||=1}|\phi(x,y)|
\]</span> ==Definition 4.3.3== (Quadratic form)</p></li>
</ol>
<p>Let <span class="math inline">\(\phi\)</span> be a bilinear functional on a vector space E. The function <span class="math inline">\(\Phi:E\rightarrow C\)</span> defined by <span class="math inline">\(\Phi(x)=\phi(x,x)\)</span> is called the quadratic form associated with <span class="math inline">\(\phi\)</span>. A quadratic form <span class="math inline">\(\Phi\)</span> on a normed space E is called bounded if there exists a constant <span class="math inline">\(k&gt;0\)</span> such that <span class="math inline">\(|\Phi(x)|\le k||x||^2\)</span> for all <span class="math inline">\(x\in E\)</span>. The norm of a bounded quadratic form is defined by <span class="math display">\[
||\Phi||=\sup_{||x||=1} |\Phi(x)|
\]</span> ==Theorem 4.3.1== (Polarization Identity)</p>
<p>Let <span class="math inline">\(\phi\)</span> be a bilinear functional on E and let <span class="math inline">\(\Phi\)</span> be quadratic form associated with <span class="math inline">\(\phi\)</span>. Then <span class="math display">\[
4\phi(x,y)=\Phi(x+y)-\Phi(x-y)+i\Phi(x+iy)-i\Phi(x-iy)
\]</span> for all <span class="math inline">\(x,y\in E\)</span>.</p>
<p>==Corollary 4.3.1== Let <span class="math inline">\(\phi_1\)</span> and <span class="math inline">\(\phi_2\)</span> be bilinear functional on E. If <span class="math inline">\(\phi_1(x,x)=\phi_2(x,x)\)</span> for all <span class="math inline">\(x\in E\)</span>, then <span class="math inline">\(\phi_1=\phi_2\)</span>. i.e. <span class="math inline">\(\phi_1(x,y)=\phi_2(x,y)\)</span> for all <span class="math inline">\(x,y \in E\)</span>.</p>
<p>==Theorem 4.3.2== A bilinear functional <span class="math inline">\(\phi\)</span> on E is symmetric if and only if the associated quadratic form <span class="math inline">\(\Phi\)</span> is real.</p>
<p>==Theorem 4.3.3== A bilinear functional <span class="math inline">\(\phi\)</span> on a normed space E is bounded if and only if the associated quadratic form <span class="math inline">\(\Phi\)</span> is bounded. Moreover, we have <span class="math display">\[
||\Phi||\le ||\phi||\le 2||\Phi||
\]</span> ==Theorem 4.3.4== If a bilinear functional <span class="math inline">\(\phi\)</span> on a normed space <span class="math inline">\(E\)</span> is symmetric and bounded, then for the associated form <span class="math inline">\(\Phi\)</span> we have <span class="math inline">\(||\phi||=||\Phi||\)</span>.</p>
<p>==Theorem 4.3.5== Let <span class="math inline">\(A\)</span> be a bounded operator on a Hilbert space <span class="math inline">\(H\)</span>. Then the bilinear functional defined by <span class="math inline">\(\phi(x,y)=&lt;x,Ay&gt;\)</span> is bounded and <span class="math inline">\(||A||=||\phi||\)</span>.</p>
<p>==Theorem 4.3.6== Let <span class="math inline">\(\phi\)</span> be a bounded bilinear functional on a Hilbert space H. There exists a unique bounded operator A on H such that <span class="math display">\[
\phi(x,y)=&lt;x,Ay&gt;\quad \forall x,y\in H
\]</span> ==Definition 4.3.6== (Coercive Functional)</p>
<p>A bilinear functional <span class="math inline">\(\phi\)</span> on a normed space <span class="math inline">\(E\)</span> is called coercive (or elliptic) if there exists a positive constant K such that <span class="math display">\[
\phi(x,x)\ge K||x||^2\quad \forall x\in E 
\]</span> ==Theorem 4.3.7== (Lax-Milgram Theorem)</p>
<p>Let <span class="math inline">\(\phi\)</span> be a bounded, coercive, bilinear functional on a Hilbert Space H. For every bounded linear functional <span class="math inline">\(f\)</span> on <span class="math inline">\(H\)</span>, there exists a unique <span class="math inline">\(x_f\in H\)</span> such that <span class="math display">\[
f(x)=\phi(x,x_f)\quad \forall x\in H
\]</span></p>
<h2 id="adjoint-and-self-adjoint-operators">4.4 Adjoint and Self-Adjoint Operators</h2>
<p>Let A be a bounded operator on a Hilbert Space H. For every fixed <span class="math inline">\(x_0\in H\)</span>, the functional <span class="math inline">\(f\)</span> defined on H by <span class="math display">\[
f(x)=&lt;Ax,x_0&gt;
\]</span> is bounded linear functional on H. Thus, by Riesz Representation Theorem, there exists unique <span class="math inline">\(y_0\in H\)</span> such that <span class="math inline">\(f(x)=&lt;x,y_0&gt;\)</span> for all <span class="math inline">\(x\in H\)</span>, or, equivalently, <span class="math inline">\(&lt;Ax,x_0&gt;=&lt;x,y_0&gt;\)</span> for all <span class="math inline">\(x\in H\)</span>. If we denote by <span class="math inline">\(A^*\)</span> the operator which to every <span class="math inline">\(x_0\in H\)</span> assigns that unique <span class="math inline">\(y_0\)</span>, then we have<span class="math inline">\(&lt;Ax,y&gt;=&lt;x,A^*y&gt;\)</span> for all <span class="math inline">\(x,y\in H\)</span>.</p>
<p>==Definition 4.4.1== (Adjoint Operator)</p>
<p>Let A be a bounded operator on a Hilbert Space H. The operator <span class="math inline">\(A^*:H\rightarrow H\)</span> defined by <span class="math display">\[
&lt;Ax,y&gt;=&lt;x,A^*y&gt;\quad \forall x,y\in E
\]</span> is called the adjoint operator of A.</p>
<p>The following properties are direct consequences of the above definition. <span class="math display">\[
(A+B)^*=A^*+B^*\\
(\alpha A)^*=\bar \alpha A^*\\
(A^*)^*=A\\
\mathscr J^*=\mathscr J\\
(AB)^*=B^*A^*
\]</span> for arbitrary operators A and B and scalar <span class="math inline">\(\alpha\)</span>.</p>
<p>==Theorem 4.4.1==</p>
<p>The adjoint operator <span class="math inline">\(A^*\)</span> of a bounded operator A is bounded. Moreover, we have <span class="math inline">\(||A||=||A^*||\)</span> and <span class="math inline">\(||A^*A||=||A||^2\)</span></p>
<p>In general, <span class="math inline">\(A\)</span> and <span class="math inline">\(A^*\)</span> need not be equal. Operators for which <span class="math inline">\(A=A^*\)</span> are of special interest.</p>
<p>==Definition 4.4.2== (Self-adjoint Operator)</p>
<p>If <span class="math inline">\(A^*=A\)</span>, i.e. <span class="math inline">\(&lt;Ax,y&gt;=&lt;x,Ay&gt;\)</span> for all <span class="math inline">\(x,y \in H\)</span>, then <span class="math inline">\(A\)</span> is called self-adjoint (or Hermitian).</p>
<p>==Theorem 4.4.2==</p>
<p>Let A be a bounded operator on a Hilbert Space H. The operator <span class="math inline">\(T_1=A^*A\)</span> and <span class="math inline">\(T_2=A+A^*\)</span> are self-adjoint.</p>
<p>==Theorem 4.4.3==</p>
<p>The product of two self-adjoint operators is self-adjoint if and only if the operators are commute.</p>
<p>==Corollary 4.4.1==</p>
<p>If A is self-adjoint, then so is any polynomial of A. <span class="math display">\[
\alpha_n A^n+\dotsm+\alpha_1 A+\alpha_0\mathscr J
\]</span> with real coefficients <span class="math inline">\(\alpha_n,\dotsm,\alpha_0\)</span>.</p>
<p>In the definition of the adjoint operator of A we have assumed that the domain of A is the entire space H. Then the existence and uniqueness of the adjoint operator <span class="math inline">\(A^*\)</span> can be guaranteed by the Riesz Representation Theorem. In practice, we often deal with the operators defined on a proper subspace of H, for example, the differential operator. In such case, the adjoint operator can be defined as follows.</p>
<p>Let <span class="math inline">\(A:\mathscr D(A)\rightarrow H\)</span> and <span class="math inline">\(B:\mathscr D(B)\rightarrow H\)</span> be operators, <span class="math inline">\(\mathscr D(A),\mathscr D(B)\subset H\)</span>. Without loss of generality, we can assume that <span class="math inline">\(\mathscr D(A)\)</span> and <span class="math inline">\(\mathscr D(B)\)</span> are vector spaces. Then B is called an adjoint operator of A if <span class="math display">\[
&lt;Ax,y&gt;=&lt;x,By&gt;\quad\forall x\in\mathscr D(A),y\in\mathscr D(B)
\]</span> In this case, an adjoint operator need not be unique. It can be proved that if <span class="math inline">\(\mathscr D(A)\)</span> is dense in H, the adjoint is unique. Operators defined on proper subspaces of Hilbert space will be discussed in more detail in section 4.12.</p>
<p>==Theorem 4.4.5==</p>
<p>Let T be a self-adjoint operator on a Hilbert Space H. Then <span class="math display">\[
||T||=\sup_{||x||=1} |&lt;Tx,x&gt;|
\]</span> ==Definition 4.4.3== (Anti-Hermitian Operator)</p>
<p>An operator A is called anti-Hermitian if <span class="math inline">\(A=-A^*\)</span>.</p>
<h2 id="invertible-normal-isometric-and-unitary-operators">4.5 Invertible, Normal, Isometric, and Unitary Operators</h2>
<p>==Definition 4.5.1== (Inverse Operator)</p>
<p>Let A be an operator defined on a vector space of E. An operator B defined on <span class="math inline">\(\mathscr R(A)\)</span> is called inverse of A if <span class="math inline">\(ABx=x\)</span> for all <span class="math inline">\(x\in \mathscr R(A)\)</span> and <span class="math inline">\(BAx=x\)</span> for all <span class="math inline">\(x\in \mathscr D(A)\)</span>. An operator which has an inverse is called invertible. The inverse of A will be denoted as <span class="math inline">\(A^{-1}\)</span>.</p>
<p>If an operator has an inverse, then it is unique. Suppose <span class="math inline">\(B_1\)</span> and <span class="math inline">\(B_2\)</span> are inverses of A, then <span class="math display">\[
B_1=B_1\mathscr J=B_1AB_2=\mathscr JB_2=B_2
\]</span> Note also that <span class="math display">\[
\mathscr D(A^{-1})=\mathscr R(A) \quad and\quad \mathscr R(A^{-1})=\mathscr D(A)
\]</span> ==Theorem 4.5.1==</p>
<ol type="a">
<li><p>The inverse of a linear operator is a linear operator</p></li>
<li><p>An operator A is invertible if and only if <span class="math inline">\(Ax=0\)</span> implies <span class="math inline">\(x=0\)</span></p></li>
<li><p>If an operator A is invertible and vectors <span class="math inline">\(x_1,x_2,\dotsm,x_n\)</span> are linearly independent, then <span class="math inline">\(Ax_1,Ax_2,\dotsm,Ax_n\)</span> are linearly independent.</p></li>
<li><p>If operators A and B are invertible, then operator AB is invertible and we have <span class="math inline">\((AB)^{-1}=B^{-1}A^{-1}\)</span></p></li>
</ol>
<p>It follows from (c) that if E is finite dimensional vector space and A is linear invertible operator on E, then <span class="math inline">\(\mathscr R(A)=E\)</span>. As the following example shows, in infinite dimensional vector space, it is not necessarily true.</p>
<p>==Example 4.5.1== Let <span class="math inline">\(E=l^2\)</span>. Define an operator A on E by <span class="math display">\[
A(x_1,x_2,\dotsm)=(0,x_1,x_2,\dotsm).
\]</span> Clearly, this is a linear invertible operator on <span class="math inline">\(l^2\)</span> whose range is proper subspace of <span class="math inline">\(l^2\)</span>.</p>
<p><strong>Invertible of a bounded operator is not necessarily bounded.</strong></p>
<p>==Theorem 4.5.2==</p>
<p>Let A be a bounded operator on a Hilbert space H such that <span class="math inline">\(\mathscr R(A)=H\)</span>. If A has a bounded inverses, then the adjoint <span class="math inline">\(A^*\)</span> is invertible and <span class="math inline">\((A^*)^{-1}=(A^{-1})^*\)</span>.</p>
<p>==Corollary 4.5.1==</p>
<p>If a bounded self-adjoint operator A has bounded inverse <span class="math inline">\(A^{-1}\)</span>, then <span class="math inline">\(A^{-1}\)</span> is self-adjoint.</p>
<p>==Definition 4.5.2== (Normal Operator)</p>
<p>A bounded operator <span class="math inline">\(T\)</span> is called a normal operator if it commutes with its adjoint. i.e. <span class="math inline">\(TT^*=T^*T\)</span>.</p>
<p>==Theorem 4.5.3==</p>
<p>A bounded operator T is normal if and only if <span class="math inline">\(||Tx||=||T^*x||\)</span> for all <span class="math inline">\(x\in H\)</span>.</p>
<p>==Theorem 4.5.4==</p>
<p>If <span class="math inline">\(A\)</span> is normal, then <span class="math inline">\((\alpha \mathscr J-A)\)</span> is normal for any <span class="math inline">\(\alpha \in C\)</span>.</p>
<p>==Theorem 4.5.5== Let T be a bounded operator on a Hilbert space H and let A and B be self-adjoint operators on H such that <span class="math inline">\(T=A+iB\)</span>. Then <span class="math inline">\(T\)</span> is normal if and only if A and B commute.</p>
<p>==Definition 4.5.3== (Isometric Operator)</p>
<p>A bounded operator T on a Hilbert Space H is called an isometric operator if <span class="math inline">\(||Tx||=||x||\)</span> for all <span class="math inline">\(x\in H\)</span>.</p>
<p>==Theorem 4.5.6==</p>
<p>A bounded operator T defined on a Hilbert Space H is isometric if and only if <span class="math inline">\(T^*T=\mathscr J\)</span> on H.</p>
<p>==Definition 4.5.4== (Unitary Operator)</p>
<p>A bounded operator T on a Hilbert space H is called a unitary operator if <span class="math inline">\(T^*T=TT^*=\mathscr J\)</span> on H.</p>
<p>==Theorem 4.5.7==</p>
<p>An operator T is unitary if and only if it is invertible and <span class="math inline">\(T^{-1}=T^*\)</span>.</p>
<p>==Theorem 4.5.8==</p>
<p>Let T be a unitary operator. Then</p>
<ol type="a">
<li><p>T is isometric</p></li>
<li><p>T is normal</p></li>
<li><p><span class="math inline">\(T^{-1}\)</span> and <span class="math inline">\(T^{*}\)</span> are unitary.</p></li>
</ol>
<h2 id="positive-operators">4.6 Positive Operators</h2>
<p>==Definition 4.6.1== (Positive Operators)</p>
<p>An operator A is called positive if it is self-adjoint and <span class="math inline">\(&lt;Ax,x&gt;\ge 0\)</span> for all <span class="math inline">\(x\in H\)</span>.</p>
<p>==Theorem 4.6.1== For any bounded operator A on a Hilbert space H, the operators <span class="math inline">\(A^*A\)</span> and <span class="math inline">\(AA^*\)</span> are positive.</p>
<p>==Theorem 4.6.2== If A is an invertible positive operator on a Hilbert Space H, then its inverse <span class="math inline">\(A^{-1}\)</span> is positive.</p>
<p>To indicate that A is positive operator, we write <span class="math inline">\(A\ge 0\)</span>. If the difference <span class="math inline">\(A-B\)</span> of two self-adjoint operators is a positive operator, i.e. <span class="math inline">\(A-B\ge 0\)</span>, then we write <span class="math inline">\(A\ge B\)</span>. Consequently, <span class="math inline">\(A\ge B\)</span> if and only if <span class="math inline">\(&lt;Ax,x&gt;\ge &lt;Bx,x&gt;\)</span> for all <span class="math inline">\(x\in H\)</span>.</p>
<p>This relation has the following natural properties,</p>
<ol type="1">
<li>If <span class="math inline">\(A\ge B\)</span> and <span class="math inline">\(C\ge D\)</span>, then <span class="math inline">\(A+C\ge B+D\)</span></li>
<li>If <span class="math inline">\(A\ge 0\)</span> and <span class="math inline">\(\alpha\ge 0\)</span>, then <span class="math inline">\(\alpha A\ge 0\)</span></li>
<li>If <span class="math inline">\(A\ge B\)</span> and <span class="math inline">\(B\ge C\)</span>, then <span class="math inline">\(A\ge C\)</span></li>
</ol>
<p>==Theorem 4.6.3==</p>
<p>If A is a self-adjoint operator on H and <span class="math inline">\(||A||\le 1\)</span>, then <span class="math inline">\(A\le \mathscr J\)</span>.</p>
<p>==Corollary 4.6.1==</p>
<p>If A is a positive operator on a Hilbert Space H, then there exists <span class="math inline">\(\alpha&gt;0\)</span> such that <span class="math inline">\(\alpha A\le \mathscr J\)</span>.</p>
<p>==Theorem 4.6.4==</p>
<p>The product of two commuting positive operators on a Hilbert space is a positive operator.</p>
<p>==Corollary 4.6.2==</p>
<p>Let A and B be self-adjoint operators on a Hilbert space H. if <span class="math inline">\(A\le B\)</span>, then <span class="math inline">\(AC\le BC\)</span> for every positive operator C that commutes with both A and B.</p>
<p>==Theorem 4.6.5==</p>
<p>Let A be a positive operator on a Hilbert Space H such that <span class="math display">\[
\alpha \mathscr J\le A\le \beta \mathscr J
\]</span> for some <span class="math inline">\(0\le \alpha\le \beta\)</span>, then</p>
<ol type="a">
<li><p>A is invertible</p></li>
<li><p><span class="math inline">\(\mathscr R(A)=H\)</span></p></li>
<li><p><span class="math inline">\(\frac{1}{\beta}\mathscr J\le A^{-1}\le \frac{1}{\alpha}\mathscr J\)</span></p></li>
</ol>
<p>The following theorem is a property of positive operator that is analogous to a property of real numbers.</p>
<p>==Theorem 4.6.6==</p>
<p>Let <span class="math inline">\(A_1\le A_2\le \dotsm\le A_n\le \dotsm\)</span> be self-adjoint operators in a Hilbert space H such that <span class="math inline">\(A_nA_m=A_mA_n\)</span> for all $m,nN $. If B is a self-adjoint operator on H such that <span class="math inline">\(A_nB=BA_n\)</span> and <span class="math inline">\(A_n\le B\)</span> for all <span class="math inline">\(n\in N\)</span>, then there exists a self-adjoint operator A such that <span class="math display">\[
\lim_{n\rightarrow \infty} A_nx=Ax\quad \forall x\in H\\
A_n\le A\le B\quad \forall n\in N
\]</span> ==Definition 4.6.2== (Square root)</p>
<p>A square root of a positive operator is a self-adjoint operator B satisfying <span class="math inline">\(B^2=A\)</span>.</p>
<p>==Theorem 4.6.7==</p>
<p>Every positive operator A has a unique positive square root B. Moreover, B commutes with every operator commuting with A.</p>
<p>==Definition 4.6.3== (Strictly positive operator)</p>
<p>A self-adjoint operator is called strictly positive definite if <span class="math inline">\(&lt;Ax,x&gt;&gt;0\)</span> for all <span class="math inline">\(x\in H\)</span>, <span class="math inline">\(x\neq 0\)</span>.</p>
<h2 id="projection-operators">4.7 Projection Operators</h2>
<p>Theorem 3.9.2 states that if S is a closed subspace of a Hilbert space H, then for every <span class="math inline">\(x\in H\)</span>, there exists a unique element <span class="math inline">\(y\in S\)</span> such that <span class="math inline">\(x=y+z\)</span> and <span class="math inline">\(z\in S^{\perp}.\)</span> Thus, every closed subspace induces an operator on H which assigns to x that unique y.</p>
<p>==Definition 4.7.1== (Orthogonal Projection Operator)</p>
<p>Let S be a closed subspace of a Hilbert Space H. The operator P on H defined by <span class="math display">\[
Px=y\quad if\quad x=y+z,y\in S, z\in S^\perp
\]</span> is called the orthogonal projection operator onto S, or simply projection operator onto S. The vector y is called the projection of x onto S.</p>
<p>==Definition 4.7.2== (Idempotent Operator)</p>
<p>An operator T is called idempotent if <span class="math inline">\(T^2=T\)</span>.</p>
<p>==Theorem 4.7.1==</p>
<p>A bounded operator is a projection if and only if it is idempotent and self-adjoint.</p>
<p>==Corollary 4.7.1==</p>
<p>If P is a projection operator onto a subspace of a Hilbert Space H, then <span class="math inline">\(&lt;Px,x&gt;=||Px||^2\)</span> for all <span class="math inline">\(x\in H\)</span>.</p>
<p>==Definition 4.7.3== (Orthogonality of Projection Operators) Two projection operator P and Q are called orthogonal if <span class="math inline">\(PQ=0\)</span>.</p>
<p>==Theorem 4.7.2== Two projection operators <span class="math inline">\(P_R:H\rightarrow R\)</span> and <span class="math inline">\(P_S:H\rightarrow S\)</span> are orthogonal if and only if <span class="math inline">\(R\perp S\)</span>.</p>
<p>==Theorem 4.7.3== The sum of two projection operators <span class="math inline">\(P_R\)</span> and <span class="math inline">\(P_S\)</span> is a projection operator if and only if <span class="math inline">\(P_RP_S=0\)</span>. In this case <span class="math inline">\(P_R+P_S=P_{R\oplus S}\)</span>.</p>
<p>==Theorem 4.7.4== The product of two projection operators <span class="math inline">\(P_R\)</span> and <span class="math inline">\(P_S\)</span> is a projection operator if and only if <span class="math inline">\(P_R\)</span> and <span class="math inline">\(P_S\)</span> commute. In this case, <span class="math inline">\(P_RP_S=P_{R\cap S}\)</span>.</p>
<p>==Theorem 4.7.5== Let R and S be two closed subspaces of a Hilbert Space H and let <span class="math inline">\(P_R\)</span> and <span class="math inline">\(P_S\)</span> be the respective projections. The following condition are equivalent:</p>
<ol type="a">
<li><p><span class="math inline">\(R\subset S\)</span></p></li>
<li><p><span class="math inline">\(P_SP_R=P_R\)</span></p></li>
<li><p><span class="math inline">\(P_RP_S=P_R\)</span></p></li>
<li><p><span class="math inline">\(||P_Rx||\le ||P_Sx||\)</span> for all <span class="math inline">\(x\in H\)</span>.</p></li>
</ol>
<h2 id="compact-operators">4.8 Compact Operators</h2>

        
      
    </div>

    
    
    
      <footer class="post-footer">
          <div class="post-eof"></div>
        
      </footer>
  </div>
  
  
  
  </article>

    
  </div>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/8/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><span class="page-number current">9</span><a class="page-number" href="/page/10/">10</a><span class="space">&hellip;</span><a class="page-number" href="/page/38/">38</a><a class="extend next" rel="next" href="/page/10/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>


          </div>
          

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc" data-target="post-toc-wrap">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview" data-target="site-overview-wrap">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Cheng-Zilong</p>
  <div class="site-description" itemprop="description"></div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">75</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">categories</span>
        </a>
      </div>
    
  </nav>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="mailto:zilongcheng@u.nus.edu" title="E-Mail &rarr; mailto:zilongcheng@u.nus.edu" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
    
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2021</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Cheng-Zilong</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.3.0</div>

        












        
      </div>
    </footer>
  </div>

  
    
  
  <script color='0,0,255' opacity='0.5' zIndex='-1' count='99' src="/lib/canvas-nest/canvas-nest.min.js"></script>
  <script src="/lib/jquery/index.js?v=3.4.1"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.3.0"></script><script src="/js/motion.js?v=7.3.0"></script>
<script src="/js/schemes/pisces.js?v=7.3.0"></script>

<script src="/js/next-boot.js?v=7.3.0"></script>



  





















  

  
    
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    
  

  

  

</body>
</html>
